{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Section 2 - Federated Learning.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ta4sJW3eWqd-",
        "colab_type": "text"
      },
      "source": [
        "# Section: Federated Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhLmZZ3LWqeC",
        "colab_type": "text"
      },
      "source": [
        "# Lesson: Introducing Federated Learning\n",
        "\n",
        "Federated Learning is a technique for training Deep Learning models on data to which you do not have access. Basically:\n",
        "\n",
        "Federated Learning: Instead of bringing all the data to one machine and training a model, we bring the model to the data, train it locally, and merely upload \"model updates\" to a central server.\n",
        "\n",
        "Use Cases:\n",
        "\n",
        "    - app company (Texting prediction app)\n",
        "    - predictive maintenance (automobiles / industrial engines)\n",
        "    - wearable medical devices\n",
        "    - ad blockers / autotomplete in browsers (Firefox/Brave)\n",
        "    \n",
        "Challenge Description: data is distributed amongst sources but we cannot aggregated it because of:\n",
        "\n",
        "    - privacy concerns: legal, user discomfort, competitive dynamics\n",
        "    - engineering: the bandwidth/storage requirements of aggregating the larger dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SZNUiVFWqeD",
        "colab_type": "text"
      },
      "source": [
        "# Lesson: Introducing / Installing PySyft\n",
        "\n",
        "In order to perform Federated Learning, we need to be able to use Deep Learning techniques on remote machines. This will require a new set of tools. Specifically, we will use an extensin of PyTorch called PySyft.\n",
        "\n",
        "### Install PySyft\n",
        "\n",
        "The easiest way to install the required libraries is with [Conda](https://docs.conda.io/projects/conda/en/latest/user-guide/overview.html). Create a new environment, then install the dependencies in that environment. In your terminal:\n",
        "\n",
        "```bash\n",
        "conda create -n pysyft python=3\n",
        "conda activate pysyft # some older version of conda require \"source activate pysyft\" instead.\n",
        "conda install jupyter notebook\n",
        "pip install syft\n",
        "pip install numpy\n",
        "```\n",
        "\n",
        "If you have any errors relating to zstd - run the following (if everything above installed fine then skip this step):\n",
        "\n",
        "```\n",
        "pip install --upgrade --force-reinstall zstd\n",
        "```\n",
        "\n",
        "and then retry installing syft (pip install syft).\n",
        "\n",
        "If you are using Windows, I suggest installing [Anaconda and using the Anaconda Prompt](https://docs.anaconda.com/anaconda/user-guide/getting-started/) to work from the command line. \n",
        "\n",
        "With this environment activated and in the repo directory, launch Jupyter Notebook:\n",
        "\n",
        "```bash\n",
        "jupyter notebook\n",
        "```\n",
        "\n",
        "and re-open this notebook on the new Jupyter server.\n",
        "\n",
        "If any part of this doesn't work for you (or any of the tests fail) - first check the [README](https://github.com/OpenMined/PySyft.git) for installation help and then open a Github Issue or ping the #beginner channel in our slack! [slack.openmined.org](http://slack.openmined.org/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dDLJwzVWqeE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch as th"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8GiPhEtWqeI",
        "colab_type": "code",
        "outputId": "e32c9900-a20c-41ed-9ba7-344b496d226f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x = th.tensor([1,2,3,4,5])\n",
        "x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3, 4, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFabGBgFWqeP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = x + x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsbA80ovWqeS",
        "colab_type": "code",
        "outputId": "e3334505-67e2-4e8a-aba5-d7bb08fe9032",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ 2,  4,  6,  8, 10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KCtQclJWqeV",
        "colab_type": "code",
        "outputId": "14435ecd-65aa-4b56-83f8-c5743b2a5860",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install --upgrade syft"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting syft\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/38/2e/16bdefc78eb089e1efa9704c33b8f76f035a30dc935bedd7cbb22f6dabaa/syft-0.1.21a1-py3-none-any.whl (219kB)\n",
            "\u001b[K     |████████████████████████████████| 225kB 2.2MB/s \n",
            "\u001b[?25hCollecting zstd>=1.4.0.0 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/27/1ea8086d37424e83ab692015cc8dd7d5e37cf791e339633a40dc828dfb74/zstd-1.4.0.0.tar.gz (450kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 45.8MB/s \n",
            "\u001b[?25hCollecting msgpack>=0.6.1 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/7e/ae9e91c1bb8d846efafd1f353476e3fd7309778b582d2fb4cea4cc15b9a2/msgpack-0.6.1-cp36-cp36m-manylinux1_x86_64.whl (248kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 44.6MB/s \n",
            "\u001b[?25hCollecting websocket-client>=0.56.0 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/19/44753eab1fdb50770ac69605527e8859468f3c0fd7dc5a76dd9c4dbd7906/websocket_client-0.56.0-py2.py3-none-any.whl (200kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 44.1MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: torchvision>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from syft) (0.3.0)\n",
            "Collecting lz4>=2.1.6 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0a/c6/96bbb3525a63ebc53ea700cc7d37ab9045542d33b4d262d0f0408ad9bbf2/lz4-2.1.10-cp36-cp36m-manylinux1_x86_64.whl (385kB)\n",
            "\u001b[K     |████████████████████████████████| 389kB 45.0MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: torch>=1.1 in /usr/local/lib/python3.6/dist-packages (from syft) (1.1.0)\n",
            "Collecting flask-socketio>=3.3.2 (from syft)\n",
            "  Downloading https://files.pythonhosted.org/packages/4b/68/fe4806d3a0a5909d274367eb9b3b87262906c1515024f46c2443a36a0c82/Flask_SocketIO-4.1.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: tblib>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from syft) (1.4.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from syft) (1.16.4)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn>=0.21.0 in /usr/local/lib/python3.6/dist-packages (from syft) (0.21.2)\n",
            "Collecting websockets>=7.0 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/61/5e/2fe6afbb796c6ac5c006460b5503cd674d33706660337f2dbff10d4aa12d/websockets-8.0-cp36-cp36m-manylinux1_x86_64.whl (72kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 28.6MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: Flask>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from syft) (1.0.3)\n",
            "Collecting tf-encrypted>=0.5.4 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/ce/da9916e7e78f736894b15538b702c0b213fd5d60a7fd6e481d74033a90c0/tf_encrypted-0.5.6-py3-none-manylinux1_x86_64.whl (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 42.2MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from websocket-client>=0.56.0->syft) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.3.0->syft) (4.3.0)\n",
            "Collecting python-socketio>=2.1.0 (from flask-socketio>=3.3.2->syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/26/1b/57e860a86f2a01be86ae1dacfa0cd8c4dfbfcd4593322268b61b5a07b564/python_socketio-4.2.0-py2.py3-none-any.whl (46kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 19.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.0->syft) (0.13.2)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.0->syft) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (7.0)\n",
            "Requirement already satisfied, skipping upgrade: Werkzeug>=0.14 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (0.15.4)\n",
            "Requirement already satisfied, skipping upgrade: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: Jinja2>=2.10 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (2.10.1)\n",
            "Collecting pyyaml>=5.1 (from tf-encrypted>=0.5.4->syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/65/837fefac7475963d1eccf4aa684c23b95aa6c1d033a2c5965ccb11e22623/PyYAML-5.1.1.tar.gz (274kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 46.0MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: tensorflow<2,>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tf-encrypted>=0.5.4->syft) (1.14.0)\n",
            "Requirement already satisfied, skipping upgrade: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision>=0.3.0->syft) (0.46)\n",
            "Collecting python-engineio>=3.8.0 (from python-socketio>=2.1.0->flask-socketio>=3.3.2->syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bd/b8/0fc389ca5c445051b37b17802f80bbf1b51c1e3b48b772ee608efbb90583/python_engineio-3.8.2.post1-py2.py3-none-any.whl (119kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 43.6MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10->Flask>=1.0.2->syft) (1.1.1)\n",
            "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.11.2)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.7.1)\n",
            "Requirement already satisfied, skipping upgrade: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.2.2)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.0.8)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.14.0)\n",
            "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.8.0)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.33.4)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.14.0)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (3.7.1)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.1.7)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (2.8.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (41.0.1)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (3.1.1)\n",
            "Building wheels for collected packages: zstd, pyyaml\n",
            "  Building wheel for zstd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/ad/9a/f4/3105b5209674ac77fcca7fede95184c62a95df0196888e0e76\n",
            "  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/16/27/a1/775c62ddea7bfa62324fd1f65847ed31c55dadb6051481ba3f\n",
            "Successfully built zstd pyyaml\n",
            "Installing collected packages: zstd, msgpack, websocket-client, lz4, python-engineio, python-socketio, flask-socketio, websockets, pyyaml, tf-encrypted, syft\n",
            "  Found existing installation: msgpack 0.5.6\n",
            "    Uninstalling msgpack-0.5.6:\n",
            "      Successfully uninstalled msgpack-0.5.6\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed flask-socketio-4.1.0 lz4-2.1.10 msgpack-0.6.1 python-engineio-3.8.2.post1 python-socketio-4.2.0 pyyaml-5.1.1 syft-0.1.21a1 tf-encrypted-0.5.6 websocket-client-0.56.0 websockets-8.0 zstd-1.4.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "te77D_lYWqeX",
        "colab_type": "code",
        "outputId": "c4fac28d-044c-46fd-be8d-9be9a864b613",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "import syft as sy"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0711 14:39:17.395351 139801093379968 secure_random.py:26] Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was '/usr/local/lib/python3.6/dist-packages/tf_encrypted/operations/secure_random/secure_random_module_tf_1.14.0.so'\n",
            "W0711 14:39:17.416212 139801093379968 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tf_encrypted/session.py:26: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irNyg-zTWqeZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hook = sy.TorchHook(th)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7gBQsRnWqeb",
        "colab_type": "code",
        "outputId": "8ecfac81-ad42-417e-924f-bca6ef6f53cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "th.tensor([1,2,3,4,5])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3, 4, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMLCgNM1Wqee",
        "colab_type": "text"
      },
      "source": [
        "# Lesson: Basic Remote Execution in PySyft"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aH_IEhefWqee",
        "colab_type": "text"
      },
      "source": [
        "## PySyft => Remote PyTorch\n",
        "\n",
        "The essence of Federated Learning is the ability to train models in parallel on a wide number of machines. Thus, we need the ability to tell remote machines to execute the operations required for Deep Learning.\n",
        "\n",
        "Thus, instead of using Torch tensors - we're now going to work with **pointers** to tensors. Let me show you what I mean. First, let's create a \"pretend\" machine owned by a \"pretend\" person - we'll call him Bob."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkNpRjxlWqef",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bob = sy.VirtualWorker(hook, id=\"bob\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFD5GHtZWqeh",
        "colab_type": "code",
        "outputId": "3fce47d8-277b-443c-9a4d-4b07e13040f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "bob._objects"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lTmCg5oWqek",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = th.tensor([1,2,3,4,5])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydUbYZJqWqen",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = x.send(bob)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvPqEHRoWqep",
        "colab_type": "code",
        "outputId": "3c5e8423-9683-4a32-dee8-3b218c02a09c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "bob._objects"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{783865760: tensor([1, 2, 3, 4, 5])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZ8Xgj6RWqet",
        "colab_type": "code",
        "outputId": "78b50f9a-af5b-43b3-b62b-3a8af7766212",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x.location"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<VirtualWorker id:bob #objects:1>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHyxT8DbWqew",
        "colab_type": "code",
        "outputId": "a64e384c-dfec-40e1-b8fd-5e018fa08a6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x.id_at_location"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "783865760"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "te89seTLWqe0",
        "colab_type": "code",
        "outputId": "ee6e87bd-155b-40e3-f9be-08c89466d463",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x.id"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "42561321233"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDKH8S-6Wqe4",
        "colab_type": "code",
        "outputId": "31040341-1ef3-4a14-e030-151879f5f1b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x.owner"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<VirtualWorker id:me #objects:0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7Y10UAIWqe7",
        "colab_type": "code",
        "outputId": "137973b9-5467-4f94-b446-9413b8257e4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "hook.local_worker"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<VirtualWorker id:me #objects:0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10YyuB5_Wqe_",
        "colab_type": "code",
        "outputId": "a020f4a6-1eba-4d59-8217-855ac93ed815",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Wrapper)>[PointerTensor | me:42561321233 -> bob:783865760]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "143VWKO9WqfC",
        "colab_type": "code",
        "outputId": "e9266c12-018a-4415-f58e-f43678bc5d9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x = x.get()\n",
        "x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3, 4, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxSAiClmWqfG",
        "colab_type": "code",
        "outputId": "9bc3f77b-d0ce-4aba-fcbf-38c7fbf3976f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "bob._objects"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ke6livirWqfJ",
        "colab_type": "text"
      },
      "source": [
        "# Project: Playing with Remote Tensors\n",
        "\n",
        "In this project, I want you to .send() and .get() a tensor to TWO workers by calling .send(bob,alice). This will first require the creation of another VirtualWorker called alice."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "445jUtneWqfJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bob=sy.VirtualWorker(hook,id=\"bob\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05sfG8dNWqfL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "alice=sy.VirtualWorker(hook,id=\"alice\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfJnqGHNWqfN",
        "colab_type": "code",
        "outputId": "68edd8a4-6580-44c7-a9fb-ee5edfdd5064",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x=th.randint(1,10,[10])\n",
        "x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2, 2, 3, 4, 6, 2, 7, 1, 6, 7])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-WPh9W-WqfO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_ptr=x.send(bob,alice)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36zEYxMAWqfQ",
        "colab_type": "code",
        "outputId": "cf63fe52-03e4-4977-8187-54b02e54d166",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# x_ptr=x_ptr.float().mean()\n",
        "alice"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<VirtualWorker id:alice #objects:4>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzh1MIqGWqfS",
        "colab_type": "code",
        "outputId": "4cee36f6-2c6d-47f1-ab18-9cecc9d6f495",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_ptr.get(sum_results=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(8.)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SH2rzJXWqfU",
        "colab_type": "code",
        "outputId": "fdeb88a5-8bb1-4b41-a981-9d9f76de85f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-84dd20fd9e6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/tensors/interpreters/native.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, inplace, *args, **kwargs)\u001b[0m\n\u001b[1;32m    557\u001b[0m         \u001b[0;31m#                     return self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 559\u001b[0;31m         \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m         \u001b[0;31m# Clean the wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'child'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4xsZXCdWqfW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lL4i2hkrWqfY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Q7UydEkWqfZ",
        "colab_type": "text"
      },
      "source": [
        "# Lesson: Introducing Remote Arithmetic"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AQ1DicJWqfa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = th.tensor([1,2,3,4,5]).send(bob)\n",
        "y = th.tensor([1,1,1,1,1]).send(bob)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpFRJFYKWqfb",
        "colab_type": "code",
        "outputId": "c647f1fd-e17e-4c13-ab1b-e50d71d3f86e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Wrapper)>[PointerTensor | me:18024113559 -> bob:1597465589]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjTlot5WWqfe",
        "colab_type": "code",
        "outputId": "8a078bf5-18bc-47ba-ec0a-14c744fede76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Wrapper)>[PointerTensor | me:29766135883 -> bob:31412341160]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAzC9_wVWqfg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "z = x + y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NxHS8pwWqfi",
        "colab_type": "code",
        "outputId": "aa889b6f-09cd-4df5-dc9a-baf02c157b97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "z"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Wrapper)>[PointerTensor | me:27724196846 -> bob:6123685564]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jomp-zPvWqfl",
        "colab_type": "code",
        "outputId": "7a451519-a64b-48d6-8a19-069968bf0824",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "z = z.get()\n",
        "z"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1,  4,  9, 16, 25])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lV3RKlAjWqfo",
        "colab_type": "code",
        "outputId": "2494dc23-3cfe-416e-c93c-39a30f4adcea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "z = th.add(x,y)\n",
        "z"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Wrapper)>[PointerTensor | me:41713350601 -> bob:54554229783]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-UB3UXXWqfq",
        "colab_type": "code",
        "outputId": "764a683c-b7c2-4350-b3de-2beece8d5da8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "z = z.get()\n",
        "z"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2, 3, 4, 5, 6])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5YDWdFYWqfs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = th.tensor([1.,2,3,4,5], requires_grad=True).send(bob)\n",
        "y = th.tensor([1.,1,1,1,1], requires_grad=True).send(bob)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZl0MhdLWqfu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "z = (x + y).sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XTvwb-XCrzg",
        "colab_type": "code",
        "outputId": "113ab9fd-4cec-4af9-bc0a-68316eb8b50c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "z.backward()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Wrapper)>[PointerTensor | me:72134898360 -> bob:84082081156]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kw8m3mkeDFgm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = x.get()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "coanwUOPWqfy",
        "colab_type": "code",
        "outputId": "eb8e54d6-76d0-40b0-cef2-81a844212165",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 2., 3., 4., 5.], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kop8emZKK1yT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x.grad"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snIgS-Q1K8Zk",
        "colab_type": "code",
        "outputId": "9a69fa78-cf87-4b64-c886-85ac672ab4bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(20., requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0DV8srfUWqgA",
        "colab_type": "text"
      },
      "source": [
        "# Project: Learn a Simple Linear Model\n",
        "\n",
        "In this project, I'd like for you to create a simple linear model which will solve for the following dataset below. You should use only Variables and .backward() to do so (no optimizers or nn.Modules). Furthermore, you must do so with both the data and the model being located on Bob's machine."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qfW6wwCWqgB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn.functional as F\n",
        "input=th.tensor([[1.,1],[1,0],[0,1],[0,0]]).send(bob)\n",
        "label=th.tensor([[1.],[1],[0],[0]]).send(bob)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDeP7mcFqTDP",
        "colab_type": "code",
        "outputId": "6266ead1-7cad-4cd6-8bee-78691f97505f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Wrapper)>[PointerTensor | me:76680720125 -> bob:65497709904]::data"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 374
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HRWRzA8WqgC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w1=th.randn([2,6], requires_grad=True).send(bob)\n",
        "b1=th.randn([1,6], requires_grad=True).send(bob)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYtWdW-HWqgF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w2=th.randn([6,1], requires_grad=True).send(bob)\n",
        "b2=th.randn([1,1], requires_grad=True).send(bob)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktZfMeuFWqgH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sigmoid(x):\n",
        "  return 1/(1+th.exp(-x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20MqRlmiWqgJ",
        "colab_type": "code",
        "outputId": "237766ec-a19b-4807-ed66-e4d8d2d0a0fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for _ in range(2000):\n",
        "  h1=sigmoid(th.mm(input,w1)+b1)\n",
        "\n",
        "\n",
        "  out=sigmoid(th.mm(h1,w2)+b2)\n",
        "  \n",
        "  loss=F.binary_cross_entropy(out, label)\n",
        "  loss.backward()\n",
        "  w1.data.sub_(w1.grad*0.2)\n",
        "  b1.data.sub_(b1.grad*0.2)\n",
        "  w2.data.sub_(w2.grad*0.2)\n",
        "  b2.data.sub_(b2.grad*0.2)\n",
        "  w1.grad*=0\n",
        "  b1.grad*=0\n",
        "  w2.grad*=0\n",
        "  b2.grad*=0\n",
        "  print(loss.get().data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.0139)\n",
            "tensor(0.0139)\n",
            "tensor(0.0138)\n",
            "tensor(0.0138)\n",
            "tensor(0.0138)\n",
            "tensor(0.0138)\n",
            "tensor(0.0138)\n",
            "tensor(0.0137)\n",
            "tensor(0.0137)\n",
            "tensor(0.0137)\n",
            "tensor(0.0137)\n",
            "tensor(0.0137)\n",
            "tensor(0.0137)\n",
            "tensor(0.0136)\n",
            "tensor(0.0136)\n",
            "tensor(0.0136)\n",
            "tensor(0.0136)\n",
            "tensor(0.0136)\n",
            "tensor(0.0135)\n",
            "tensor(0.0135)\n",
            "tensor(0.0135)\n",
            "tensor(0.0135)\n",
            "tensor(0.0135)\n",
            "tensor(0.0134)\n",
            "tensor(0.0134)\n",
            "tensor(0.0134)\n",
            "tensor(0.0134)\n",
            "tensor(0.0134)\n",
            "tensor(0.0134)\n",
            "tensor(0.0133)\n",
            "tensor(0.0133)\n",
            "tensor(0.0133)\n",
            "tensor(0.0133)\n",
            "tensor(0.0133)\n",
            "tensor(0.0132)\n",
            "tensor(0.0132)\n",
            "tensor(0.0132)\n",
            "tensor(0.0132)\n",
            "tensor(0.0132)\n",
            "tensor(0.0132)\n",
            "tensor(0.0131)\n",
            "tensor(0.0131)\n",
            "tensor(0.0131)\n",
            "tensor(0.0131)\n",
            "tensor(0.0131)\n",
            "tensor(0.0130)\n",
            "tensor(0.0130)\n",
            "tensor(0.0130)\n",
            "tensor(0.0130)\n",
            "tensor(0.0130)\n",
            "tensor(0.0130)\n",
            "tensor(0.0129)\n",
            "tensor(0.0129)\n",
            "tensor(0.0129)\n",
            "tensor(0.0129)\n",
            "tensor(0.0129)\n",
            "tensor(0.0129)\n",
            "tensor(0.0128)\n",
            "tensor(0.0128)\n",
            "tensor(0.0128)\n",
            "tensor(0.0128)\n",
            "tensor(0.0128)\n",
            "tensor(0.0128)\n",
            "tensor(0.0127)\n",
            "tensor(0.0127)\n",
            "tensor(0.0127)\n",
            "tensor(0.0127)\n",
            "tensor(0.0127)\n",
            "tensor(0.0127)\n",
            "tensor(0.0126)\n",
            "tensor(0.0126)\n",
            "tensor(0.0126)\n",
            "tensor(0.0126)\n",
            "tensor(0.0126)\n",
            "tensor(0.0126)\n",
            "tensor(0.0125)\n",
            "tensor(0.0125)\n",
            "tensor(0.0125)\n",
            "tensor(0.0125)\n",
            "tensor(0.0125)\n",
            "tensor(0.0125)\n",
            "tensor(0.0124)\n",
            "tensor(0.0124)\n",
            "tensor(0.0124)\n",
            "tensor(0.0124)\n",
            "tensor(0.0124)\n",
            "tensor(0.0124)\n",
            "tensor(0.0123)\n",
            "tensor(0.0123)\n",
            "tensor(0.0123)\n",
            "tensor(0.0123)\n",
            "tensor(0.0123)\n",
            "tensor(0.0123)\n",
            "tensor(0.0122)\n",
            "tensor(0.0122)\n",
            "tensor(0.0122)\n",
            "tensor(0.0122)\n",
            "tensor(0.0122)\n",
            "tensor(0.0122)\n",
            "tensor(0.0122)\n",
            "tensor(0.0121)\n",
            "tensor(0.0121)\n",
            "tensor(0.0121)\n",
            "tensor(0.0121)\n",
            "tensor(0.0121)\n",
            "tensor(0.0121)\n",
            "tensor(0.0120)\n",
            "tensor(0.0120)\n",
            "tensor(0.0120)\n",
            "tensor(0.0120)\n",
            "tensor(0.0120)\n",
            "tensor(0.0120)\n",
            "tensor(0.0120)\n",
            "tensor(0.0119)\n",
            "tensor(0.0119)\n",
            "tensor(0.0119)\n",
            "tensor(0.0119)\n",
            "tensor(0.0119)\n",
            "tensor(0.0119)\n",
            "tensor(0.0119)\n",
            "tensor(0.0118)\n",
            "tensor(0.0118)\n",
            "tensor(0.0118)\n",
            "tensor(0.0118)\n",
            "tensor(0.0118)\n",
            "tensor(0.0118)\n",
            "tensor(0.0118)\n",
            "tensor(0.0117)\n",
            "tensor(0.0117)\n",
            "tensor(0.0117)\n",
            "tensor(0.0117)\n",
            "tensor(0.0117)\n",
            "tensor(0.0117)\n",
            "tensor(0.0117)\n",
            "tensor(0.0116)\n",
            "tensor(0.0116)\n",
            "tensor(0.0116)\n",
            "tensor(0.0116)\n",
            "tensor(0.0116)\n",
            "tensor(0.0116)\n",
            "tensor(0.0116)\n",
            "tensor(0.0115)\n",
            "tensor(0.0115)\n",
            "tensor(0.0115)\n",
            "tensor(0.0115)\n",
            "tensor(0.0115)\n",
            "tensor(0.0115)\n",
            "tensor(0.0115)\n",
            "tensor(0.0114)\n",
            "tensor(0.0114)\n",
            "tensor(0.0114)\n",
            "tensor(0.0114)\n",
            "tensor(0.0114)\n",
            "tensor(0.0114)\n",
            "tensor(0.0114)\n",
            "tensor(0.0113)\n",
            "tensor(0.0113)\n",
            "tensor(0.0113)\n",
            "tensor(0.0113)\n",
            "tensor(0.0113)\n",
            "tensor(0.0113)\n",
            "tensor(0.0113)\n",
            "tensor(0.0112)\n",
            "tensor(0.0112)\n",
            "tensor(0.0112)\n",
            "tensor(0.0112)\n",
            "tensor(0.0112)\n",
            "tensor(0.0112)\n",
            "tensor(0.0112)\n",
            "tensor(0.0112)\n",
            "tensor(0.0111)\n",
            "tensor(0.0111)\n",
            "tensor(0.0111)\n",
            "tensor(0.0111)\n",
            "tensor(0.0111)\n",
            "tensor(0.0111)\n",
            "tensor(0.0111)\n",
            "tensor(0.0111)\n",
            "tensor(0.0110)\n",
            "tensor(0.0110)\n",
            "tensor(0.0110)\n",
            "tensor(0.0110)\n",
            "tensor(0.0110)\n",
            "tensor(0.0110)\n",
            "tensor(0.0110)\n",
            "tensor(0.0109)\n",
            "tensor(0.0109)\n",
            "tensor(0.0109)\n",
            "tensor(0.0109)\n",
            "tensor(0.0109)\n",
            "tensor(0.0109)\n",
            "tensor(0.0109)\n",
            "tensor(0.0109)\n",
            "tensor(0.0108)\n",
            "tensor(0.0108)\n",
            "tensor(0.0108)\n",
            "tensor(0.0108)\n",
            "tensor(0.0108)\n",
            "tensor(0.0108)\n",
            "tensor(0.0108)\n",
            "tensor(0.0108)\n",
            "tensor(0.0107)\n",
            "tensor(0.0107)\n",
            "tensor(0.0107)\n",
            "tensor(0.0107)\n",
            "tensor(0.0107)\n",
            "tensor(0.0107)\n",
            "tensor(0.0107)\n",
            "tensor(0.0107)\n",
            "tensor(0.0106)\n",
            "tensor(0.0106)\n",
            "tensor(0.0106)\n",
            "tensor(0.0106)\n",
            "tensor(0.0106)\n",
            "tensor(0.0106)\n",
            "tensor(0.0106)\n",
            "tensor(0.0106)\n",
            "tensor(0.0106)\n",
            "tensor(0.0105)\n",
            "tensor(0.0105)\n",
            "tensor(0.0105)\n",
            "tensor(0.0105)\n",
            "tensor(0.0105)\n",
            "tensor(0.0105)\n",
            "tensor(0.0105)\n",
            "tensor(0.0105)\n",
            "tensor(0.0104)\n",
            "tensor(0.0104)\n",
            "tensor(0.0104)\n",
            "tensor(0.0104)\n",
            "tensor(0.0104)\n",
            "tensor(0.0104)\n",
            "tensor(0.0104)\n",
            "tensor(0.0104)\n",
            "tensor(0.0104)\n",
            "tensor(0.0103)\n",
            "tensor(0.0103)\n",
            "tensor(0.0103)\n",
            "tensor(0.0103)\n",
            "tensor(0.0103)\n",
            "tensor(0.0103)\n",
            "tensor(0.0103)\n",
            "tensor(0.0103)\n",
            "tensor(0.0103)\n",
            "tensor(0.0102)\n",
            "tensor(0.0102)\n",
            "tensor(0.0102)\n",
            "tensor(0.0102)\n",
            "tensor(0.0102)\n",
            "tensor(0.0102)\n",
            "tensor(0.0102)\n",
            "tensor(0.0102)\n",
            "tensor(0.0102)\n",
            "tensor(0.0101)\n",
            "tensor(0.0101)\n",
            "tensor(0.0101)\n",
            "tensor(0.0101)\n",
            "tensor(0.0101)\n",
            "tensor(0.0101)\n",
            "tensor(0.0101)\n",
            "tensor(0.0101)\n",
            "tensor(0.0101)\n",
            "tensor(0.0100)\n",
            "tensor(0.0100)\n",
            "tensor(0.0100)\n",
            "tensor(0.0100)\n",
            "tensor(0.0100)\n",
            "tensor(0.0100)\n",
            "tensor(0.0100)\n",
            "tensor(0.0100)\n",
            "tensor(0.0100)\n",
            "tensor(0.0099)\n",
            "tensor(0.0099)\n",
            "tensor(0.0099)\n",
            "tensor(0.0099)\n",
            "tensor(0.0099)\n",
            "tensor(0.0099)\n",
            "tensor(0.0099)\n",
            "tensor(0.0099)\n",
            "tensor(0.0099)\n",
            "tensor(0.0098)\n",
            "tensor(0.0098)\n",
            "tensor(0.0098)\n",
            "tensor(0.0098)\n",
            "tensor(0.0098)\n",
            "tensor(0.0098)\n",
            "tensor(0.0098)\n",
            "tensor(0.0098)\n",
            "tensor(0.0098)\n",
            "tensor(0.0098)\n",
            "tensor(0.0097)\n",
            "tensor(0.0097)\n",
            "tensor(0.0097)\n",
            "tensor(0.0097)\n",
            "tensor(0.0097)\n",
            "tensor(0.0097)\n",
            "tensor(0.0097)\n",
            "tensor(0.0097)\n",
            "tensor(0.0097)\n",
            "tensor(0.0097)\n",
            "tensor(0.0096)\n",
            "tensor(0.0096)\n",
            "tensor(0.0096)\n",
            "tensor(0.0096)\n",
            "tensor(0.0096)\n",
            "tensor(0.0096)\n",
            "tensor(0.0096)\n",
            "tensor(0.0096)\n",
            "tensor(0.0096)\n",
            "tensor(0.0096)\n",
            "tensor(0.0095)\n",
            "tensor(0.0095)\n",
            "tensor(0.0095)\n",
            "tensor(0.0095)\n",
            "tensor(0.0095)\n",
            "tensor(0.0095)\n",
            "tensor(0.0095)\n",
            "tensor(0.0095)\n",
            "tensor(0.0095)\n",
            "tensor(0.0095)\n",
            "tensor(0.0094)\n",
            "tensor(0.0094)\n",
            "tensor(0.0094)\n",
            "tensor(0.0094)\n",
            "tensor(0.0094)\n",
            "tensor(0.0094)\n",
            "tensor(0.0094)\n",
            "tensor(0.0094)\n",
            "tensor(0.0094)\n",
            "tensor(0.0094)\n",
            "tensor(0.0093)\n",
            "tensor(0.0093)\n",
            "tensor(0.0093)\n",
            "tensor(0.0093)\n",
            "tensor(0.0093)\n",
            "tensor(0.0093)\n",
            "tensor(0.0093)\n",
            "tensor(0.0093)\n",
            "tensor(0.0093)\n",
            "tensor(0.0093)\n",
            "tensor(0.0093)\n",
            "tensor(0.0092)\n",
            "tensor(0.0092)\n",
            "tensor(0.0092)\n",
            "tensor(0.0092)\n",
            "tensor(0.0092)\n",
            "tensor(0.0092)\n",
            "tensor(0.0092)\n",
            "tensor(0.0092)\n",
            "tensor(0.0092)\n",
            "tensor(0.0092)\n",
            "tensor(0.0092)\n",
            "tensor(0.0091)\n",
            "tensor(0.0091)\n",
            "tensor(0.0091)\n",
            "tensor(0.0091)\n",
            "tensor(0.0091)\n",
            "tensor(0.0091)\n",
            "tensor(0.0091)\n",
            "tensor(0.0091)\n",
            "tensor(0.0091)\n",
            "tensor(0.0091)\n",
            "tensor(0.0091)\n",
            "tensor(0.0090)\n",
            "tensor(0.0090)\n",
            "tensor(0.0090)\n",
            "tensor(0.0090)\n",
            "tensor(0.0090)\n",
            "tensor(0.0090)\n",
            "tensor(0.0090)\n",
            "tensor(0.0090)\n",
            "tensor(0.0090)\n",
            "tensor(0.0090)\n",
            "tensor(0.0090)\n",
            "tensor(0.0089)\n",
            "tensor(0.0089)\n",
            "tensor(0.0089)\n",
            "tensor(0.0089)\n",
            "tensor(0.0089)\n",
            "tensor(0.0089)\n",
            "tensor(0.0089)\n",
            "tensor(0.0089)\n",
            "tensor(0.0089)\n",
            "tensor(0.0089)\n",
            "tensor(0.0089)\n",
            "tensor(0.0089)\n",
            "tensor(0.0088)\n",
            "tensor(0.0088)\n",
            "tensor(0.0088)\n",
            "tensor(0.0088)\n",
            "tensor(0.0088)\n",
            "tensor(0.0088)\n",
            "tensor(0.0088)\n",
            "tensor(0.0088)\n",
            "tensor(0.0088)\n",
            "tensor(0.0088)\n",
            "tensor(0.0088)\n",
            "tensor(0.0087)\n",
            "tensor(0.0087)\n",
            "tensor(0.0087)\n",
            "tensor(0.0087)\n",
            "tensor(0.0087)\n",
            "tensor(0.0087)\n",
            "tensor(0.0087)\n",
            "tensor(0.0087)\n",
            "tensor(0.0087)\n",
            "tensor(0.0087)\n",
            "tensor(0.0087)\n",
            "tensor(0.0087)\n",
            "tensor(0.0086)\n",
            "tensor(0.0086)\n",
            "tensor(0.0086)\n",
            "tensor(0.0086)\n",
            "tensor(0.0086)\n",
            "tensor(0.0086)\n",
            "tensor(0.0086)\n",
            "tensor(0.0086)\n",
            "tensor(0.0086)\n",
            "tensor(0.0086)\n",
            "tensor(0.0086)\n",
            "tensor(0.0086)\n",
            "tensor(0.0086)\n",
            "tensor(0.0085)\n",
            "tensor(0.0085)\n",
            "tensor(0.0085)\n",
            "tensor(0.0085)\n",
            "tensor(0.0085)\n",
            "tensor(0.0085)\n",
            "tensor(0.0085)\n",
            "tensor(0.0085)\n",
            "tensor(0.0085)\n",
            "tensor(0.0085)\n",
            "tensor(0.0085)\n",
            "tensor(0.0085)\n",
            "tensor(0.0084)\n",
            "tensor(0.0084)\n",
            "tensor(0.0084)\n",
            "tensor(0.0084)\n",
            "tensor(0.0084)\n",
            "tensor(0.0084)\n",
            "tensor(0.0084)\n",
            "tensor(0.0084)\n",
            "tensor(0.0084)\n",
            "tensor(0.0084)\n",
            "tensor(0.0084)\n",
            "tensor(0.0084)\n",
            "tensor(0.0084)\n",
            "tensor(0.0083)\n",
            "tensor(0.0083)\n",
            "tensor(0.0083)\n",
            "tensor(0.0083)\n",
            "tensor(0.0083)\n",
            "tensor(0.0083)\n",
            "tensor(0.0083)\n",
            "tensor(0.0083)\n",
            "tensor(0.0083)\n",
            "tensor(0.0083)\n",
            "tensor(0.0083)\n",
            "tensor(0.0083)\n",
            "tensor(0.0083)\n",
            "tensor(0.0082)\n",
            "tensor(0.0082)\n",
            "tensor(0.0082)\n",
            "tensor(0.0082)\n",
            "tensor(0.0082)\n",
            "tensor(0.0082)\n",
            "tensor(0.0082)\n",
            "tensor(0.0082)\n",
            "tensor(0.0082)\n",
            "tensor(0.0082)\n",
            "tensor(0.0082)\n",
            "tensor(0.0082)\n",
            "tensor(0.0082)\n",
            "tensor(0.0082)\n",
            "tensor(0.0081)\n",
            "tensor(0.0081)\n",
            "tensor(0.0081)\n",
            "tensor(0.0081)\n",
            "tensor(0.0081)\n",
            "tensor(0.0081)\n",
            "tensor(0.0081)\n",
            "tensor(0.0081)\n",
            "tensor(0.0081)\n",
            "tensor(0.0081)\n",
            "tensor(0.0081)\n",
            "tensor(0.0081)\n",
            "tensor(0.0081)\n",
            "tensor(0.0080)\n",
            "tensor(0.0080)\n",
            "tensor(0.0080)\n",
            "tensor(0.0080)\n",
            "tensor(0.0080)\n",
            "tensor(0.0080)\n",
            "tensor(0.0080)\n",
            "tensor(0.0080)\n",
            "tensor(0.0080)\n",
            "tensor(0.0080)\n",
            "tensor(0.0080)\n",
            "tensor(0.0080)\n",
            "tensor(0.0080)\n",
            "tensor(0.0080)\n",
            "tensor(0.0079)\n",
            "tensor(0.0079)\n",
            "tensor(0.0079)\n",
            "tensor(0.0079)\n",
            "tensor(0.0079)\n",
            "tensor(0.0079)\n",
            "tensor(0.0079)\n",
            "tensor(0.0079)\n",
            "tensor(0.0079)\n",
            "tensor(0.0079)\n",
            "tensor(0.0079)\n",
            "tensor(0.0079)\n",
            "tensor(0.0079)\n",
            "tensor(0.0079)\n",
            "tensor(0.0079)\n",
            "tensor(0.0078)\n",
            "tensor(0.0078)\n",
            "tensor(0.0078)\n",
            "tensor(0.0078)\n",
            "tensor(0.0078)\n",
            "tensor(0.0078)\n",
            "tensor(0.0078)\n",
            "tensor(0.0078)\n",
            "tensor(0.0078)\n",
            "tensor(0.0078)\n",
            "tensor(0.0078)\n",
            "tensor(0.0078)\n",
            "tensor(0.0078)\n",
            "tensor(0.0078)\n",
            "tensor(0.0077)\n",
            "tensor(0.0077)\n",
            "tensor(0.0077)\n",
            "tensor(0.0077)\n",
            "tensor(0.0077)\n",
            "tensor(0.0077)\n",
            "tensor(0.0077)\n",
            "tensor(0.0077)\n",
            "tensor(0.0077)\n",
            "tensor(0.0077)\n",
            "tensor(0.0077)\n",
            "tensor(0.0077)\n",
            "tensor(0.0077)\n",
            "tensor(0.0077)\n",
            "tensor(0.0077)\n",
            "tensor(0.0076)\n",
            "tensor(0.0076)\n",
            "tensor(0.0076)\n",
            "tensor(0.0076)\n",
            "tensor(0.0076)\n",
            "tensor(0.0076)\n",
            "tensor(0.0076)\n",
            "tensor(0.0076)\n",
            "tensor(0.0076)\n",
            "tensor(0.0076)\n",
            "tensor(0.0076)\n",
            "tensor(0.0076)\n",
            "tensor(0.0076)\n",
            "tensor(0.0076)\n",
            "tensor(0.0076)\n",
            "tensor(0.0076)\n",
            "tensor(0.0075)\n",
            "tensor(0.0075)\n",
            "tensor(0.0075)\n",
            "tensor(0.0075)\n",
            "tensor(0.0075)\n",
            "tensor(0.0075)\n",
            "tensor(0.0075)\n",
            "tensor(0.0075)\n",
            "tensor(0.0075)\n",
            "tensor(0.0075)\n",
            "tensor(0.0075)\n",
            "tensor(0.0075)\n",
            "tensor(0.0075)\n",
            "tensor(0.0075)\n",
            "tensor(0.0075)\n",
            "tensor(0.0075)\n",
            "tensor(0.0074)\n",
            "tensor(0.0074)\n",
            "tensor(0.0074)\n",
            "tensor(0.0074)\n",
            "tensor(0.0074)\n",
            "tensor(0.0074)\n",
            "tensor(0.0074)\n",
            "tensor(0.0074)\n",
            "tensor(0.0074)\n",
            "tensor(0.0074)\n",
            "tensor(0.0074)\n",
            "tensor(0.0074)\n",
            "tensor(0.0074)\n",
            "tensor(0.0074)\n",
            "tensor(0.0074)\n",
            "tensor(0.0074)\n",
            "tensor(0.0073)\n",
            "tensor(0.0073)\n",
            "tensor(0.0073)\n",
            "tensor(0.0073)\n",
            "tensor(0.0073)\n",
            "tensor(0.0073)\n",
            "tensor(0.0073)\n",
            "tensor(0.0073)\n",
            "tensor(0.0073)\n",
            "tensor(0.0073)\n",
            "tensor(0.0073)\n",
            "tensor(0.0073)\n",
            "tensor(0.0073)\n",
            "tensor(0.0073)\n",
            "tensor(0.0073)\n",
            "tensor(0.0073)\n",
            "tensor(0.0072)\n",
            "tensor(0.0072)\n",
            "tensor(0.0072)\n",
            "tensor(0.0072)\n",
            "tensor(0.0072)\n",
            "tensor(0.0072)\n",
            "tensor(0.0072)\n",
            "tensor(0.0072)\n",
            "tensor(0.0072)\n",
            "tensor(0.0072)\n",
            "tensor(0.0072)\n",
            "tensor(0.0072)\n",
            "tensor(0.0072)\n",
            "tensor(0.0072)\n",
            "tensor(0.0072)\n",
            "tensor(0.0072)\n",
            "tensor(0.0072)\n",
            "tensor(0.0072)\n",
            "tensor(0.0071)\n",
            "tensor(0.0071)\n",
            "tensor(0.0071)\n",
            "tensor(0.0071)\n",
            "tensor(0.0071)\n",
            "tensor(0.0071)\n",
            "tensor(0.0071)\n",
            "tensor(0.0071)\n",
            "tensor(0.0071)\n",
            "tensor(0.0071)\n",
            "tensor(0.0071)\n",
            "tensor(0.0071)\n",
            "tensor(0.0071)\n",
            "tensor(0.0071)\n",
            "tensor(0.0071)\n",
            "tensor(0.0071)\n",
            "tensor(0.0071)\n",
            "tensor(0.0070)\n",
            "tensor(0.0070)\n",
            "tensor(0.0070)\n",
            "tensor(0.0070)\n",
            "tensor(0.0070)\n",
            "tensor(0.0070)\n",
            "tensor(0.0070)\n",
            "tensor(0.0070)\n",
            "tensor(0.0070)\n",
            "tensor(0.0070)\n",
            "tensor(0.0070)\n",
            "tensor(0.0070)\n",
            "tensor(0.0070)\n",
            "tensor(0.0070)\n",
            "tensor(0.0070)\n",
            "tensor(0.0070)\n",
            "tensor(0.0070)\n",
            "tensor(0.0070)\n",
            "tensor(0.0069)\n",
            "tensor(0.0069)\n",
            "tensor(0.0069)\n",
            "tensor(0.0069)\n",
            "tensor(0.0069)\n",
            "tensor(0.0069)\n",
            "tensor(0.0069)\n",
            "tensor(0.0069)\n",
            "tensor(0.0069)\n",
            "tensor(0.0069)\n",
            "tensor(0.0069)\n",
            "tensor(0.0069)\n",
            "tensor(0.0069)\n",
            "tensor(0.0069)\n",
            "tensor(0.0069)\n",
            "tensor(0.0069)\n",
            "tensor(0.0069)\n",
            "tensor(0.0069)\n",
            "tensor(0.0069)\n",
            "tensor(0.0068)\n",
            "tensor(0.0068)\n",
            "tensor(0.0068)\n",
            "tensor(0.0068)\n",
            "tensor(0.0068)\n",
            "tensor(0.0068)\n",
            "tensor(0.0068)\n",
            "tensor(0.0068)\n",
            "tensor(0.0068)\n",
            "tensor(0.0068)\n",
            "tensor(0.0068)\n",
            "tensor(0.0068)\n",
            "tensor(0.0068)\n",
            "tensor(0.0068)\n",
            "tensor(0.0068)\n",
            "tensor(0.0068)\n",
            "tensor(0.0068)\n",
            "tensor(0.0068)\n",
            "tensor(0.0068)\n",
            "tensor(0.0067)\n",
            "tensor(0.0067)\n",
            "tensor(0.0067)\n",
            "tensor(0.0067)\n",
            "tensor(0.0067)\n",
            "tensor(0.0067)\n",
            "tensor(0.0067)\n",
            "tensor(0.0067)\n",
            "tensor(0.0067)\n",
            "tensor(0.0067)\n",
            "tensor(0.0067)\n",
            "tensor(0.0067)\n",
            "tensor(0.0067)\n",
            "tensor(0.0067)\n",
            "tensor(0.0067)\n",
            "tensor(0.0067)\n",
            "tensor(0.0067)\n",
            "tensor(0.0067)\n",
            "tensor(0.0067)\n",
            "tensor(0.0066)\n",
            "tensor(0.0066)\n",
            "tensor(0.0066)\n",
            "tensor(0.0066)\n",
            "tensor(0.0066)\n",
            "tensor(0.0066)\n",
            "tensor(0.0066)\n",
            "tensor(0.0066)\n",
            "tensor(0.0066)\n",
            "tensor(0.0066)\n",
            "tensor(0.0066)\n",
            "tensor(0.0066)\n",
            "tensor(0.0066)\n",
            "tensor(0.0066)\n",
            "tensor(0.0066)\n",
            "tensor(0.0066)\n",
            "tensor(0.0066)\n",
            "tensor(0.0066)\n",
            "tensor(0.0066)\n",
            "tensor(0.0066)\n",
            "tensor(0.0065)\n",
            "tensor(0.0065)\n",
            "tensor(0.0065)\n",
            "tensor(0.0065)\n",
            "tensor(0.0065)\n",
            "tensor(0.0065)\n",
            "tensor(0.0065)\n",
            "tensor(0.0065)\n",
            "tensor(0.0065)\n",
            "tensor(0.0065)\n",
            "tensor(0.0065)\n",
            "tensor(0.0065)\n",
            "tensor(0.0065)\n",
            "tensor(0.0065)\n",
            "tensor(0.0065)\n",
            "tensor(0.0065)\n",
            "tensor(0.0065)\n",
            "tensor(0.0065)\n",
            "tensor(0.0065)\n",
            "tensor(0.0065)\n",
            "tensor(0.0065)\n",
            "tensor(0.0064)\n",
            "tensor(0.0064)\n",
            "tensor(0.0064)\n",
            "tensor(0.0064)\n",
            "tensor(0.0064)\n",
            "tensor(0.0064)\n",
            "tensor(0.0064)\n",
            "tensor(0.0064)\n",
            "tensor(0.0064)\n",
            "tensor(0.0064)\n",
            "tensor(0.0064)\n",
            "tensor(0.0064)\n",
            "tensor(0.0064)\n",
            "tensor(0.0064)\n",
            "tensor(0.0064)\n",
            "tensor(0.0064)\n",
            "tensor(0.0064)\n",
            "tensor(0.0064)\n",
            "tensor(0.0064)\n",
            "tensor(0.0064)\n",
            "tensor(0.0064)\n",
            "tensor(0.0063)\n",
            "tensor(0.0063)\n",
            "tensor(0.0063)\n",
            "tensor(0.0063)\n",
            "tensor(0.0063)\n",
            "tensor(0.0063)\n",
            "tensor(0.0063)\n",
            "tensor(0.0063)\n",
            "tensor(0.0063)\n",
            "tensor(0.0063)\n",
            "tensor(0.0063)\n",
            "tensor(0.0063)\n",
            "tensor(0.0063)\n",
            "tensor(0.0063)\n",
            "tensor(0.0063)\n",
            "tensor(0.0063)\n",
            "tensor(0.0063)\n",
            "tensor(0.0063)\n",
            "tensor(0.0063)\n",
            "tensor(0.0063)\n",
            "tensor(0.0063)\n",
            "tensor(0.0063)\n",
            "tensor(0.0062)\n",
            "tensor(0.0062)\n",
            "tensor(0.0062)\n",
            "tensor(0.0062)\n",
            "tensor(0.0062)\n",
            "tensor(0.0062)\n",
            "tensor(0.0062)\n",
            "tensor(0.0062)\n",
            "tensor(0.0062)\n",
            "tensor(0.0062)\n",
            "tensor(0.0062)\n",
            "tensor(0.0062)\n",
            "tensor(0.0062)\n",
            "tensor(0.0062)\n",
            "tensor(0.0062)\n",
            "tensor(0.0062)\n",
            "tensor(0.0062)\n",
            "tensor(0.0062)\n",
            "tensor(0.0062)\n",
            "tensor(0.0062)\n",
            "tensor(0.0062)\n",
            "tensor(0.0062)\n",
            "tensor(0.0062)\n",
            "tensor(0.0061)\n",
            "tensor(0.0061)\n",
            "tensor(0.0061)\n",
            "tensor(0.0061)\n",
            "tensor(0.0061)\n",
            "tensor(0.0061)\n",
            "tensor(0.0061)\n",
            "tensor(0.0061)\n",
            "tensor(0.0061)\n",
            "tensor(0.0061)\n",
            "tensor(0.0061)\n",
            "tensor(0.0061)\n",
            "tensor(0.0061)\n",
            "tensor(0.0061)\n",
            "tensor(0.0061)\n",
            "tensor(0.0061)\n",
            "tensor(0.0061)\n",
            "tensor(0.0061)\n",
            "tensor(0.0061)\n",
            "tensor(0.0061)\n",
            "tensor(0.0061)\n",
            "tensor(0.0061)\n",
            "tensor(0.0061)\n",
            "tensor(0.0060)\n",
            "tensor(0.0060)\n",
            "tensor(0.0060)\n",
            "tensor(0.0060)\n",
            "tensor(0.0060)\n",
            "tensor(0.0060)\n",
            "tensor(0.0060)\n",
            "tensor(0.0060)\n",
            "tensor(0.0060)\n",
            "tensor(0.0060)\n",
            "tensor(0.0060)\n",
            "tensor(0.0060)\n",
            "tensor(0.0060)\n",
            "tensor(0.0060)\n",
            "tensor(0.0060)\n",
            "tensor(0.0060)\n",
            "tensor(0.0060)\n",
            "tensor(0.0060)\n",
            "tensor(0.0060)\n",
            "tensor(0.0060)\n",
            "tensor(0.0060)\n",
            "tensor(0.0060)\n",
            "tensor(0.0060)\n",
            "tensor(0.0060)\n",
            "tensor(0.0059)\n",
            "tensor(0.0059)\n",
            "tensor(0.0059)\n",
            "tensor(0.0059)\n",
            "tensor(0.0059)\n",
            "tensor(0.0059)\n",
            "tensor(0.0059)\n",
            "tensor(0.0059)\n",
            "tensor(0.0059)\n",
            "tensor(0.0059)\n",
            "tensor(0.0059)\n",
            "tensor(0.0059)\n",
            "tensor(0.0059)\n",
            "tensor(0.0059)\n",
            "tensor(0.0059)\n",
            "tensor(0.0059)\n",
            "tensor(0.0059)\n",
            "tensor(0.0059)\n",
            "tensor(0.0059)\n",
            "tensor(0.0059)\n",
            "tensor(0.0059)\n",
            "tensor(0.0059)\n",
            "tensor(0.0059)\n",
            "tensor(0.0059)\n",
            "tensor(0.0059)\n",
            "tensor(0.0058)\n",
            "tensor(0.0058)\n",
            "tensor(0.0058)\n",
            "tensor(0.0058)\n",
            "tensor(0.0058)\n",
            "tensor(0.0058)\n",
            "tensor(0.0058)\n",
            "tensor(0.0058)\n",
            "tensor(0.0058)\n",
            "tensor(0.0058)\n",
            "tensor(0.0058)\n",
            "tensor(0.0058)\n",
            "tensor(0.0058)\n",
            "tensor(0.0058)\n",
            "tensor(0.0058)\n",
            "tensor(0.0058)\n",
            "tensor(0.0058)\n",
            "tensor(0.0058)\n",
            "tensor(0.0058)\n",
            "tensor(0.0058)\n",
            "tensor(0.0058)\n",
            "tensor(0.0058)\n",
            "tensor(0.0058)\n",
            "tensor(0.0058)\n",
            "tensor(0.0058)\n",
            "tensor(0.0057)\n",
            "tensor(0.0057)\n",
            "tensor(0.0057)\n",
            "tensor(0.0057)\n",
            "tensor(0.0057)\n",
            "tensor(0.0057)\n",
            "tensor(0.0057)\n",
            "tensor(0.0057)\n",
            "tensor(0.0057)\n",
            "tensor(0.0057)\n",
            "tensor(0.0057)\n",
            "tensor(0.0057)\n",
            "tensor(0.0057)\n",
            "tensor(0.0057)\n",
            "tensor(0.0057)\n",
            "tensor(0.0057)\n",
            "tensor(0.0057)\n",
            "tensor(0.0057)\n",
            "tensor(0.0057)\n",
            "tensor(0.0057)\n",
            "tensor(0.0057)\n",
            "tensor(0.0057)\n",
            "tensor(0.0057)\n",
            "tensor(0.0057)\n",
            "tensor(0.0057)\n",
            "tensor(0.0057)\n",
            "tensor(0.0057)\n",
            "tensor(0.0056)\n",
            "tensor(0.0056)\n",
            "tensor(0.0056)\n",
            "tensor(0.0056)\n",
            "tensor(0.0056)\n",
            "tensor(0.0056)\n",
            "tensor(0.0056)\n",
            "tensor(0.0056)\n",
            "tensor(0.0056)\n",
            "tensor(0.0056)\n",
            "tensor(0.0056)\n",
            "tensor(0.0056)\n",
            "tensor(0.0056)\n",
            "tensor(0.0056)\n",
            "tensor(0.0056)\n",
            "tensor(0.0056)\n",
            "tensor(0.0056)\n",
            "tensor(0.0056)\n",
            "tensor(0.0056)\n",
            "tensor(0.0056)\n",
            "tensor(0.0056)\n",
            "tensor(0.0056)\n",
            "tensor(0.0056)\n",
            "tensor(0.0056)\n",
            "tensor(0.0056)\n",
            "tensor(0.0056)\n",
            "tensor(0.0056)\n",
            "tensor(0.0055)\n",
            "tensor(0.0055)\n",
            "tensor(0.0055)\n",
            "tensor(0.0055)\n",
            "tensor(0.0055)\n",
            "tensor(0.0055)\n",
            "tensor(0.0055)\n",
            "tensor(0.0055)\n",
            "tensor(0.0055)\n",
            "tensor(0.0055)\n",
            "tensor(0.0055)\n",
            "tensor(0.0055)\n",
            "tensor(0.0055)\n",
            "tensor(0.0055)\n",
            "tensor(0.0055)\n",
            "tensor(0.0055)\n",
            "tensor(0.0055)\n",
            "tensor(0.0055)\n",
            "tensor(0.0055)\n",
            "tensor(0.0055)\n",
            "tensor(0.0055)\n",
            "tensor(0.0055)\n",
            "tensor(0.0055)\n",
            "tensor(0.0055)\n",
            "tensor(0.0055)\n",
            "tensor(0.0055)\n",
            "tensor(0.0055)\n",
            "tensor(0.0055)\n",
            "tensor(0.0054)\n",
            "tensor(0.0054)\n",
            "tensor(0.0054)\n",
            "tensor(0.0054)\n",
            "tensor(0.0054)\n",
            "tensor(0.0054)\n",
            "tensor(0.0054)\n",
            "tensor(0.0054)\n",
            "tensor(0.0054)\n",
            "tensor(0.0054)\n",
            "tensor(0.0054)\n",
            "tensor(0.0054)\n",
            "tensor(0.0054)\n",
            "tensor(0.0054)\n",
            "tensor(0.0054)\n",
            "tensor(0.0054)\n",
            "tensor(0.0054)\n",
            "tensor(0.0054)\n",
            "tensor(0.0054)\n",
            "tensor(0.0054)\n",
            "tensor(0.0054)\n",
            "tensor(0.0054)\n",
            "tensor(0.0054)\n",
            "tensor(0.0054)\n",
            "tensor(0.0054)\n",
            "tensor(0.0054)\n",
            "tensor(0.0054)\n",
            "tensor(0.0054)\n",
            "tensor(0.0054)\n",
            "tensor(0.0053)\n",
            "tensor(0.0053)\n",
            "tensor(0.0053)\n",
            "tensor(0.0053)\n",
            "tensor(0.0053)\n",
            "tensor(0.0053)\n",
            "tensor(0.0053)\n",
            "tensor(0.0053)\n",
            "tensor(0.0053)\n",
            "tensor(0.0053)\n",
            "tensor(0.0053)\n",
            "tensor(0.0053)\n",
            "tensor(0.0053)\n",
            "tensor(0.0053)\n",
            "tensor(0.0053)\n",
            "tensor(0.0053)\n",
            "tensor(0.0053)\n",
            "tensor(0.0053)\n",
            "tensor(0.0053)\n",
            "tensor(0.0053)\n",
            "tensor(0.0053)\n",
            "tensor(0.0053)\n",
            "tensor(0.0053)\n",
            "tensor(0.0053)\n",
            "tensor(0.0053)\n",
            "tensor(0.0053)\n",
            "tensor(0.0053)\n",
            "tensor(0.0053)\n",
            "tensor(0.0053)\n",
            "tensor(0.0053)\n",
            "tensor(0.0053)\n",
            "tensor(0.0052)\n",
            "tensor(0.0052)\n",
            "tensor(0.0052)\n",
            "tensor(0.0052)\n",
            "tensor(0.0052)\n",
            "tensor(0.0052)\n",
            "tensor(0.0052)\n",
            "tensor(0.0052)\n",
            "tensor(0.0052)\n",
            "tensor(0.0052)\n",
            "tensor(0.0052)\n",
            "tensor(0.0052)\n",
            "tensor(0.0052)\n",
            "tensor(0.0052)\n",
            "tensor(0.0052)\n",
            "tensor(0.0052)\n",
            "tensor(0.0052)\n",
            "tensor(0.0052)\n",
            "tensor(0.0052)\n",
            "tensor(0.0052)\n",
            "tensor(0.0052)\n",
            "tensor(0.0052)\n",
            "tensor(0.0052)\n",
            "tensor(0.0052)\n",
            "tensor(0.0052)\n",
            "tensor(0.0052)\n",
            "tensor(0.0052)\n",
            "tensor(0.0052)\n",
            "tensor(0.0052)\n",
            "tensor(0.0052)\n",
            "tensor(0.0052)\n",
            "tensor(0.0051)\n",
            "tensor(0.0051)\n",
            "tensor(0.0051)\n",
            "tensor(0.0051)\n",
            "tensor(0.0051)\n",
            "tensor(0.0051)\n",
            "tensor(0.0051)\n",
            "tensor(0.0051)\n",
            "tensor(0.0051)\n",
            "tensor(0.0051)\n",
            "tensor(0.0051)\n",
            "tensor(0.0051)\n",
            "tensor(0.0051)\n",
            "tensor(0.0051)\n",
            "tensor(0.0051)\n",
            "tensor(0.0051)\n",
            "tensor(0.0051)\n",
            "tensor(0.0051)\n",
            "tensor(0.0051)\n",
            "tensor(0.0051)\n",
            "tensor(0.0051)\n",
            "tensor(0.0051)\n",
            "tensor(0.0051)\n",
            "tensor(0.0051)\n",
            "tensor(0.0051)\n",
            "tensor(0.0051)\n",
            "tensor(0.0051)\n",
            "tensor(0.0051)\n",
            "tensor(0.0051)\n",
            "tensor(0.0051)\n",
            "tensor(0.0051)\n",
            "tensor(0.0051)\n",
            "tensor(0.0051)\n",
            "tensor(0.0050)\n",
            "tensor(0.0050)\n",
            "tensor(0.0050)\n",
            "tensor(0.0050)\n",
            "tensor(0.0050)\n",
            "tensor(0.0050)\n",
            "tensor(0.0050)\n",
            "tensor(0.0050)\n",
            "tensor(0.0050)\n",
            "tensor(0.0050)\n",
            "tensor(0.0050)\n",
            "tensor(0.0050)\n",
            "tensor(0.0050)\n",
            "tensor(0.0050)\n",
            "tensor(0.0050)\n",
            "tensor(0.0050)\n",
            "tensor(0.0050)\n",
            "tensor(0.0050)\n",
            "tensor(0.0050)\n",
            "tensor(0.0050)\n",
            "tensor(0.0050)\n",
            "tensor(0.0050)\n",
            "tensor(0.0050)\n",
            "tensor(0.0050)\n",
            "tensor(0.0050)\n",
            "tensor(0.0050)\n",
            "tensor(0.0050)\n",
            "tensor(0.0050)\n",
            "tensor(0.0050)\n",
            "tensor(0.0050)\n",
            "tensor(0.0050)\n",
            "tensor(0.0050)\n",
            "tensor(0.0050)\n",
            "tensor(0.0050)\n",
            "tensor(0.0049)\n",
            "tensor(0.0049)\n",
            "tensor(0.0049)\n",
            "tensor(0.0049)\n",
            "tensor(0.0049)\n",
            "tensor(0.0049)\n",
            "tensor(0.0049)\n",
            "tensor(0.0049)\n",
            "tensor(0.0049)\n",
            "tensor(0.0049)\n",
            "tensor(0.0049)\n",
            "tensor(0.0049)\n",
            "tensor(0.0049)\n",
            "tensor(0.0049)\n",
            "tensor(0.0049)\n",
            "tensor(0.0049)\n",
            "tensor(0.0049)\n",
            "tensor(0.0049)\n",
            "tensor(0.0049)\n",
            "tensor(0.0049)\n",
            "tensor(0.0049)\n",
            "tensor(0.0049)\n",
            "tensor(0.0049)\n",
            "tensor(0.0049)\n",
            "tensor(0.0049)\n",
            "tensor(0.0049)\n",
            "tensor(0.0049)\n",
            "tensor(0.0049)\n",
            "tensor(0.0049)\n",
            "tensor(0.0049)\n",
            "tensor(0.0049)\n",
            "tensor(0.0049)\n",
            "tensor(0.0049)\n",
            "tensor(0.0049)\n",
            "tensor(0.0049)\n",
            "tensor(0.0048)\n",
            "tensor(0.0048)\n",
            "tensor(0.0048)\n",
            "tensor(0.0048)\n",
            "tensor(0.0048)\n",
            "tensor(0.0048)\n",
            "tensor(0.0048)\n",
            "tensor(0.0048)\n",
            "tensor(0.0048)\n",
            "tensor(0.0048)\n",
            "tensor(0.0048)\n",
            "tensor(0.0048)\n",
            "tensor(0.0048)\n",
            "tensor(0.0048)\n",
            "tensor(0.0048)\n",
            "tensor(0.0048)\n",
            "tensor(0.0048)\n",
            "tensor(0.0048)\n",
            "tensor(0.0048)\n",
            "tensor(0.0048)\n",
            "tensor(0.0048)\n",
            "tensor(0.0048)\n",
            "tensor(0.0048)\n",
            "tensor(0.0048)\n",
            "tensor(0.0048)\n",
            "tensor(0.0048)\n",
            "tensor(0.0048)\n",
            "tensor(0.0048)\n",
            "tensor(0.0048)\n",
            "tensor(0.0048)\n",
            "tensor(0.0048)\n",
            "tensor(0.0048)\n",
            "tensor(0.0048)\n",
            "tensor(0.0048)\n",
            "tensor(0.0048)\n",
            "tensor(0.0048)\n",
            "tensor(0.0047)\n",
            "tensor(0.0047)\n",
            "tensor(0.0047)\n",
            "tensor(0.0047)\n",
            "tensor(0.0047)\n",
            "tensor(0.0047)\n",
            "tensor(0.0047)\n",
            "tensor(0.0047)\n",
            "tensor(0.0047)\n",
            "tensor(0.0047)\n",
            "tensor(0.0047)\n",
            "tensor(0.0047)\n",
            "tensor(0.0047)\n",
            "tensor(0.0047)\n",
            "tensor(0.0047)\n",
            "tensor(0.0047)\n",
            "tensor(0.0047)\n",
            "tensor(0.0047)\n",
            "tensor(0.0047)\n",
            "tensor(0.0047)\n",
            "tensor(0.0047)\n",
            "tensor(0.0047)\n",
            "tensor(0.0047)\n",
            "tensor(0.0047)\n",
            "tensor(0.0047)\n",
            "tensor(0.0047)\n",
            "tensor(0.0047)\n",
            "tensor(0.0047)\n",
            "tensor(0.0047)\n",
            "tensor(0.0047)\n",
            "tensor(0.0047)\n",
            "tensor(0.0047)\n",
            "tensor(0.0047)\n",
            "tensor(0.0047)\n",
            "tensor(0.0047)\n",
            "tensor(0.0047)\n",
            "tensor(0.0047)\n",
            "tensor(0.0047)\n",
            "tensor(0.0046)\n",
            "tensor(0.0046)\n",
            "tensor(0.0046)\n",
            "tensor(0.0046)\n",
            "tensor(0.0046)\n",
            "tensor(0.0046)\n",
            "tensor(0.0046)\n",
            "tensor(0.0046)\n",
            "tensor(0.0046)\n",
            "tensor(0.0046)\n",
            "tensor(0.0046)\n",
            "tensor(0.0046)\n",
            "tensor(0.0046)\n",
            "tensor(0.0046)\n",
            "tensor(0.0046)\n",
            "tensor(0.0046)\n",
            "tensor(0.0046)\n",
            "tensor(0.0046)\n",
            "tensor(0.0046)\n",
            "tensor(0.0046)\n",
            "tensor(0.0046)\n",
            "tensor(0.0046)\n",
            "tensor(0.0046)\n",
            "tensor(0.0046)\n",
            "tensor(0.0046)\n",
            "tensor(0.0046)\n",
            "tensor(0.0046)\n",
            "tensor(0.0046)\n",
            "tensor(0.0046)\n",
            "tensor(0.0046)\n",
            "tensor(0.0046)\n",
            "tensor(0.0046)\n",
            "tensor(0.0046)\n",
            "tensor(0.0046)\n",
            "tensor(0.0046)\n",
            "tensor(0.0046)\n",
            "tensor(0.0046)\n",
            "tensor(0.0046)\n",
            "tensor(0.0046)\n",
            "tensor(0.0046)\n",
            "tensor(0.0045)\n",
            "tensor(0.0045)\n",
            "tensor(0.0045)\n",
            "tensor(0.0045)\n",
            "tensor(0.0045)\n",
            "tensor(0.0045)\n",
            "tensor(0.0045)\n",
            "tensor(0.0045)\n",
            "tensor(0.0045)\n",
            "tensor(0.0045)\n",
            "tensor(0.0045)\n",
            "tensor(0.0045)\n",
            "tensor(0.0045)\n",
            "tensor(0.0045)\n",
            "tensor(0.0045)\n",
            "tensor(0.0045)\n",
            "tensor(0.0045)\n",
            "tensor(0.0045)\n",
            "tensor(0.0045)\n",
            "tensor(0.0045)\n",
            "tensor(0.0045)\n",
            "tensor(0.0045)\n",
            "tensor(0.0045)\n",
            "tensor(0.0045)\n",
            "tensor(0.0045)\n",
            "tensor(0.0045)\n",
            "tensor(0.0045)\n",
            "tensor(0.0045)\n",
            "tensor(0.0045)\n",
            "tensor(0.0045)\n",
            "tensor(0.0045)\n",
            "tensor(0.0045)\n",
            "tensor(0.0045)\n",
            "tensor(0.0045)\n",
            "tensor(0.0045)\n",
            "tensor(0.0045)\n",
            "tensor(0.0045)\n",
            "tensor(0.0045)\n",
            "tensor(0.0045)\n",
            "tensor(0.0045)\n",
            "tensor(0.0045)\n",
            "tensor(0.0044)\n",
            "tensor(0.0044)\n",
            "tensor(0.0044)\n",
            "tensor(0.0044)\n",
            "tensor(0.0044)\n",
            "tensor(0.0044)\n",
            "tensor(0.0044)\n",
            "tensor(0.0044)\n",
            "tensor(0.0044)\n",
            "tensor(0.0044)\n",
            "tensor(0.0044)\n",
            "tensor(0.0044)\n",
            "tensor(0.0044)\n",
            "tensor(0.0044)\n",
            "tensor(0.0044)\n",
            "tensor(0.0044)\n",
            "tensor(0.0044)\n",
            "tensor(0.0044)\n",
            "tensor(0.0044)\n",
            "tensor(0.0044)\n",
            "tensor(0.0044)\n",
            "tensor(0.0044)\n",
            "tensor(0.0044)\n",
            "tensor(0.0044)\n",
            "tensor(0.0044)\n",
            "tensor(0.0044)\n",
            "tensor(0.0044)\n",
            "tensor(0.0044)\n",
            "tensor(0.0044)\n",
            "tensor(0.0044)\n",
            "tensor(0.0044)\n",
            "tensor(0.0044)\n",
            "tensor(0.0044)\n",
            "tensor(0.0044)\n",
            "tensor(0.0044)\n",
            "tensor(0.0044)\n",
            "tensor(0.0044)\n",
            "tensor(0.0044)\n",
            "tensor(0.0044)\n",
            "tensor(0.0044)\n",
            "tensor(0.0044)\n",
            "tensor(0.0044)\n",
            "tensor(0.0044)\n",
            "tensor(0.0043)\n",
            "tensor(0.0043)\n",
            "tensor(0.0043)\n",
            "tensor(0.0043)\n",
            "tensor(0.0043)\n",
            "tensor(0.0043)\n",
            "tensor(0.0043)\n",
            "tensor(0.0043)\n",
            "tensor(0.0043)\n",
            "tensor(0.0043)\n",
            "tensor(0.0043)\n",
            "tensor(0.0043)\n",
            "tensor(0.0043)\n",
            "tensor(0.0043)\n",
            "tensor(0.0043)\n",
            "tensor(0.0043)\n",
            "tensor(0.0043)\n",
            "tensor(0.0043)\n",
            "tensor(0.0043)\n",
            "tensor(0.0043)\n",
            "tensor(0.0043)\n",
            "tensor(0.0043)\n",
            "tensor(0.0043)\n",
            "tensor(0.0043)\n",
            "tensor(0.0043)\n",
            "tensor(0.0043)\n",
            "tensor(0.0043)\n",
            "tensor(0.0043)\n",
            "tensor(0.0043)\n",
            "tensor(0.0043)\n",
            "tensor(0.0043)\n",
            "tensor(0.0043)\n",
            "tensor(0.0043)\n",
            "tensor(0.0043)\n",
            "tensor(0.0043)\n",
            "tensor(0.0043)\n",
            "tensor(0.0043)\n",
            "tensor(0.0043)\n",
            "tensor(0.0043)\n",
            "tensor(0.0043)\n",
            "tensor(0.0043)\n",
            "tensor(0.0043)\n",
            "tensor(0.0043)\n",
            "tensor(0.0043)\n",
            "tensor(0.0043)\n",
            "tensor(0.0042)\n",
            "tensor(0.0042)\n",
            "tensor(0.0042)\n",
            "tensor(0.0042)\n",
            "tensor(0.0042)\n",
            "tensor(0.0042)\n",
            "tensor(0.0042)\n",
            "tensor(0.0042)\n",
            "tensor(0.0042)\n",
            "tensor(0.0042)\n",
            "tensor(0.0042)\n",
            "tensor(0.0042)\n",
            "tensor(0.0042)\n",
            "tensor(0.0042)\n",
            "tensor(0.0042)\n",
            "tensor(0.0042)\n",
            "tensor(0.0042)\n",
            "tensor(0.0042)\n",
            "tensor(0.0042)\n",
            "tensor(0.0042)\n",
            "tensor(0.0042)\n",
            "tensor(0.0042)\n",
            "tensor(0.0042)\n",
            "tensor(0.0042)\n",
            "tensor(0.0042)\n",
            "tensor(0.0042)\n",
            "tensor(0.0042)\n",
            "tensor(0.0042)\n",
            "tensor(0.0042)\n",
            "tensor(0.0042)\n",
            "tensor(0.0042)\n",
            "tensor(0.0042)\n",
            "tensor(0.0042)\n",
            "tensor(0.0042)\n",
            "tensor(0.0042)\n",
            "tensor(0.0042)\n",
            "tensor(0.0042)\n",
            "tensor(0.0042)\n",
            "tensor(0.0042)\n",
            "tensor(0.0042)\n",
            "tensor(0.0042)\n",
            "tensor(0.0042)\n",
            "tensor(0.0042)\n",
            "tensor(0.0042)\n",
            "tensor(0.0042)\n",
            "tensor(0.0042)\n",
            "tensor(0.0042)\n",
            "tensor(0.0041)\n",
            "tensor(0.0041)\n",
            "tensor(0.0041)\n",
            "tensor(0.0041)\n",
            "tensor(0.0041)\n",
            "tensor(0.0041)\n",
            "tensor(0.0041)\n",
            "tensor(0.0041)\n",
            "tensor(0.0041)\n",
            "tensor(0.0041)\n",
            "tensor(0.0041)\n",
            "tensor(0.0041)\n",
            "tensor(0.0041)\n",
            "tensor(0.0041)\n",
            "tensor(0.0041)\n",
            "tensor(0.0041)\n",
            "tensor(0.0041)\n",
            "tensor(0.0041)\n",
            "tensor(0.0041)\n",
            "tensor(0.0041)\n",
            "tensor(0.0041)\n",
            "tensor(0.0041)\n",
            "tensor(0.0041)\n",
            "tensor(0.0041)\n",
            "tensor(0.0041)\n",
            "tensor(0.0041)\n",
            "tensor(0.0041)\n",
            "tensor(0.0041)\n",
            "tensor(0.0041)\n",
            "tensor(0.0041)\n",
            "tensor(0.0041)\n",
            "tensor(0.0041)\n",
            "tensor(0.0041)\n",
            "tensor(0.0041)\n",
            "tensor(0.0041)\n",
            "tensor(0.0041)\n",
            "tensor(0.0041)\n",
            "tensor(0.0041)\n",
            "tensor(0.0041)\n",
            "tensor(0.0041)\n",
            "tensor(0.0041)\n",
            "tensor(0.0041)\n",
            "tensor(0.0041)\n",
            "tensor(0.0041)\n",
            "tensor(0.0041)\n",
            "tensor(0.0041)\n",
            "tensor(0.0041)\n",
            "tensor(0.0041)\n",
            "tensor(0.0041)\n",
            "tensor(0.0040)\n",
            "tensor(0.0040)\n",
            "tensor(0.0040)\n",
            "tensor(0.0040)\n",
            "tensor(0.0040)\n",
            "tensor(0.0040)\n",
            "tensor(0.0040)\n",
            "tensor(0.0040)\n",
            "tensor(0.0040)\n",
            "tensor(0.0040)\n",
            "tensor(0.0040)\n",
            "tensor(0.0040)\n",
            "tensor(0.0040)\n",
            "tensor(0.0040)\n",
            "tensor(0.0040)\n",
            "tensor(0.0040)\n",
            "tensor(0.0040)\n",
            "tensor(0.0040)\n",
            "tensor(0.0040)\n",
            "tensor(0.0040)\n",
            "tensor(0.0040)\n",
            "tensor(0.0040)\n",
            "tensor(0.0040)\n",
            "tensor(0.0040)\n",
            "tensor(0.0040)\n",
            "tensor(0.0040)\n",
            "tensor(0.0040)\n",
            "tensor(0.0040)\n",
            "tensor(0.0040)\n",
            "tensor(0.0040)\n",
            "tensor(0.0040)\n",
            "tensor(0.0040)\n",
            "tensor(0.0040)\n",
            "tensor(0.0040)\n",
            "tensor(0.0040)\n",
            "tensor(0.0040)\n",
            "tensor(0.0040)\n",
            "tensor(0.0040)\n",
            "tensor(0.0040)\n",
            "tensor(0.0040)\n",
            "tensor(0.0040)\n",
            "tensor(0.0040)\n",
            "tensor(0.0040)\n",
            "tensor(0.0040)\n",
            "tensor(0.0040)\n",
            "tensor(0.0040)\n",
            "tensor(0.0040)\n",
            "tensor(0.0040)\n",
            "tensor(0.0040)\n",
            "tensor(0.0040)\n",
            "tensor(0.0040)\n",
            "tensor(0.0039)\n",
            "tensor(0.0039)\n",
            "tensor(0.0039)\n",
            "tensor(0.0039)\n",
            "tensor(0.0039)\n",
            "tensor(0.0039)\n",
            "tensor(0.0039)\n",
            "tensor(0.0039)\n",
            "tensor(0.0039)\n",
            "tensor(0.0039)\n",
            "tensor(0.0039)\n",
            "tensor(0.0039)\n",
            "tensor(0.0039)\n",
            "tensor(0.0039)\n",
            "tensor(0.0039)\n",
            "tensor(0.0039)\n",
            "tensor(0.0039)\n",
            "tensor(0.0039)\n",
            "tensor(0.0039)\n",
            "tensor(0.0039)\n",
            "tensor(0.0039)\n",
            "tensor(0.0039)\n",
            "tensor(0.0039)\n",
            "tensor(0.0039)\n",
            "tensor(0.0039)\n",
            "tensor(0.0039)\n",
            "tensor(0.0039)\n",
            "tensor(0.0039)\n",
            "tensor(0.0039)\n",
            "tensor(0.0039)\n",
            "tensor(0.0039)\n",
            "tensor(0.0039)\n",
            "tensor(0.0039)\n",
            "tensor(0.0039)\n",
            "tensor(0.0039)\n",
            "tensor(0.0039)\n",
            "tensor(0.0039)\n",
            "tensor(0.0039)\n",
            "tensor(0.0039)\n",
            "tensor(0.0039)\n",
            "tensor(0.0039)\n",
            "tensor(0.0039)\n",
            "tensor(0.0039)\n",
            "tensor(0.0039)\n",
            "tensor(0.0039)\n",
            "tensor(0.0039)\n",
            "tensor(0.0039)\n",
            "tensor(0.0039)\n",
            "tensor(0.0039)\n",
            "tensor(0.0039)\n",
            "tensor(0.0039)\n",
            "tensor(0.0039)\n",
            "tensor(0.0039)\n",
            "tensor(0.0039)\n",
            "tensor(0.0038)\n",
            "tensor(0.0038)\n",
            "tensor(0.0038)\n",
            "tensor(0.0038)\n",
            "tensor(0.0038)\n",
            "tensor(0.0038)\n",
            "tensor(0.0038)\n",
            "tensor(0.0038)\n",
            "tensor(0.0038)\n",
            "tensor(0.0038)\n",
            "tensor(0.0038)\n",
            "tensor(0.0038)\n",
            "tensor(0.0038)\n",
            "tensor(0.0038)\n",
            "tensor(0.0038)\n",
            "tensor(0.0038)\n",
            "tensor(0.0038)\n",
            "tensor(0.0038)\n",
            "tensor(0.0038)\n",
            "tensor(0.0038)\n",
            "tensor(0.0038)\n",
            "tensor(0.0038)\n",
            "tensor(0.0038)\n",
            "tensor(0.0038)\n",
            "tensor(0.0038)\n",
            "tensor(0.0038)\n",
            "tensor(0.0038)\n",
            "tensor(0.0038)\n",
            "tensor(0.0038)\n",
            "tensor(0.0038)\n",
            "tensor(0.0038)\n",
            "tensor(0.0038)\n",
            "tensor(0.0038)\n",
            "tensor(0.0038)\n",
            "tensor(0.0038)\n",
            "tensor(0.0038)\n",
            "tensor(0.0038)\n",
            "tensor(0.0038)\n",
            "tensor(0.0038)\n",
            "tensor(0.0038)\n",
            "tensor(0.0038)\n",
            "tensor(0.0038)\n",
            "tensor(0.0038)\n",
            "tensor(0.0038)\n",
            "tensor(0.0038)\n",
            "tensor(0.0038)\n",
            "tensor(0.0038)\n",
            "tensor(0.0038)\n",
            "tensor(0.0038)\n",
            "tensor(0.0038)\n",
            "tensor(0.0038)\n",
            "tensor(0.0038)\n",
            "tensor(0.0038)\n",
            "tensor(0.0038)\n",
            "tensor(0.0038)\n",
            "tensor(0.0038)\n",
            "tensor(0.0038)\n",
            "tensor(0.0037)\n",
            "tensor(0.0037)\n",
            "tensor(0.0037)\n",
            "tensor(0.0037)\n",
            "tensor(0.0037)\n",
            "tensor(0.0037)\n",
            "tensor(0.0037)\n",
            "tensor(0.0037)\n",
            "tensor(0.0037)\n",
            "tensor(0.0037)\n",
            "tensor(0.0037)\n",
            "tensor(0.0037)\n",
            "tensor(0.0037)\n",
            "tensor(0.0037)\n",
            "tensor(0.0037)\n",
            "tensor(0.0037)\n",
            "tensor(0.0037)\n",
            "tensor(0.0037)\n",
            "tensor(0.0037)\n",
            "tensor(0.0037)\n",
            "tensor(0.0037)\n",
            "tensor(0.0037)\n",
            "tensor(0.0037)\n",
            "tensor(0.0037)\n",
            "tensor(0.0037)\n",
            "tensor(0.0037)\n",
            "tensor(0.0037)\n",
            "tensor(0.0037)\n",
            "tensor(0.0037)\n",
            "tensor(0.0037)\n",
            "tensor(0.0037)\n",
            "tensor(0.0037)\n",
            "tensor(0.0037)\n",
            "tensor(0.0037)\n",
            "tensor(0.0037)\n",
            "tensor(0.0037)\n",
            "tensor(0.0037)\n",
            "tensor(0.0037)\n",
            "tensor(0.0037)\n",
            "tensor(0.0037)\n",
            "tensor(0.0037)\n",
            "tensor(0.0037)\n",
            "tensor(0.0037)\n",
            "tensor(0.0037)\n",
            "tensor(0.0037)\n",
            "tensor(0.0037)\n",
            "tensor(0.0037)\n",
            "tensor(0.0037)\n",
            "tensor(0.0037)\n",
            "tensor(0.0037)\n",
            "tensor(0.0037)\n",
            "tensor(0.0037)\n",
            "tensor(0.0037)\n",
            "tensor(0.0037)\n",
            "tensor(0.0037)\n",
            "tensor(0.0037)\n",
            "tensor(0.0037)\n",
            "tensor(0.0037)\n",
            "tensor(0.0037)\n",
            "tensor(0.0037)\n",
            "tensor(0.0036)\n",
            "tensor(0.0036)\n",
            "tensor(0.0036)\n",
            "tensor(0.0036)\n",
            "tensor(0.0036)\n",
            "tensor(0.0036)\n",
            "tensor(0.0036)\n",
            "tensor(0.0036)\n",
            "tensor(0.0036)\n",
            "tensor(0.0036)\n",
            "tensor(0.0036)\n",
            "tensor(0.0036)\n",
            "tensor(0.0036)\n",
            "tensor(0.0036)\n",
            "tensor(0.0036)\n",
            "tensor(0.0036)\n",
            "tensor(0.0036)\n",
            "tensor(0.0036)\n",
            "tensor(0.0036)\n",
            "tensor(0.0036)\n",
            "tensor(0.0036)\n",
            "tensor(0.0036)\n",
            "tensor(0.0036)\n",
            "tensor(0.0036)\n",
            "tensor(0.0036)\n",
            "tensor(0.0036)\n",
            "tensor(0.0036)\n",
            "tensor(0.0036)\n",
            "tensor(0.0036)\n",
            "tensor(0.0036)\n",
            "tensor(0.0036)\n",
            "tensor(0.0036)\n",
            "tensor(0.0036)\n",
            "tensor(0.0036)\n",
            "tensor(0.0036)\n",
            "tensor(0.0036)\n",
            "tensor(0.0036)\n",
            "tensor(0.0036)\n",
            "tensor(0.0036)\n",
            "tensor(0.0036)\n",
            "tensor(0.0036)\n",
            "tensor(0.0036)\n",
            "tensor(0.0036)\n",
            "tensor(0.0036)\n",
            "tensor(0.0036)\n",
            "tensor(0.0036)\n",
            "tensor(0.0036)\n",
            "tensor(0.0036)\n",
            "tensor(0.0036)\n",
            "tensor(0.0036)\n",
            "tensor(0.0036)\n",
            "tensor(0.0036)\n",
            "tensor(0.0036)\n",
            "tensor(0.0036)\n",
            "tensor(0.0036)\n",
            "tensor(0.0036)\n",
            "tensor(0.0036)\n",
            "tensor(0.0036)\n",
            "tensor(0.0036)\n",
            "tensor(0.0036)\n",
            "tensor(0.0036)\n",
            "tensor(0.0036)\n",
            "tensor(0.0035)\n",
            "tensor(0.0035)\n",
            "tensor(0.0035)\n",
            "tensor(0.0035)\n",
            "tensor(0.0035)\n",
            "tensor(0.0035)\n",
            "tensor(0.0035)\n",
            "tensor(0.0035)\n",
            "tensor(0.0035)\n",
            "tensor(0.0035)\n",
            "tensor(0.0035)\n",
            "tensor(0.0035)\n",
            "tensor(0.0035)\n",
            "tensor(0.0035)\n",
            "tensor(0.0035)\n",
            "tensor(0.0035)\n",
            "tensor(0.0035)\n",
            "tensor(0.0035)\n",
            "tensor(0.0035)\n",
            "tensor(0.0035)\n",
            "tensor(0.0035)\n",
            "tensor(0.0035)\n",
            "tensor(0.0035)\n",
            "tensor(0.0035)\n",
            "tensor(0.0035)\n",
            "tensor(0.0035)\n",
            "tensor(0.0035)\n",
            "tensor(0.0035)\n",
            "tensor(0.0035)\n",
            "tensor(0.0035)\n",
            "tensor(0.0035)\n",
            "tensor(0.0035)\n",
            "tensor(0.0035)\n",
            "tensor(0.0035)\n",
            "tensor(0.0035)\n",
            "tensor(0.0035)\n",
            "tensor(0.0035)\n",
            "tensor(0.0035)\n",
            "tensor(0.0035)\n",
            "tensor(0.0035)\n",
            "tensor(0.0035)\n",
            "tensor(0.0035)\n",
            "tensor(0.0035)\n",
            "tensor(0.0035)\n",
            "tensor(0.0035)\n",
            "tensor(0.0035)\n",
            "tensor(0.0035)\n",
            "tensor(0.0035)\n",
            "tensor(0.0035)\n",
            "tensor(0.0035)\n",
            "tensor(0.0035)\n",
            "tensor(0.0035)\n",
            "tensor(0.0035)\n",
            "tensor(0.0035)\n",
            "tensor(0.0035)\n",
            "tensor(0.0035)\n",
            "tensor(0.0035)\n",
            "tensor(0.0035)\n",
            "tensor(0.0035)\n",
            "tensor(0.0035)\n",
            "tensor(0.0035)\n",
            "tensor(0.0035)\n",
            "tensor(0.0035)\n",
            "tensor(0.0035)\n",
            "tensor(0.0035)\n",
            "tensor(0.0035)\n",
            "tensor(0.0035)\n",
            "tensor(0.0034)\n",
            "tensor(0.0034)\n",
            "tensor(0.0034)\n",
            "tensor(0.0034)\n",
            "tensor(0.0034)\n",
            "tensor(0.0034)\n",
            "tensor(0.0034)\n",
            "tensor(0.0034)\n",
            "tensor(0.0034)\n",
            "tensor(0.0034)\n",
            "tensor(0.0034)\n",
            "tensor(0.0034)\n",
            "tensor(0.0034)\n",
            "tensor(0.0034)\n",
            "tensor(0.0034)\n",
            "tensor(0.0034)\n",
            "tensor(0.0034)\n",
            "tensor(0.0034)\n",
            "tensor(0.0034)\n",
            "tensor(0.0034)\n",
            "tensor(0.0034)\n",
            "tensor(0.0034)\n",
            "tensor(0.0034)\n",
            "tensor(0.0034)\n",
            "tensor(0.0034)\n",
            "tensor(0.0034)\n",
            "tensor(0.0034)\n",
            "tensor(0.0034)\n",
            "tensor(0.0034)\n",
            "tensor(0.0034)\n",
            "tensor(0.0034)\n",
            "tensor(0.0034)\n",
            "tensor(0.0034)\n",
            "tensor(0.0034)\n",
            "tensor(0.0034)\n",
            "tensor(0.0034)\n",
            "tensor(0.0034)\n",
            "tensor(0.0034)\n",
            "tensor(0.0034)\n",
            "tensor(0.0034)\n",
            "tensor(0.0034)\n",
            "tensor(0.0034)\n",
            "tensor(0.0034)\n",
            "tensor(0.0034)\n",
            "tensor(0.0034)\n",
            "tensor(0.0034)\n",
            "tensor(0.0034)\n",
            "tensor(0.0034)\n",
            "tensor(0.0034)\n",
            "tensor(0.0034)\n",
            "tensor(0.0034)\n",
            "tensor(0.0034)\n",
            "tensor(0.0034)\n",
            "tensor(0.0034)\n",
            "tensor(0.0034)\n",
            "tensor(0.0034)\n",
            "tensor(0.0034)\n",
            "tensor(0.0034)\n",
            "tensor(0.0034)\n",
            "tensor(0.0034)\n",
            "tensor(0.0034)\n",
            "tensor(0.0034)\n",
            "tensor(0.0034)\n",
            "tensor(0.0034)\n",
            "tensor(0.0034)\n",
            "tensor(0.0034)\n",
            "tensor(0.0034)\n",
            "tensor(0.0034)\n",
            "tensor(0.0034)\n",
            "tensor(0.0034)\n",
            "tensor(0.0033)\n",
            "tensor(0.0033)\n",
            "tensor(0.0033)\n",
            "tensor(0.0033)\n",
            "tensor(0.0033)\n",
            "tensor(0.0033)\n",
            "tensor(0.0033)\n",
            "tensor(0.0033)\n",
            "tensor(0.0033)\n",
            "tensor(0.0033)\n",
            "tensor(0.0033)\n",
            "tensor(0.0033)\n",
            "tensor(0.0033)\n",
            "tensor(0.0033)\n",
            "tensor(0.0033)\n",
            "tensor(0.0033)\n",
            "tensor(0.0033)\n",
            "tensor(0.0033)\n",
            "tensor(0.0033)\n",
            "tensor(0.0033)\n",
            "tensor(0.0033)\n",
            "tensor(0.0033)\n",
            "tensor(0.0033)\n",
            "tensor(0.0033)\n",
            "tensor(0.0033)\n",
            "tensor(0.0033)\n",
            "tensor(0.0033)\n",
            "tensor(0.0033)\n",
            "tensor(0.0033)\n",
            "tensor(0.0033)\n",
            "tensor(0.0033)\n",
            "tensor(0.0033)\n",
            "tensor(0.0033)\n",
            "tensor(0.0033)\n",
            "tensor(0.0033)\n",
            "tensor(0.0033)\n",
            "tensor(0.0033)\n",
            "tensor(0.0033)\n",
            "tensor(0.0033)\n",
            "tensor(0.0033)\n",
            "tensor(0.0033)\n",
            "tensor(0.0033)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aiFklfHTWqgK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "out=out.get()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4J3ntBhMWqgM",
        "colab_type": "code",
        "outputId": "2efe68f2-9a56-42e9-bc7c-9c32282c066a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "out"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.9856],\n",
              "        [0.9885],\n",
              "        [0.0117],\n",
              "        [0.0176]], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 373
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-q8DAOB6Li53",
        "colab_type": "code",
        "outputId": "3542539e-d69a-466d-825c-133afc875d93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "w1.grad"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-2.0825e-03, -3.1833e-04, -1.2322e-04],\n",
              "        [ 2.9329e-03,  9.2790e-05, -2.7978e-05],\n",
              "        [-1.3097e-03, -2.7794e-04,  8.3252e-05],\n",
              "        [ 1.6909e-03,  4.8462e-05, -1.0258e-04],\n",
              "        [-1.5993e-03,  7.4773e-05, -1.7332e-04]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 283
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KXX1pVLOoQZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "out=out.get()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70X7p_NmYcAn",
        "colab_type": "code",
        "outputId": "fa2d83b7-65b9-419c-edd6-21307a92711d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "out"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.9966],\n",
              "        [0.9972],\n",
              "        [0.0029],\n",
              "        [0.0041]], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 377
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4GzlQfyZmRj",
        "colab_type": "code",
        "outputId": "dc2cff1a-fbec-4387-a592-29f2cb6c504c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "x=x.get()\n",
        "x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.6516,  0.6162,  1.0106,  1.3454,  0.2684],\n",
              "        [ 1.3804,  0.9218,  3.0091, -0.5988, -1.3014],\n",
              "        [ 0.8171, -1.1758, -0.1974,  0.0266,  0.5463],\n",
              "        [ 0.1135, -0.1423,  1.8862,  0.3520, -0.1075],\n",
              "        [ 0.1909, -0.3648, -0.3256,  0.7250, -0.5396],\n",
              "        [ 1.0933, -1.2085, -0.6667, -0.0858,  0.6897],\n",
              "        [ 0.0122,  1.4891, -0.2990, -1.0622,  0.6830],\n",
              "        [-2.4573, -1.1542,  0.2709, -1.5584,  0.6325],\n",
              "        [ 0.9898,  0.1380, -1.9752, -1.5378,  1.2027],\n",
              "        [-0.2116,  0.7338, -0.9320, -0.1794, -0.1203]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 286
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhwpltv0WqgP",
        "colab_type": "text"
      },
      "source": [
        "# Lesson: Garbage Collection and Common Errors\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cI7BOXIrWqgQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bob = bob.clear_objects()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCUsrKMoWqgR",
        "colab_type": "code",
        "outputId": "be8d813f-aa8d-4282-dc81-ab9fabf8e485",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "bob._objects"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 379
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOHRvhClWqgW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = th.tensor([1,2,3,4,5]).send(bob)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOYbQqGEWqgY",
        "colab_type": "code",
        "outputId": "0ba6a55a-8e16-4948-ee88-db6f39308139",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "bob._objects"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{76095677946: tensor([1, 2, 3, 4, 5])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 381
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9a0OTfyWqga",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-P_vj7NWqgc",
        "colab_type": "code",
        "outputId": "e5a34304-2071-439f-d022-5350f3bfbdb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "bob._objects"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 383
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h98ncOQPWqgd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = th.tensor([1,2,3,4,5]).send(bob)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2-Aib8MWqge",
        "colab_type": "code",
        "outputId": "1e685340-fe79-482c-b9c3-b5280f2df572",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "bob._objects"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{21999285274: tensor([1, 2, 3, 4, 5])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 385
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FoAyt1blWqgh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = \"asdf\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVI4MHnrWqgi",
        "colab_type": "code",
        "outputId": "cac5206f-3de2-446e-ca5f-517f56bc0324",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "bob._objects"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 387
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEL1ufACWqgl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = th.tensor([1,2,3,4,5]).send(bob)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huh4VjWjWqgm",
        "colab_type": "code",
        "outputId": "02344c0c-9957-4503-ede9-97cb9c9425f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Wrapper)>[PointerTensor | me:3420727541 -> bob:44765379635]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 389
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1llwV06Wqgr",
        "colab_type": "code",
        "outputId": "550e56b9-4aeb-4d31-deef-8aa42acb3676",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "bob._objects"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{44765379635: tensor([1, 2, 3, 4, 5])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 390
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9r73Vg3oWqgu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = \"asdf\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBpysb5mWqgv",
        "colab_type": "code",
        "outputId": "a3a5acdd-947e-4734-b1fc-aba3d70a728a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "bob._objects"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{44765379635: tensor([1, 2, 3, 4, 5])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 392
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSbc6V7iWqgx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GWfV8JlWqg0",
        "colab_type": "code",
        "outputId": "90fe42b7-30de-4e7a-bf53-7db98c66d258",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "bob._objects"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{44765379635: tensor([1, 2, 3, 4, 5])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 394
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YA_lYT0dWqg2",
        "colab_type": "code",
        "outputId": "57df6981-e866-4672-e991-f61ce45b6553",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "bob = bob.clear_objects()\n",
        "bob._objects"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 395
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sax15U1bWqg4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(1000):\n",
        "    x = th.tensor([1,2,3,4,5]).send(bob)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zWJygNqWqg5",
        "colab_type": "code",
        "outputId": "0143cd35-e747-453f-88a8-16944e795a7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "bob._objects"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{14018917294: tensor([1, 2, 3, 4, 5])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 397
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXqBhsTWWqg7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = th.tensor([1,2,3,4,5]).send(bob)\n",
        "y = th.tensor([1,1,1,1,1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZrT1xkYWqg8",
        "colab_type": "code",
        "outputId": "675471e7-15dd-4109-c704-99a66caefa58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        }
      },
      "source": [
        "z = x + y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TensorsNotCollocatedException",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPureTorchTensorFoundError\u001b[0m                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/hook/hook.py\u001b[0m in \u001b[0;36moverloaded_native_method\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    668\u001b[0m                     new_self, new_args, new_kwargs = syft.frameworks.torch.hook_args.hook_method_args(\n\u001b[0;32m--> 669\u001b[0;31m                         \u001b[0mmethod_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m                     )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/hook/hook_args.py\u001b[0m in \u001b[0;36mhook_method_args\u001b[0;34m(attr, method_self, args, kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;31m# Try running it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m         \u001b[0mnew_self\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod_self\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/hook/hook_args.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlambdas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/hook/hook_args.py\u001b[0m in \u001b[0;36mtwo_fold\u001b[0;34m(lambdas, args, **kwargs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtwo_fold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlambdas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlambdas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambdas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/hook/hook_args.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlambdas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/hook/hook_args.py\u001b[0m in \u001b[0;36mtuple_one_fold\u001b[0;34m(lambdas, args)\u001b[0m\n\u001b[1;32m    509\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtuple_one_fold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlambdas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlambdas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/hook/hook_args.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(i)\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;31m# Last if not, rule is probably == 1 so use type to return the right transformation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m         \u001b[0;32melse\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mforward_func\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrules\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# And do this for all the args / rules provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/hook/hook_args.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(i)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"child\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPureTorchTensorFoundError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParameter\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/hook/hook_args.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"child\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPureTorchTensorFoundError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParameter\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mPureTorchTensorFoundError\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTensorsNotCollocatedException\u001b[0m             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-399-8c8f78e0676d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/hook/hook.py\u001b[0m in \u001b[0;36moverloaded_native_method\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    671\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m                     \u001b[0;31m# we can make some errors more descriptive with this method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mroute_method_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m                 \u001b[0;31m# Send the new command to the appropriate class and get the response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTensorsNotCollocatedException\u001b[0m: You tried to call a method involving two tensors where one tensor is actually located on another machine (is a PointerTensor). Call .get() on the PointerTensor or .send(bob) on the other tensor.\n\nTensor A: [PointerTensor | me:95304086509 -> bob:8869619624]\nTensor B: tensor([1, 1, 1, 1, 1])"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2cRxzAJWqg-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = th.tensor([1,2,3,4,5]).send(bob)\n",
        "y = th.tensor([1,1,1,1,1]).send(alice)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJKs4grbWqhA",
        "colab_type": "code",
        "outputId": "f366b9bc-f5de-4fa9-e065-c0f625981f9e",
        "colab": {}
      },
      "source": [
        "z = x + y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TensorsNotCollocatedException",
          "evalue": "You tried to call a method involving two tensors where one tensor is actually locatedon another machine (is a PointerTensor). Call .get() on the PointerTensor or .send(bob) on the other tensor.\n\nTensor A: [PointerTensor | me:46419059800 -> bob:14412738960]\nTensor B: tensor([1, 1, 1, 1, 1])",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPureTorchTensorFoundError\u001b[0m                 Traceback (most recent call last)",
            "\u001b[0;32m/Users/atrask/anaconda/lib/python3.6/site-packages/syft-0.1.2a1-py3.6.egg/syft/frameworks/torch/hook.py\u001b[0m in \u001b[0;36moverloaded_native_method\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    561\u001b[0m                     new_self, new_args = syft.frameworks.torch.hook_args.hook_method_args(\n\u001b[0;32m--> 562\u001b[0;31m                         \u001b[0mmethod_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m                     )\n",
            "\u001b[0;32m/Users/atrask/anaconda/lib/python3.6/site-packages/syft-0.1.2a1-py3.6.egg/syft/frameworks/torch/hook_args.py\u001b[0m in \u001b[0;36mhook_method_args\u001b[0;34m(attr, method_self, args)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;31m# Try running it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mnew_self\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod_self\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/Users/atrask/anaconda/lib/python3.6/site-packages/syft-0.1.2a1-py3.6.egg/syft/frameworks/torch/hook_args.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlambdas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/Users/atrask/anaconda/lib/python3.6/site-packages/syft-0.1.2a1-py3.6.egg/syft/frameworks/torch/hook_args.py\u001b[0m in \u001b[0;36mtwo_fold\u001b[0;34m(lambdas, args)\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtwo_fold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlambdas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlambdas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambdas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/Users/atrask/anaconda/lib/python3.6/site-packages/syft-0.1.2a1-py3.6.egg/syft/frameworks/torch/hook_args.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlambdas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/Users/atrask/anaconda/lib/python3.6/site-packages/syft-0.1.2a1-py3.6.egg/syft/frameworks/torch/hook_args.py\u001b[0m in \u001b[0;36mtuple_one_fold\u001b[0;34m(lambdas, args)\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtuple_one_fold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlambdas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlambdas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/Users/atrask/anaconda/lib/python3.6/site-packages/syft-0.1.2a1-py3.6.egg/syft/frameworks/torch/hook_args.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(i)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;31m# Last if not, rule is probably == 1 so use type to return the right transformation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0;32melse\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mforward_func\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrules\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# And do this for all the args / rules provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/Users/atrask/anaconda/lib/python3.6/site-packages/syft-0.1.2a1-py3.6.egg/syft/frameworks/torch/hook_args.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(i)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"child\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPureTorchTensorFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParameter\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/Users/atrask/anaconda/lib/python3.6/site-packages/syft-0.1.2a1-py3.6.egg/syft/frameworks/torch/hook_args.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"child\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPureTorchTensorFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParameter\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mPureTorchTensorFoundError\u001b[0m: tensor([1, 1, 1, 1, 1])",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTensorsNotCollocatedException\u001b[0m             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-66-d63d93af9bc6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/Users/atrask/anaconda/lib/python3.6/site-packages/syft-0.1.2a1-py3.6.egg/syft/frameworks/torch/hook.py\u001b[0m in \u001b[0;36moverloaded_native_method\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    564\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m                     \u001b[0;31m# we can make some errors more descriptive with this method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mroute_method_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m                 \u001b[0;31m# Send the new command to the appropriate class and get the response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTensorsNotCollocatedException\u001b[0m: You tried to call a method involving two tensors where one tensor is actually locatedon another machine (is a PointerTensor). Call .get() on the PointerTensor or .send(bob) on the other tensor.\n\nTensor A: [PointerTensor | me:46419059800 -> bob:14412738960]\nTensor B: tensor([1, 1, 1, 1, 1])"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5oH9leO9WqhC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tltDkmfpWqhE",
        "colab_type": "text"
      },
      "source": [
        "# Lesson: Toy Federated Learning\n",
        "\n",
        "Let's start by training a toy model the centralized way. This is about a simple as models get. We first need:\n",
        "\n",
        "- a toy dataset\n",
        "- a model\n",
        "- some basic training logic for training a model to fit the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2hl-L6GWqhF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch import nn, optim\n",
        "import torch as th"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkK3rD84WqhG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A Toy Dataset\n",
        "data = th.tensor([[1.,1],[0,1],[1,0],[0,0]], requires_grad=True)\n",
        "target = th.tensor([[1.],[1], [0], [0]], requires_grad=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1n__wTFfWqhH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A Toy Model\n",
        "model = nn.Linear(2,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZgDdNAIWqhI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt = optim.SGD(params=model.parameters(), lr=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Df6XeDEsWqhL",
        "colab_type": "code",
        "outputId": "3454d5f7-c407-414f-c37a-23b6cb12bf45",
        "colab": {}
      },
      "source": [
        "def train(iterations=20):\n",
        "    for iter in range(iterations):\n",
        "        opt.zero_grad()\n",
        "\n",
        "        pred = model(data)\n",
        "\n",
        "        loss = ((pred - target)**2).sum()\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        opt.step()\n",
        "\n",
        "        print(loss.data)\n",
        "        \n",
        "train()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.0860)\n",
            "tensor(0.0586)\n",
            "tensor(0.0402)\n",
            "tensor(0.0278)\n",
            "tensor(0.0194)\n",
            "tensor(0.0136)\n",
            "tensor(0.0096)\n",
            "tensor(0.0069)\n",
            "tensor(0.0049)\n",
            "tensor(0.0036)\n",
            "tensor(0.0026)\n",
            "tensor(0.0019)\n",
            "tensor(0.0014)\n",
            "tensor(0.0010)\n",
            "tensor(0.0008)\n",
            "tensor(0.0006)\n",
            "tensor(0.0004)\n",
            "tensor(0.0003)\n",
            "tensor(0.0002)\n",
            "tensor(0.0002)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esGxrpqVWqhN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_bob = data[0:2].send(bob)\n",
        "target_bob = target[0:2].send(bob)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeCA7kp_WqhN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_alice = data[2:4].send(alice)\n",
        "target_alice = target[2:4].send(alice)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTyWubYDWqhQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datasets = [(data_bob, target_bob), (data_alice, target_alice)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2XFC2C5_50U",
        "colab_type": "code",
        "outputId": "d4dbb226-2e82-4b60-f75c-4cdb2720b65b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "bob"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<VirtualWorker id:bob #objects:5>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDPGG0jkWqhS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(iterations=20):\n",
        "\n",
        "    model = nn.Linear(2,1)\n",
        "    opt = optim.SGD(params=model.parameters(), lr=0.1)\n",
        "    \n",
        "    for iter in range(iterations):\n",
        "\n",
        "        for _data, _target in datasets:\n",
        "\n",
        "            # send model to the data\n",
        "            model = model.send(_data.location)\n",
        "\n",
        "            # do normal training\n",
        "            opt.zero_grad()\n",
        "            pred = model(_data)\n",
        "            loss = ((pred - _target)**2).sum()\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            model.move(bob)\n",
        "            model.weight.grad\n",
        "            # get smarter model back\n",
        "            model = model.get()\n",
        "\n",
        "            print(loss.get())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zl35prJgWqhT",
        "colab_type": "code",
        "outputId": "76e34826-e9be-4029-c758-be65df18bcfb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "source": [
        "\n",
        "train()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.6236, requires_grad=True)\n",
            "tensor(0.4768, requires_grad=True)\n",
            "tensor(0.2001, requires_grad=True)\n",
            "tensor(0.2951, requires_grad=True)\n",
            "tensor(0.1111, requires_grad=True)\n",
            "tensor(0.1768, requires_grad=True)\n",
            "tensor(0.0648, requires_grad=True)\n",
            "tensor(0.1062, requires_grad=True)\n",
            "tensor(0.0381, requires_grad=True)\n",
            "tensor(0.0642, requires_grad=True)\n",
            "tensor(0.0225, requires_grad=True)\n",
            "tensor(0.0390, requires_grad=True)\n",
            "tensor(0.0134, requires_grad=True)\n",
            "tensor(0.0239, requires_grad=True)\n",
            "tensor(0.0081, requires_grad=True)\n",
            "tensor(0.0148, requires_grad=True)\n",
            "tensor(0.0049, requires_grad=True)\n",
            "tensor(0.0093, requires_grad=True)\n",
            "tensor(0.0030, requires_grad=True)\n",
            "tensor(0.0058, requires_grad=True)\n",
            "tensor(0.0019, requires_grad=True)\n",
            "tensor(0.0037, requires_grad=True)\n",
            "tensor(0.0012, requires_grad=True)\n",
            "tensor(0.0024, requires_grad=True)\n",
            "tensor(0.0008, requires_grad=True)\n",
            "tensor(0.0016, requires_grad=True)\n",
            "tensor(0.0005, requires_grad=True)\n",
            "tensor(0.0010, requires_grad=True)\n",
            "tensor(0.0004, requires_grad=True)\n",
            "tensor(0.0007, requires_grad=True)\n",
            "tensor(0.0002, requires_grad=True)\n",
            "tensor(0.0005, requires_grad=True)\n",
            "tensor(0.0002, requires_grad=True)\n",
            "tensor(0.0003, requires_grad=True)\n",
            "tensor(0.0001, requires_grad=True)\n",
            "tensor(0.0002, requires_grad=True)\n",
            "tensor(8.7531e-05, requires_grad=True)\n",
            "tensor(0.0002, requires_grad=True)\n",
            "tensor(6.3603e-05, requires_grad=True)\n",
            "tensor(0.0001, requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhdMgXHuWqhU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdx2HypQWqhV",
        "colab_type": "text"
      },
      "source": [
        "# Lesson: Advanced Remote Execution Tools\n",
        "\n",
        "In the last section we trained a toy model using Federated Learning. We did this by calling .send() and .get() on our model, sending it to the location of training data, updating it, and then bringing it back. However, at the end of the example we realized that we needed to go a bit further to protect people privacy. Namely, we want to average the gradients BEFORE calling .get(). That way, we won't ever see anyone's exact gradient (thus better protecting their privacy!!!)\n",
        "\n",
        "But, in order to do this, we need a few more pieces:\n",
        "\n",
        "- use a pointer to send a Tensor directly to another worker\n",
        "\n",
        "And in addition, while we're here, we're going to learn about a few more advanced tensor operations as well which will help us both with this example and a few in the future!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFdYWquOWqhV",
        "colab_type": "code",
        "outputId": "496c431d-6acd-46ac-94d6-422e9c851cda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "bob.clear_objects()\n",
        "alice.clear_objects()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<VirtualWorker id:alice #objects:0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 410
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3i5IxLY7WqhW",
        "colab_type": "code",
        "outputId": "60ed9c47-300e-4a7b-8b9a-f2e75a964421",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<VirtualWorker id:alice #tensors:0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k75JPQRSWqhX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = th.tensor([1,2,3,4,5]).send(bob)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDgPc58uWqhY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = x.send(alice)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9jCtebRWqhZ",
        "colab_type": "code",
        "outputId": "fed64fba-3913-44a1-cc5b-75f0bc94f746",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "bob._objects"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{60919291280: tensor([1, 2, 3, 4, 5])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 413
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pWFSdgNWqha",
        "colab_type": "code",
        "outputId": "2856218c-f95b-4bb4-e1e4-085cb5dc4be3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "alice._objects"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{46793677354: (Wrapper)>[PointerTensor | alice:46793677354 -> bob:60919291280]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 415
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKAI96AnWqhb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = x + x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGMIZJQEWqhd",
        "colab_type": "code",
        "outputId": "650e2e0f-34e7-4c62-b33f-de00ceb8844e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Wrapper)>[PointerTensor | me:92538866869 -> alice:32871421246]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 417
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzdEcuziWqhe",
        "colab_type": "code",
        "outputId": "70fb8faf-1404-437e-975b-240c5f571c48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "bob._objects"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{60919291280: tensor([1, 2, 3, 4, 5]),\n",
              " 72123043838: tensor([ 2,  4,  6,  8, 10])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 418
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xb29thvpWqhf",
        "colab_type": "code",
        "outputId": "86f7d21f-bd4a-4724-b601-ac827f6ab8d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "alice._objects"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{32871421246: (Wrapper)>[PointerTensor | alice:32871421246 -> bob:72123043838],\n",
              " 46793677354: (Wrapper)>[PointerTensor | alice:46793677354 -> bob:60919291280]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 419
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQyW_kYoWqhh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "jon = sy.VirtualWorker(hook, id=\"jon\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4VN0TwHWqhi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bob.clear_objects()\n",
        "alice.clear_objects()\n",
        "\n",
        "x = th.tensor([1,2,3,4,5]).send(bob).send(alice)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2Uen7ZlWqhi",
        "colab_type": "code",
        "outputId": "7802aa70-47cd-4eb1-d1f7-5779eb981617",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "bob._objects"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{18160533154: tensor([1, 2, 3, 4, 5])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 422
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnK4_UrcWqhm",
        "colab_type": "code",
        "outputId": "4c15364c-a6ef-481f-c59e-73caffdea409",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "alice._objects"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{53783886866: (Wrapper)>[PointerTensor | alice:53783886866 -> bob:18160533154]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 423
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEHqjyxyWqhq",
        "colab_type": "code",
        "outputId": "82cb07f8-3ca7-4b5c-a8c5-3d1c2afdbfc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x = x.get()\n",
        "x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Wrapper)>[PointerTensor | me:53783886866 -> bob:18160533154]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 424
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfHy9Mr5Wqhv",
        "colab_type": "code",
        "outputId": "d5928da6-996d-47c0-c30d-14804503394d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "bob._objects"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{18160533154: tensor([1, 2, 3, 4, 5])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 425
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R57osix6Wqhx",
        "colab_type": "code",
        "outputId": "9025df1c-f321-4f99-c9de-7586fc00f475",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "alice._objects"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 426
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Da7Fql_kWqhy",
        "colab_type": "code",
        "outputId": "2334e841-cd8d-4846-ee4b-e0251c9b5c30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x = x.get()\n",
        "x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3, 4, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 427
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5MeQfqLWqhz",
        "colab_type": "code",
        "outputId": "644df29f-5aa7-40f7-a68e-54e90172972e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "bob._objects"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 428
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56U0-4WzWqh0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bob.clear_objects()\n",
        "alice.clear_objects()\n",
        "\n",
        "x = th.tensor([1,2,3,4,5]).send(bob).send(alice)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmE2ynU6Wqh2",
        "colab_type": "code",
        "outputId": "b231db44-c2e5-4cae-8a91-2dca500ebebb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "bob._objects"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{51514801886: tensor([1, 2, 3, 4, 5])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 430
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAmnb4L9Wqh4",
        "colab_type": "code",
        "outputId": "f203710c-8f5e-4ce1-fd19-c9b4d8119bb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "alice._objects"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{80795951581: (Wrapper)>[PointerTensor | alice:80795951581 -> bob:51514801886]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 431
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLVP4khhWqh5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNilAK0kWqh6",
        "colab_type": "code",
        "outputId": "91122621-75f8-4c4c-aa56-2c4bb76bd8df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "bob._objects"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 433
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpw3LPthWqh7",
        "colab_type": "code",
        "outputId": "03066e4e-0705-4186-c8f7-bb69ecd81b79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "alice._objects"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 434
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ry4dgtaAWqh-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dgttGgvWqiB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bc_25LQWqiC",
        "colab_type": "text"
      },
      "source": [
        "# Lesson: Pointer Chain Operations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbqP_9q8WqiC",
        "colab_type": "code",
        "outputId": "d0fac578-7899-41e6-a3b3-70c41613a824",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "bob.clear_objects()\n",
        "alice.clear_objects()\n",
        "jon.clear_objects()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<VirtualWorker id:jon #objects:0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 452
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxYGFiGdWqiE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = torch.tensor([1,2,3,4,5]).send(bob)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNi8VYMfWqiH",
        "colab_type": "code",
        "outputId": "1a8057c0-7663-4bdf-c147-2d0b4f518c77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<VirtualWorker id:bob #objects:3>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbnOdq4wWqiJ",
        "colab_type": "code",
        "outputId": "50424330-a3ae-4d99-844a-c27e88f1430f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "alice._objects"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 439
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhGJ1BTkWqiK",
        "colab_type": "code",
        "outputId": "fbf8adae-4223-4d0e-d025-5e20f3321fed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x.move(alice)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Wrapper)>[PointerTensor | me:54954175478 -> alice:54954175478]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 440
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSkSaxAYWqiL",
        "colab_type": "code",
        "outputId": "6184e20e-88f2-4fa9-eff0-33cd56c9858c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "bob._objects"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 441
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vB9Z-buXWqiN",
        "colab_type": "code",
        "outputId": "06266f08-3612-4c3e-c3a6-df60b477b616",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "alice._objects"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{54954175478: tensor([1, 2, 3, 4, 5])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 442
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdSkjjWrWqiQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14QmSsVpWqiR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = th.tensor([1,2,3,4,5]).send(bob).send(alice).send(jon)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-nJZpiHWqiS",
        "colab_type": "code",
        "outputId": "bec3f10e-e4b0-4837-9536-29e45756edac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "bob._objects"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{92897231289: tensor([1, 2, 3, 4, 5])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 454
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBgUCB7zWqiU",
        "colab_type": "code",
        "outputId": "8f83ba9b-d187-4636-d7fd-4884686352ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "alice._objects"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{19877040920: (Wrapper)>[PointerTensor | alice:19877040920 -> bob:92897231289]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 455
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZI7U6y2GWKjv",
        "colab_type": "code",
        "outputId": "b39ac4da-4d53-4524-9eb3-b0ecd884ada9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "jon._objects"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{17246609480: (Wrapper)>[PointerTensor | jon:17246609480 -> alice:19877040920]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 456
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIKFWKqAWhEP",
        "colab_type": "code",
        "outputId": "a97eab50-cded-4bc5-d871-a4693547030f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Wrapper)>[PointerTensor | me:87878937621 -> jon:17246609480]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 457
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1ozHYsyWqiW",
        "colab_type": "code",
        "outputId": "2c41be76-31ec-417b-be50-d656361ca67a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x.remote_get()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Wrapper)>[PointerTensor | me:87878937621 -> jon:17246609480]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 465
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znmlUdy_WqiX",
        "colab_type": "code",
        "outputId": "2f7f3537-9365-44da-9f31-854acf8b6304",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "bob._objects"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 466
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1oJtz_vWqiZ",
        "colab_type": "code",
        "outputId": "a90674ea-1bc1-498c-e931-dd79db20be33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "alice._objects"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 467
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wt_kOFUMWtIR",
        "colab_type": "code",
        "outputId": "4a6810ca-b94c-45ce-9424-5178deec53c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "jon._objects"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{17246609480: (Wrapper)>[PointerTensor | jon:17246609480 -> bob:92897231289]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 464
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzO1kv6aWqia",
        "colab_type": "code",
        "outputId": "b92ba3d2-d460-4a01-a305-e233de7cd410",
        "colab": {}
      },
      "source": [
        "x.move(bob)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Wrapper)>[PointerTensor | me:87205391815 -> bob:87205391815]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 208
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgP7Mp6CWqib",
        "colab_type": "code",
        "outputId": "22529af7-e730-4118-d30d-e98a2fdbea53",
        "colab": {}
      },
      "source": [
        "x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Wrapper)>[PointerTensor | me:87205391815 -> bob:87205391815]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 209
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4oDVp03Wqie",
        "colab_type": "code",
        "outputId": "e99ed2c8-1a6e-42a1-e88f-8a2a0ef81603",
        "colab": {}
      },
      "source": [
        "bob._objects"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{87205391815: tensor([1, 2, 3, 4, 5])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 210
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXKA27QcWqig",
        "colab_type": "code",
        "outputId": "c1e092dd-bebd-4674-d105-46a2ea1a7b1c",
        "colab": {}
      },
      "source": [
        "alice._objects"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{94092707138: tensor([1, 2, 3, 4, 5])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 211
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTCewGuumiF1",
        "colab_type": "code",
        "outputId": "4467a8e9-0030-4e8e-b1a8-7d9e4c139617",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install tf-encrypted\n",
        "\n",
        "! URL=\"https://github.com/openmined/PySyft.git\" && FOLDER=\"PySyft\" && if [ ! -d $FOLDER ]; then git clone -b dev --single-branch $URL; else (cd $FOLDER && git pull $URL && cd ..); fi;\n",
        "\n",
        "!cd PySyft; python setup.py install  > /dev/null\n",
        "\n",
        "import os\n",
        "import sys\n",
        "module_path = os.path.abspath(os.path.join('./PySyft'))\n",
        "if module_path not in sys.path:\n",
        "    sys.path.append(module_path)\n",
        "    \n",
        "!pip install --upgrade --force-reinstall lz4\n",
        "!pip install --upgrade --force-reinstall websocket\n",
        "!pip install --upgrade --force-reinstall websockets\n",
        "!pip install --upgrade --force-reinstall zstd"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tf-encrypted\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/55/ff/7dbd5fc77fcec0df1798268a6b72a2ab0150b854761bc39c77d566798f0b/tf_encrypted-0.5.7-py3-none-manylinux1_x86_64.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow<2,>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tf-encrypted) (1.14.0)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tf-encrypted) (1.16.4)\n",
            "Collecting pyyaml>=5.1 (from tf-encrypted)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/65/837fefac7475963d1eccf4aa684c23b95aa6c1d033a2c5965ccb11e22623/PyYAML-5.1.1.tar.gz (274kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 37.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted) (1.11.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted) (0.1.7)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted) (1.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted) (0.8.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted) (0.33.4)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted) (1.0.8)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted) (1.12.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted) (0.7.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted) (1.1.0)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted) (1.14.0)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted) (1.14.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted) (0.2.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted) (3.7.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow<2,>=1.12.0->tf-encrypted) (2.8.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow<2,>=1.12.0->tf-encrypted) (41.0.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow<2,>=1.12.0->tf-encrypted) (0.15.5)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow<2,>=1.12.0->tf-encrypted) (3.1.1)\n",
            "Building wheels for collected packages: pyyaml\n",
            "  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/16/27/a1/775c62ddea7bfa62324fd1f65847ed31c55dadb6051481ba3f\n",
            "Successfully built pyyaml\n",
            "Installing collected packages: pyyaml, tf-encrypted\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed pyyaml-5.1.1 tf-encrypted-0.5.7\n",
            "Cloning into 'PySyft'...\n",
            "remote: Enumerating objects: 28675, done.\u001b[K\n",
            "remote: Total 28675 (delta 0), reused 0 (delta 0), pack-reused 28675\u001b[K\n",
            "Receiving objects: 100% (28675/28675), 32.07 MiB | 19.74 MiB/s, done.\n",
            "Resolving deltas: 100% (19010/19010), done.\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "__pycache__.zstd.cpython-36: module references __file__\n",
            "Collecting lz4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0a/c6/96bbb3525a63ebc53ea700cc7d37ab9045542d33b4d262d0f0408ad9bbf2/lz4-2.1.10-cp36-cp36m-manylinux1_x86_64.whl (385kB)\n",
            "\u001b[K     |████████████████████████████████| 389kB 2.8MB/s \n",
            "\u001b[31mERROR: syft 0.1.21a1 has requirement msgpack>=0.6.1, but you'll have msgpack 0.5.6 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: syft 0.1.21a1 has requirement tf_encrypted!=0.5.7,>=0.5.4, but you'll have tf-encrypted 0.5.7 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lz4\n",
            "  Found existing installation: lz4 2.1.10\n",
            "    Uninstalling lz4-2.1.10:\n",
            "      Successfully uninstalled lz4-2.1.10\n",
            "Successfully installed lz4-2.1.10\n",
            "Collecting websocket\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f2/6d/a60d620ea575c885510c574909d2e3ed62129b121fa2df00ca1c81024c87/websocket-0.2.1.tar.gz (195kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 2.9MB/s \n",
            "\u001b[?25hCollecting gevent (from websocket)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f2/ca/5b5962361ed832847b6b2f9a2d0452c8c2f29a93baef850bb8ad067c7bf9/gevent-1.4.0-cp36-cp36m-manylinux1_x86_64.whl (5.5MB)\n",
            "\u001b[K     |████████████████████████████████| 5.5MB 38.0MB/s \n",
            "\u001b[?25hCollecting greenlet (from websocket)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bf/45/142141aa47e01a5779f0fa5a53b81f8379ce8f2b1cd13df7d2f1d751ae42/greenlet-0.4.15-cp36-cp36m-manylinux1_x86_64.whl (41kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 23.1MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: websocket\n",
            "  Building wheel for websocket (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/35/f7/5c/9e8243838269ea93f05295708519a6e183fa6b515d9ce3b636\n",
            "Successfully built websocket\n",
            "Installing collected packages: greenlet, gevent, websocket\n",
            "  Found existing installation: greenlet 0.4.15\n",
            "    Uninstalling greenlet-0.4.15:\n",
            "      Successfully uninstalled greenlet-0.4.15\n",
            "  Found existing installation: gevent 1.4.0\n",
            "    Uninstalling gevent-1.4.0:\n",
            "      Successfully uninstalled gevent-1.4.0\n",
            "Successfully installed gevent-1.4.0 greenlet-0.4.15 websocket-0.2.1\n",
            "Collecting websockets\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c1/d2/bf72435a7d56f94b57efdeae26c76bf0d16f409fd44ff595da745c3fbefd/websockets-8.0.1-cp36-cp36m-manylinux1_x86_64.whl (72kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 3.2MB/s \n",
            "\u001b[31mERROR: syft 0.1.21a1 has requirement msgpack>=0.6.1, but you'll have msgpack 0.5.6 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: syft 0.1.21a1 has requirement tf_encrypted!=0.5.7,>=0.5.4, but you'll have tf-encrypted 0.5.7 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: websockets\n",
            "  Found existing installation: websockets 8.0.1\n",
            "    Uninstalling websockets-8.0.1:\n",
            "      Successfully uninstalled websockets-8.0.1\n",
            "Successfully installed websockets-8.0.1\n",
            "Collecting zstd\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/37/6a7ba746ebddbd6cd06de84367515d6bc239acd94fb3e0b1c85788176ca2/zstd-1.4.1.0.tar.gz (454kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 2.8MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: zstd\n",
            "  Building wheel for zstd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/66/3f/ee/ac08c81af7c1b24a80c746df669ea3cb37542d27877d66ccf4\n",
            "Successfully built zstd\n",
            "\u001b[31mERROR: syft 0.1.21a1 has requirement msgpack>=0.6.1, but you'll have msgpack 0.5.6 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: syft 0.1.21a1 has requirement tf_encrypted!=0.5.7,>=0.5.4, but you'll have tf-encrypted 0.5.7 which is incompatible.\u001b[0m\n",
            "Installing collected packages: zstd\n",
            "  Found existing installation: zstd 1.4.1.0\n",
            "    Uninstalling zstd-1.4.1.0:\n",
            "      Successfully uninstalled zstd-1.4.1.0\n",
            "Successfully installed zstd-1.4.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7NlM4yRAS0P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "21b3f0e0-a2a1-4338-f97c-cee4886d14c7"
      },
      "source": [
        "!pip install pytorch==1.0.1"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch==1.0.1\n",
            "\u001b[31m  ERROR: Could not find a version that satisfies the requirement pytorch==1.0.1 (from versions: 0.1.2, 1.0.2)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for pytorch==1.0.1\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nx1x3cTUWqih",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import syft as sy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-frYVwLWqii",
        "colab_type": "code",
        "outputId": "d4434063-0297-4701-ed63-bb2fb1f3f496",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "\n",
        "hook = sy.TorchHook(torch)  \n",
        "bob = sy.VirtualWorker(hook, id=\"bob\")  \n",
        "alice = sy.VirtualWorker(hook, id=\"alice\")\n",
        "secure_worker=sy.VirtualWorker(hook, id=\"secure_worker\")\n",
        "bob.clear_objects()\n",
        "alice.clear_objects()\n",
        "secure_worker.clear_objects()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0722 09:28:38.812662 140642623997824 hook.py:98] Torch was already hooked... skipping hooking process\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<VirtualWorker id:secure_worker #objects:0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JF7G8OD5I8nW",
        "colab": {}
      },
      "source": [
        "class Arguments():\n",
        "    def __init__(self):\n",
        "        self.batch_size = 64\n",
        "        self.test_batch_size = 1000\n",
        "        self.epochs = 10\n",
        "        self.lr = 0.01\n",
        "        self.momentum = 0.5\n",
        "        self.no_cuda = False\n",
        "        self.seed = 1\n",
        "        self.log_interval = 10\n",
        "        self.save_model = True\n",
        "\n",
        "args = Arguments()\n",
        "\n",
        "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
        "\n",
        "torch.manual_seed(args.seed)\n",
        "\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCnEPF-SzhRn",
        "colab_type": "code",
        "outputId": "b1e83c92-75d2-43dc-af36-13039b583071",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "federated_train_loader = sy.FederatedDataLoader(\n",
        "                          datasets.FashionMNIST('../data', train=True, download=True,\n",
        "                          transform=transforms.Compose([\n",
        "                          transforms.ToTensor(),\n",
        "                          transforms.Normalize((0.1307,), (0.3081,))])).federate((bob, alice)),\n",
        "                          batch_size=args.batch_size, shuffle=True,**kwargs)\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "                          datasets.FashionMNIST('../data', train=True, download=True,\n",
        "                          transform=transforms.Compose([\n",
        "                          transforms.ToTensor(),\n",
        "                          transforms.Normalize((0.1307,), (0.3081,))])),\n",
        "                          batch_size=args.batch_size, shuffle=True,**kwargs)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "                       datasets.FashionMNIST('../data', train=False, transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.1307,), (0.3081,))])),\n",
        "                       batch_size=args.test_batch_size, shuffle=True,**kwargs)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0722 09:35:17.093801 140642623997824 dataloader.py:197] The following options are not supported: num_workers: 1, pin_memory: True\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iixkWI7_PlLd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.set_default_tensor_type(torch.cuda.FloatTensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCFtPZunWqij",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
        "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
        "        self.fc1 = nn.Linear(4*4*50, 500)\n",
        "        self.fc2 = nn.Linear(500, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = x.view(-1, 4*4*50)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x, dim=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckxhEzKuWqik",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def train(args, model, device, train_loader, optimizer, epoch):\n",
        "#     model.train()\n",
        "#     for batch_idx, (data, target) in enumerate(federated_train_loader):\n",
        "#         model.send(data.location) # <-- NEW: send the model to the right location\n",
        "#         data, target = data.to(device), target.to(device)\n",
        "#         optimizer.zero_grad()\n",
        "#         output = model(data)\n",
        "#         loss = F.nll_loss(output, target)\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "#         model.get() # <-- NEW: get the model back\n",
        "#         if batch_idx % args.log_interval == 0:\n",
        "#             loss = loss.get() # <-- NEW: get the loss back\n",
        "#             print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "#                 epoch, batch_idx * args.batch_size, len(train_loader) * args.batch_size, #batch_idx * len(data), len(train_loader.dataset),\n",
        "#                 100. * batch_idx / len(train_loader), loss.item()))\n",
        "            \n",
        "            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQPU1n9KWqim",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(args, model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
        "            pred = output.argmax(1, keepdim=True) # get the index of the max log-probability \n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzdEqCiP9n1c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model=Net().to(device)\n",
        "\n",
        "optimizer=optim.SGD(model.parameters(), lr=args.lr)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sD5F1l9kB36s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        },
        "outputId": "1b003ac2-61a0-4a2b-a82d-5bcf2cc4ddb6"
      },
      "source": [
        "data,target=next(iter(train_loader))\n",
        "data, target = data.to(device), target.to(device)\n",
        "optimizer.zero_grad()\n",
        "output = model(data)\n",
        "loss = F.nll_loss(output, target)\n",
        "loss.backward()\n",
        "optimizer.step()\n",
        "test(args, model, device, test_loader)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-46dbac56e343>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    580\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreorder_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mnext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__next__\u001b[0m  \u001b[0;31m# Python 2 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_next_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    606\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"KeyError:\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Traceback (most recent call last):\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/worker.py\", line 99, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/collate.py\", line 68, in default_collate\n    return [default_collate(samples) for samples in transposed]\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/collate.py\", line 68, in <listcomp>\n    return [default_collate(samples) for samples in transposed]\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/collate.py\", line 59, in default_collate\n    return torch.tensor(batch)\n  File \"/content/PySyft/syft/frameworks/torch/hook/hook.py\", line 764, in new_tensor\n    current_tensor = hook_self.torch.native_tensor(*args, **kwargs)\nRuntimeError: CUDA error: initialization error\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T409m3nrD5GF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_bob= model.copy().send(bob)\n",
        "model_alice=model.copy().send(alice)\n",
        "optimizer_bob = optim.SGD(model_bob.parameters(), lr=args.lr)\n",
        "optimizer_alice = optim.SGD(model_alice.parameters(), lr=args.lr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXd7JYho9xOL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3f956837-9972-465c-fad2-da867f9e7ac4"
      },
      "source": [
        "model_bob.train()\n",
        "model_alice.train()\n",
        "data,target=next(iter(federated_train_loader))\n",
        "if data.location == bob:\n",
        "          \n",
        "  model_bob.send(data.location) # <-- NEW: send the model to the right location\n",
        "  data, target = data.to(device), target.to(device)\n",
        "  optimizer_bob.zero_grad()\n",
        "  output_bob = model_bob(data)\n",
        "  loss_bob = F.nll_loss(output_bob, target)\n",
        "  loss_bob.backward()\n",
        "  optimizer_bob.step()\n",
        "  loss_bob=loss_bob.get().data\n",
        "  test(args, model_bob, device, test_loader)\n",
        "elif data.location==alice:\n",
        "          \n",
        "  model_alice.send(data.location) # <-- NEW: send the model to the right location\n",
        "  data, target = data.to(device), target.to(device)\n",
        "  optimizer_alice.zero_grad()\n",
        "  output_alice = model_alice(data)\n",
        "  loss_alice = F.nll_loss(output_alice, target)\n",
        "  loss_alice.backward()\n",
        "  optimizer_alice.step()\n",
        "  loss_alice=loss_alice.get().data\n",
        "  test(args, model_bob, device, test_loader)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPureTorchTensorFoundError\u001b[0m                 Traceback (most recent call last)",
            "\u001b[0;32m/content/PySyft/syft/frameworks/torch/tensors/interpreters/native.py\u001b[0m in \u001b[0;36mhandle_func_command\u001b[0;34m(cls, command)\u001b[0m\n\u001b[1;32m    271\u001b[0m             new_args, new_kwargs, new_type, args_type = syft.frameworks.torch.hook_args.hook_function_args(\n\u001b[0;32m--> 272\u001b[0;31m                 \u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_args_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m             )\n",
            "\u001b[0;32m/content/PySyft/syft/frameworks/torch/hook/hook_args.py\u001b[0m in \u001b[0;36mhook_function_args\u001b[0;34m(attr, args, kwargs, return_args_type)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;31m# Try running it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m         \u001b[0mnew_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/PySyft/syft/frameworks/torch/hook/hook_args.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlambdas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/PySyft/syft/frameworks/torch/hook/hook_args.py\u001b[0m in \u001b[0;36mseven_fold\u001b[0;34m(lambdas, args, **kwargs)\u001b[0m\n\u001b[1;32m    558\u001b[0m     return (\n\u001b[0;32m--> 559\u001b[0;31m         \u001b[0mlambdas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    560\u001b[0m         \u001b[0mlambdas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/PySyft/syft/frameworks/torch/hook/hook_args.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(i)\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;31m# Last if not, rule is probably == 1 so use type to return the right transformation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m         \u001b[0;32melse\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mforward_func\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrules\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# And do this for all the args / rules provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/PySyft/syft/frameworks/torch/hook/hook_args.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(i)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"child\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPureTorchTensorFoundError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParameter\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/PySyft/syft/frameworks/torch/hook/hook_args.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"child\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPureTorchTensorFoundError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParameter\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mPureTorchTensorFoundError\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-cdf886af25d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0moptimizer_bob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0moutput_bob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_bob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m   \u001b[0mloss_bob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_bob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0mloss_bob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-ceb0955942ca>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    336\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    337\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 338\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/PySyft/syft/frameworks/torch/hook/hook.py\u001b[0m in \u001b[0;36moverloaded_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mcmd_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{attr.__module__}.{attr.__name__}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m             \u001b[0mcommand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcmd_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTorchTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_func_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    718\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/PySyft/syft/frameworks/torch/tensors/interpreters/native.py\u001b[0m in \u001b[0;36mhandle_func_command\u001b[0;34m(cls, command)\u001b[0m\n\u001b[1;32m    280\u001b[0m             \u001b[0mnew_command\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0;31m# Send it to the appropriate class and get the response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_func_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_command\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m             \u001b[0;31m# Put back the wrappers where needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m             response = syft.frameworks.torch.hook_args.hook_response(\n",
            "\u001b[0;32m/content/PySyft/syft/frameworks/torch/pointers/object_pointer.py\u001b[0m in \u001b[0;36mhandle_func_command\u001b[0;34m(cls, command)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;31m# Send the command\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mowner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/PySyft/syft/workers/base.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, recipient, message, return_ids)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mret_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSGTYPE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCMD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrecipient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mResponseSignatureError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0mret_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/PySyft/syft/workers/base.py\u001b[0m in \u001b[0;36msend_msg\u001b[0;34m(self, msg_type, message, location)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;31m# Step 2: send the message and wait for a response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0mbin_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbin_message\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;31m# Step 3: deserialize the response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/PySyft/syft/workers/virtual.py\u001b[0m in \u001b[0;36m_send_msg\u001b[0;34m(self, message, location)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mVirtualWorker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseWorker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFederatedClient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_send_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mBaseWorker\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbin\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/PySyft/syft/workers/virtual.py\u001b[0m in \u001b[0;36m_recv_msg\u001b[0;34m(self, message)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbin\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/PySyft/syft/workers/base.py\u001b[0m in \u001b[0;36mrecv_msg\u001b[0;34m(self, bin_message)\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"worker {self} received {sy.codes.code2MSGTYPE[msg_type]} {contents}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0;31m# Step 1: route message to appropriate function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_message_router\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmsg_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0;31m# Step 2: Serialize the message to simple python objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/PySyft/syft/workers/base.py\u001b[0m in \u001b[0;36mexecute_command\u001b[0;34m(self, message)\u001b[0m\n\u001b[1;32m    383\u001b[0m                 \u001b[0mcommand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcommand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;31m# some functions don't return anything (such as .backward())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/PySyft/syft/frameworks/torch/hook/hook.py\u001b[0m in \u001b[0;36moverloaded_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mcmd_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{attr.__module__}.{attr.__name__}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m             \u001b[0mcommand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcmd_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTorchTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_func_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    718\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/PySyft/syft/frameworks/torch/tensors/interpreters/native.py\u001b[0m in \u001b[0;36mhandle_func_command\u001b[0;34m(cls, command)\u001b[0m\n\u001b[1;32m    306\u001b[0m             \u001b[0;31m# in the execute_command function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: weight should have at least three dimensions"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZbUTv2rWqio",
        "colab_type": "code",
        "outputId": "db55356b-b7cd-4c8e-c2d0-cdc132984735",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        }
      },
      "source": [
        "\n",
        "for epoch in range(1, args.epochs + 1):\n",
        "    model_bob.train()\n",
        "    model_alice.train()\n",
        "    for data, target in federated_train_loader:\n",
        "      if data.location == bob:\n",
        "          \n",
        "          model_bob.send(data.location) # <-- NEW: send the model to the right location\n",
        "          data, target = data.to(device), target.to(device)\n",
        "          optimizer_bob.zero_grad()\n",
        "          output_bob = model_bob(data)\n",
        "          loss_bob = F.nll_loss(output_bob, target)\n",
        "          loss_bob.backward()\n",
        "          optimizer_bob.step()\n",
        "          loss_bob=loss_bob.get().data\n",
        "          test(args, model_bob, device, test_loader)\n",
        "      elif data.location==alice:\n",
        "          \n",
        "          model_alice.send(data.location) # <-- NEW: send the model to the right location\n",
        "          data, target = data.to(device), target.to(device)\n",
        "          optimizer_alice.zero_grad()\n",
        "          output_alice = model_alice(data)\n",
        "          loss_alice = F.nll_loss(output_alice, target)\n",
        "          loss_alice.backward()\n",
        "          optimizer_alice.step()\n",
        "          loss_alice=loss_alice.get().data\n",
        "          test(args, model_bob, device, test_loader)\n",
        "    model_alice.move(secure_worker)\n",
        "    model_bob.move(secure_worker)\n",
        "    with torch.no_grad():\n",
        "        model.weight.set_(((model_alice.conv1.weight.data + model_bob.conv1.weight.data) / 2).get())\n",
        "        model.bias.set_(((model_alice.conv1.bias.data + model_bob.conv1.bias.data) / 2).get())    \n",
        "        model.weight.set_(((model_alice.conv2.weight.data + model_bob.conv2.weight.data) / 2).get())\n",
        "        model.bias.set_(((model_alice.conv2.bias.data + model_bob.conv2.bias.data) / 2).get())    \n",
        "        model.weight.set_(((model_alice.fc1.weight.data + model_bob.fc1.weight.data) / 2).get())\n",
        "        model.bias.set_(((model_alice.fc1.bias.data + model_bob.fc1.bias.data) / 2).get())    \n",
        "        model.weight.set_(((model_alice.fc2.weight.data + model_bob.fc2.weight.data) / 2).get())\n",
        "        model.bias.set_(((model_alice.fc2.bias.data + model_bob.fc2.bias.data) / 2).get())    \n",
        "\n",
        "        print('Train Epoch: {} \\tAlice Loss: {:.6f} \\bob Loss: {:.6f}'.format(\n",
        "                epoch, loss_alice.item(),loss_bob.item()))\n",
        "            \n",
        "            \n",
        "  \n",
        "    \n",
        "\n",
        "if (args.save_model):\n",
        "    torch.save(model.state_dict(), \"mnist_cnn.pt\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPureTorchTensorFoundError\u001b[0m                 Traceback (most recent call last)",
            "\u001b[0;32m/content/PySyft/syft/frameworks/torch/tensors/interpreters/native.py\u001b[0m in \u001b[0;36mhandle_func_command\u001b[0;34m(cls, command)\u001b[0m\n\u001b[1;32m    271\u001b[0m             new_args, new_kwargs, new_type, args_type = syft.frameworks.torch.hook_args.hook_function_args(\n\u001b[0;32m--> 272\u001b[0;31m                 \u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_args_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m             )\n",
            "\u001b[0;32m/content/PySyft/syft/frameworks/torch/hook/hook_args.py\u001b[0m in \u001b[0;36mhook_function_args\u001b[0;34m(attr, args, kwargs, return_args_type)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;31m# Try running it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m         \u001b[0mnew_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/PySyft/syft/frameworks/torch/hook/hook_args.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlambdas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/PySyft/syft/frameworks/torch/hook/hook_args.py\u001b[0m in \u001b[0;36mseven_fold\u001b[0;34m(lambdas, args, **kwargs)\u001b[0m\n\u001b[1;32m    558\u001b[0m     return (\n\u001b[0;32m--> 559\u001b[0;31m         \u001b[0mlambdas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    560\u001b[0m         \u001b[0mlambdas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/PySyft/syft/frameworks/torch/hook/hook_args.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(i)\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;31m# Last if not, rule is probably == 1 so use type to return the right transformation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m         \u001b[0;32melse\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mforward_func\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrules\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# And do this for all the args / rules provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/PySyft/syft/frameworks/torch/hook/hook_args.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(i)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"child\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPureTorchTensorFoundError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParameter\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/PySyft/syft/frameworks/torch/hook/hook_args.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"child\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPureTorchTensorFoundError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParameter\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mPureTorchTensorFoundError\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-900a03c10bf8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m           \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m           \u001b[0moptimizer_bob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m           \u001b[0moutput_bob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_bob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m           \u001b[0mloss_bob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_bob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m           \u001b[0mloss_bob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-ceb0955942ca>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    336\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    337\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 338\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/PySyft/syft/frameworks/torch/hook/hook.py\u001b[0m in \u001b[0;36moverloaded_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mcmd_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{attr.__module__}.{attr.__name__}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m             \u001b[0mcommand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcmd_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTorchTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_func_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    718\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/PySyft/syft/frameworks/torch/tensors/interpreters/native.py\u001b[0m in \u001b[0;36mhandle_func_command\u001b[0;34m(cls, command)\u001b[0m\n\u001b[1;32m    280\u001b[0m             \u001b[0mnew_command\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0;31m# Send it to the appropriate class and get the response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_func_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_command\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m             \u001b[0;31m# Put back the wrappers where needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m             response = syft.frameworks.torch.hook_args.hook_response(\n",
            "\u001b[0;32m/content/PySyft/syft/frameworks/torch/pointers/object_pointer.py\u001b[0m in \u001b[0;36mhandle_func_command\u001b[0;34m(cls, command)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;31m# Send the command\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mowner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/PySyft/syft/workers/base.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, recipient, message, return_ids)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mret_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSGTYPE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCMD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrecipient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mResponseSignatureError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0mret_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/PySyft/syft/workers/base.py\u001b[0m in \u001b[0;36msend_msg\u001b[0;34m(self, msg_type, message, location)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;31m# Step 2: send the message and wait for a response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0mbin_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbin_message\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;31m# Step 3: deserialize the response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/PySyft/syft/workers/virtual.py\u001b[0m in \u001b[0;36m_send_msg\u001b[0;34m(self, message, location)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mVirtualWorker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseWorker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFederatedClient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_send_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mBaseWorker\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbin\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/PySyft/syft/workers/virtual.py\u001b[0m in \u001b[0;36m_recv_msg\u001b[0;34m(self, message)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbin\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/PySyft/syft/workers/base.py\u001b[0m in \u001b[0;36mrecv_msg\u001b[0;34m(self, bin_message)\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"worker {self} received {sy.codes.code2MSGTYPE[msg_type]} {contents}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0;31m# Step 1: route message to appropriate function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_message_router\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmsg_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0;31m# Step 2: Serialize the message to simple python objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/PySyft/syft/workers/base.py\u001b[0m in \u001b[0;36mexecute_command\u001b[0;34m(self, message)\u001b[0m\n\u001b[1;32m    383\u001b[0m                 \u001b[0mcommand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcommand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;31m# some functions don't return anything (such as .backward())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/PySyft/syft/frameworks/torch/hook/hook.py\u001b[0m in \u001b[0;36moverloaded_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mcmd_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{attr.__module__}.{attr.__name__}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m             \u001b[0mcommand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcmd_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTorchTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_func_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    718\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/PySyft/syft/frameworks/torch/tensors/interpreters/native.py\u001b[0m in \u001b[0;36mhandle_func_command\u001b[0;34m(cls, command)\u001b[0m\n\u001b[1;32m    306\u001b[0m             \u001b[0;31m# in the execute_command function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: weight should have at least three dimensions"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1zww9qWWqis",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_QVrZEQWqit",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PlMdg-UWqiu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whpfpDqvWqiw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StnYs1BOWqiy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PwLi9uwWqi1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}