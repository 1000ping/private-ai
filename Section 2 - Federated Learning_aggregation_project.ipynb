{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Section 2 - Federated Learning.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ta4sJW3eWqd-",
        "colab_type": "text"
      },
      "source": [
        "# Section: Federated Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhLmZZ3LWqeC",
        "colab_type": "text"
      },
      "source": [
        "# Lesson: Introducing Federated Learning\n",
        "\n",
        "Federated Learning is a technique for training Deep Learning models on data to which you do not have access. Basically:\n",
        "\n",
        "Federated Learning: Instead of bringing all the data to one machine and training a model, we bring the model to the data, train it locally, and merely upload \"model updates\" to a central server.\n",
        "\n",
        "Use Cases:\n",
        "\n",
        "    - app company (Texting prediction app)\n",
        "    - predictive maintenance (automobiles / industrial engines)\n",
        "    - wearable medical devices\n",
        "    - ad blockers / autotomplete in browsers (Firefox/Brave)\n",
        "    \n",
        "Challenge Description: data is distributed amongst sources but we cannot aggregated it because of:\n",
        "\n",
        "    - privacy concerns: legal, user discomfort, competitive dynamics\n",
        "    - engineering: the bandwidth/storage requirements of aggregating the larger dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SZNUiVFWqeD",
        "colab_type": "text"
      },
      "source": [
        "# Lesson: Introducing / Installing PySyft\n",
        "\n",
        "In order to perform Federated Learning, we need to be able to use Deep Learning techniques on remote machines. This will require a new set of tools. Specifically, we will use an extensin of PyTorch called PySyft.\n",
        "\n",
        "### Install PySyft\n",
        "\n",
        "The easiest way to install the required libraries is with [Conda](https://docs.conda.io/projects/conda/en/latest/user-guide/overview.html). Create a new environment, then install the dependencies in that environment. In your terminal:\n",
        "\n",
        "```bash\n",
        "conda create -n pysyft python=3\n",
        "conda activate pysyft # some older version of conda require \"source activate pysyft\" instead.\n",
        "conda install jupyter notebook\n",
        "pip install syft\n",
        "pip install numpy\n",
        "```\n",
        "\n",
        "If you have any errors relating to zstd - run the following (if everything above installed fine then skip this step):\n",
        "\n",
        "```\n",
        "pip install --upgrade --force-reinstall zstd\n",
        "```\n",
        "\n",
        "and then retry installing syft (pip install syft).\n",
        "\n",
        "If you are using Windows, I suggest installing [Anaconda and using the Anaconda Prompt](https://docs.anaconda.com/anaconda/user-guide/getting-started/) to work from the command line. \n",
        "\n",
        "With this environment activated and in the repo directory, launch Jupyter Notebook:\n",
        "\n",
        "```bash\n",
        "jupyter notebook\n",
        "```\n",
        "\n",
        "and re-open this notebook on the new Jupyter server.\n",
        "\n",
        "If any part of this doesn't work for you (or any of the tests fail) - first check the [README](https://github.com/OpenMined/PySyft.git) for installation help and then open a Github Issue or ping the #beginner channel in our slack! [slack.openmined.org](http://slack.openmined.org/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bc_25LQWqiC",
        "colab_type": "text"
      },
      "source": [
        "# Lesson: Pointer Chain Operations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTCewGuumiF1",
        "colab_type": "code",
        "outputId": "7eca1c0e-9ad2-4448-cd39-c69add31d497",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install tf-encrypted\n",
        "\n",
        "! URL=\"https://github.com/openmined/PySyft.git\" && FOLDER=\"PySyft\" && if [ ! -d $FOLDER ]; then git clone -b dev --single-branch $URL; else (cd $FOLDER && git pull $URL && cd ..); fi;\n",
        "\n",
        "!cd PySyft; python setup.py install  > /dev/null\n",
        "\n",
        "import os\n",
        "import sys\n",
        "module_path = os.path.abspath(os.path.join('./PySyft'))\n",
        "if module_path not in sys.path:\n",
        "    sys.path.append(module_path)\n",
        "    \n",
        "!pip install --upgrade --force-reinstall lz4\n",
        "!pip install --upgrade --force-reinstall websocket\n",
        "!pip install --upgrade --force-reinstall websockets\n",
        "!pip install --upgrade --force-reinstall zstd"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tf-encrypted\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/55/ff/7dbd5fc77fcec0df1798268a6b72a2ab0150b854761bc39c77d566798f0b/tf_encrypted-0.5.7-py3-none-manylinux1_x86_64.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 6.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow<2,>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tf-encrypted) (1.14.0)\n",
            "Collecting pyyaml>=5.1 (from tf-encrypted)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/65/837fefac7475963d1eccf4aa684c23b95aa6c1d033a2c5965ccb11e22623/PyYAML-5.1.1.tar.gz (274kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 43.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tf-encrypted) (1.16.4)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted) (1.12.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted) (1.14.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted) (1.11.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted) (0.33.4)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted) (1.14.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted) (1.15.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted) (0.2.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted) (3.7.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted) (0.1.7)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted) (1.0.8)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted) (0.7.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted) (0.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow<2,>=1.12.0->tf-encrypted) (0.15.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow<2,>=1.12.0->tf-encrypted) (41.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow<2,>=1.12.0->tf-encrypted) (3.1.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow<2,>=1.12.0->tf-encrypted) (2.8.0)\n",
            "Building wheels for collected packages: pyyaml\n",
            "  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/16/27/a1/775c62ddea7bfa62324fd1f65847ed31c55dadb6051481ba3f\n",
            "Successfully built pyyaml\n",
            "Installing collected packages: pyyaml, tf-encrypted\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed pyyaml-5.1.1 tf-encrypted-0.5.7\n",
            "Cloning into 'PySyft'...\n",
            "remote: Enumerating objects: 7, done.\u001b[K\n",
            "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 28691 (delta 1), reused 3 (delta 0), pack-reused 28684\u001b[K\n",
            "Receiving objects: 100% (28691/28691), 32.07 MiB | 17.04 MiB/s, done.\n",
            "Resolving deltas: 100% (19020/19020), done.\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "__pycache__.zstd.cpython-36: module references __file__\n",
            "Collecting lz4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0a/c6/96bbb3525a63ebc53ea700cc7d37ab9045542d33b4d262d0f0408ad9bbf2/lz4-2.1.10-cp36-cp36m-manylinux1_x86_64.whl (385kB)\n",
            "\u001b[K     |████████████████████████████████| 389kB 6.4MB/s \n",
            "\u001b[31mERROR: syft 0.1.21a1 has requirement msgpack>=0.6.1, but you'll have msgpack 0.5.6 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: syft 0.1.21a1 has requirement tf_encrypted!=0.5.7,>=0.5.4, but you'll have tf-encrypted 0.5.7 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lz4\n",
            "  Found existing installation: lz4 2.1.10\n",
            "    Uninstalling lz4-2.1.10:\n",
            "      Successfully uninstalled lz4-2.1.10\n",
            "Successfully installed lz4-2.1.10\n",
            "Collecting websocket\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f2/6d/a60d620ea575c885510c574909d2e3ed62129b121fa2df00ca1c81024c87/websocket-0.2.1.tar.gz (195kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 6.8MB/s \n",
            "\u001b[?25hCollecting gevent (from websocket)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f2/ca/5b5962361ed832847b6b2f9a2d0452c8c2f29a93baef850bb8ad067c7bf9/gevent-1.4.0-cp36-cp36m-manylinux1_x86_64.whl (5.5MB)\n",
            "\u001b[K     |████████████████████████████████| 5.5MB 29.4MB/s \n",
            "\u001b[?25hCollecting greenlet (from websocket)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bf/45/142141aa47e01a5779f0fa5a53b81f8379ce8f2b1cd13df7d2f1d751ae42/greenlet-0.4.15-cp36-cp36m-manylinux1_x86_64.whl (41kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 17.1MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: websocket\n",
            "  Building wheel for websocket (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/35/f7/5c/9e8243838269ea93f05295708519a6e183fa6b515d9ce3b636\n",
            "Successfully built websocket\n",
            "Installing collected packages: greenlet, gevent, websocket\n",
            "  Found existing installation: greenlet 0.4.15\n",
            "    Uninstalling greenlet-0.4.15:\n",
            "      Successfully uninstalled greenlet-0.4.15\n",
            "  Found existing installation: gevent 1.4.0\n",
            "    Uninstalling gevent-1.4.0:\n",
            "      Successfully uninstalled gevent-1.4.0\n",
            "Successfully installed gevent-1.4.0 greenlet-0.4.15 websocket-0.2.1\n",
            "Collecting websockets\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c1/d2/bf72435a7d56f94b57efdeae26c76bf0d16f409fd44ff595da745c3fbefd/websockets-8.0.1-cp36-cp36m-manylinux1_x86_64.whl (72kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 6.8MB/s \n",
            "\u001b[31mERROR: syft 0.1.21a1 has requirement msgpack>=0.6.1, but you'll have msgpack 0.5.6 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: syft 0.1.21a1 has requirement tf_encrypted!=0.5.7,>=0.5.4, but you'll have tf-encrypted 0.5.7 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: websockets\n",
            "  Found existing installation: websockets 8.0.1\n",
            "    Uninstalling websockets-8.0.1:\n",
            "      Successfully uninstalled websockets-8.0.1\n",
            "Successfully installed websockets-8.0.1\n",
            "Collecting zstd\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/37/6a7ba746ebddbd6cd06de84367515d6bc239acd94fb3e0b1c85788176ca2/zstd-1.4.1.0.tar.gz (454kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 6.8MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: zstd\n",
            "  Building wheel for zstd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/66/3f/ee/ac08c81af7c1b24a80c746df669ea3cb37542d27877d66ccf4\n",
            "Successfully built zstd\n",
            "\u001b[31mERROR: syft 0.1.21a1 has requirement msgpack>=0.6.1, but you'll have msgpack 0.5.6 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: syft 0.1.21a1 has requirement tf_encrypted!=0.5.7,>=0.5.4, but you'll have tf-encrypted 0.5.7 which is incompatible.\u001b[0m\n",
            "Installing collected packages: zstd\n",
            "  Found existing installation: zstd 1.4.1.0\n",
            "    Uninstalling zstd-1.4.1.0:\n",
            "      Successfully uninstalled zstd-1.4.1.0\n",
            "Successfully installed zstd-1.4.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nx1x3cTUWqih",
        "colab_type": "code",
        "outputId": "6a446b94-2021-441c-9f26-fb5aa5438113",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import syft as sy"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0723 18:21:40.604112 140665277544320 secure_random.py:26] Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was '/usr/local/lib/python3.6/dist-packages/tf_encrypted/operations/secure_random/secure_random_module_tf_1.14.0.so'\n",
            "W0723 18:21:40.623174 140665277544320 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tf_encrypted/session.py:26: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-frYVwLWqii",
        "colab_type": "code",
        "outputId": "1f473de2-5d3d-4b08-f662-996732ad18b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "hook = sy.TorchHook(torch)\n",
        "bob = sy.VirtualWorker(hook, id=\"bob\")\n",
        "alice = sy.VirtualWorker(hook, id=\"alice\")\n",
        "secure_worker=sy.VirtualWorker(hook, id=\"secure_worker\")\n",
        "bob.add_workers([alice,secure_worker])\n",
        "alice.add_workers([bob,secure_worker])\n",
        "secure_worker.add_workers([alice,bob])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0723 18:21:54.662210 140665277544320 base.py:628] Worker alice already exists. Replacing old worker which could cause                     unexpected behavior\n",
            "W0723 18:21:54.664159 140665277544320 base.py:628] Worker secure_worker already exists. Replacing old worker which could cause                     unexpected behavior\n",
            "W0723 18:21:54.665334 140665277544320 base.py:628] Worker bob already exists. Replacing old worker which could cause                     unexpected behavior\n",
            "W0723 18:21:54.666596 140665277544320 base.py:628] Worker secure_worker already exists. Replacing old worker which could cause                     unexpected behavior\n",
            "W0723 18:21:54.668752 140665277544320 base.py:628] Worker alice already exists. Replacing old worker which could cause                     unexpected behavior\n",
            "W0723 18:21:54.670842 140665277544320 base.py:628] Worker bob already exists. Replacing old worker which could cause                     unexpected behavior\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<VirtualWorker id:secure_worker #objects:0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JF7G8OD5I8nW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "f2282e29-d234-4aae-9260-b3fa15edd5e4"
      },
      "source": [
        "class Arguments():\n",
        "    def __init__(self):\n",
        "        self.batch_size = 64\n",
        "        self.test_batch_size = 1000\n",
        "        self.epochs = 10\n",
        "        self.lr = 0.01\n",
        "        self.momentum = 0.5\n",
        "        self.no_cuda = False\n",
        "        self.seed = 1\n",
        "        self.log_interval = 10\n",
        "        self.save_model = True\n",
        "\n",
        "args = Arguments()\n",
        "\n",
        "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
        "kwargs = {\"num_workers\": 1, \"pin_memory\": True} if use_cuda else {}\n",
        "torch.manual_seed(args.seed)\n",
        "\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "federated_train_loader = sy.FederatedDataLoader(\n",
        "                          datasets.MNIST('../data', train=True, download=True,\n",
        "                          transform=transforms.Compose([\n",
        "                          transforms.ToTensor(),\n",
        "                          transforms.Normalize((0.1307,), (0.3081,))])).federate((bob, alice)),\n",
        "                          batch_size=args.batch_size, shuffle=True,**kwargs)\n",
        "torch.set_default_tensor_type(torch.cuda.FloatTensor)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9920512it [00:01, 8747873.07it/s]                            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/28881 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 135542.44it/s]           \n",
            "  0%|          | 0/1648877 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1654784it [00:00, 2208700.60it/s]                            \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8192it [00:00, 51446.36it/s]            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0723 18:23:22.674018 140665277544320 dataloader.py:197] The following options are not supported: num_workers: 1, pin_memory: True\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCnEPF-SzhRn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 5)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 5)\n",
        "        self.fc1 = nn.Linear(4*4*64, 500)\n",
        "        self.fc2 = nn.Linear(500, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print(x)\n",
        "        x = F.relu(self.conv1(x))\n",
        "        # print(x)\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        # print(x)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        # print(x)\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        # print(x)\n",
        "        x = x.view(-1, 4*4*64)\n",
        "        # print(x)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        # print(x)\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x, dim=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iixkWI7_PlLd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_loader = torch.utils.data.DataLoader(\n",
        "                       datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.1307,), (0.3081,))])),\n",
        "                       batch_size=args.test_batch_size, shuffle=True)\n",
        "def test(args, model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
        "            pred = output.argmax(1, keepdim=True) # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCFtPZunWqij",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Net().cuda()\n",
        "model.train()\n",
        "model_bob = model.copy().send(bob)\n",
        "model_alice= model.copy().send(alice)\n",
        "optimizer_bob = optim.SGD(params=model_bob.parameters(), lr=args.lr)\n",
        "optimizer_alice = optim.SGD(params=model_alice.parameters(), lr=args.lr)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckxhEzKuWqik",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "be0d444f-7f18-4ab8-979b-d7e537be067d"
      },
      "source": [
        "for epoch in range(1, args.epochs + 1):\n",
        "\n",
        "    for idx,(data, target) in enumerate(federated_train_loader):\n",
        "\n",
        "        if data.location == bob:\n",
        "            model_bob.train()\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            optimizer_bob.zero_grad()\n",
        "            output_bob = model_bob(data)\n",
        "            loss_bob = F.nll_loss(output_bob, target)\n",
        "            loss_bob.backward()\n",
        "            optimizer_bob.step()\n",
        "            loss_bob = loss_bob.get().data\n",
        "\n",
        "        elif data.location == alice:\n",
        "            model_alice.train()\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            optimizer_alice.zero_grad()\n",
        "            output_alice = model_alice(data)\n",
        "            loss_alice = F.nll_loss(output_alice, target)\n",
        "            loss_alice.backward()\n",
        "            optimizer_alice.step()\n",
        "            loss_alice = loss_alice.get().data\n",
        "    print('Train Epoch: {} \\tAlice Loss: {:.6f} \\tbob Loss: {:.6f}'.format(\n",
        "        epoch, loss_alice.item(), loss_bob.item()))\n",
        "    with torch.no_grad():\n",
        "        pram1=[pram for pram in model_bob.parameters()]\n",
        "        pram2=[pram for pram in model_alice.parameters()]\n",
        "        model_alice.move(secure_worker)\n",
        "        model_bob.move(secure_worker)\n",
        "\n",
        "        for i in range(len(pram1)):\n",
        "            pram1[i].set_(((pram1[i] + pram2[i]) * 0.5).float().to(device))\n",
        "            pram2[i].set_(((pram1[i] + pram2[i]) * 0.5).float().to(device))\n",
        "\n",
        "        model_bob= model_bob.get()\n",
        "        test(args, model_bob, device, test_loader)\n",
        "        model_alice= model_alice.get()\n",
        "        test(args, model_alice, device, test_loader)\n",
        "        model_bob = model_bob.send(bob)\n",
        "        model_alice = model_alice.send(alice)\n",
        "\n",
        "            "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 \tAlice Loss: 0.206999 \tbob Loss: 0.194432\n",
            "\n",
            "Test set: Average loss: 0.2663, Accuracy: 9208/10000 (92%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.2826, Accuracy: 9137/10000 (91%)\n",
            "\n",
            "Train Epoch: 2 \tAlice Loss: 0.150931 \tbob Loss: 0.241952\n",
            "\n",
            "Test set: Average loss: 0.1667, Accuracy: 9520/10000 (95%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.1717, Accuracy: 9460/10000 (95%)\n",
            "\n",
            "Train Epoch: 3 \tAlice Loss: 0.030590 \tbob Loss: 0.190386\n",
            "\n",
            "Test set: Average loss: 0.1114, Accuracy: 9663/10000 (97%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.1181, Accuracy: 9646/10000 (96%)\n",
            "\n",
            "Train Epoch: 4 \tAlice Loss: 0.051556 \tbob Loss: 0.106082\n",
            "\n",
            "Test set: Average loss: 0.0991, Accuracy: 9697/10000 (97%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.1004, Accuracy: 9707/10000 (97%)\n",
            "\n",
            "Train Epoch: 5 \tAlice Loss: 0.067597 \tbob Loss: 0.151261\n",
            "\n",
            "Test set: Average loss: 0.0871, Accuracy: 9737/10000 (97%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0822, Accuracy: 9753/10000 (98%)\n",
            "\n",
            "Train Epoch: 6 \tAlice Loss: 0.134932 \tbob Loss: 0.039990\n",
            "\n",
            "Test set: Average loss: 0.0685, Accuracy: 9778/10000 (98%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0952, Accuracy: 9694/10000 (97%)\n",
            "\n",
            "Train Epoch: 7 \tAlice Loss: 0.030611 \tbob Loss: 0.050880\n",
            "\n",
            "Test set: Average loss: 0.0570, Accuracy: 9815/10000 (98%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0622, Accuracy: 9798/10000 (98%)\n",
            "\n",
            "Train Epoch: 8 \tAlice Loss: 0.099868 \tbob Loss: 0.030235\n",
            "\n",
            "Test set: Average loss: 0.0516, Accuracy: 9828/10000 (98%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0559, Accuracy: 9824/10000 (98%)\n",
            "\n",
            "Train Epoch: 9 \tAlice Loss: 0.112452 \tbob Loss: 0.027574\n",
            "\n",
            "Test set: Average loss: 0.0512, Accuracy: 9839/10000 (98%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0491, Accuracy: 9836/10000 (98%)\n",
            "\n",
            "Train Epoch: 10 \tAlice Loss: 0.067094 \tbob Loss: 0.075864\n",
            "\n",
            "Test set: Average loss: 0.0596, Accuracy: 9803/10000 (98%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0542, Accuracy: 9841/10000 (98%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PlMdg-UWqiu",
        "colab_type": "code",
        "outputId": "a4967f48-2ba0-4a03-ecce-01834c838f95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "! nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Jul 22 10:40:48 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 418.67       Driver Version: 410.79       CUDA Version: 10.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   28C    P8    26W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StnYs1BOWqiy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PwLi9uwWqi1",
        "colab_type": "code",
        "outputId": "c0ae2415-21bb-4751-abb7-f1385f2c68b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "torch.__version__"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.1.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    }
  ]
}