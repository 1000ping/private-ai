{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Section 4 - Encrypted Deep Learning.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAFK7sD25VqN",
        "colab_type": "text"
      },
      "source": [
        "# Section: Encrypted Deep Learning\n",
        "\n",
        "- Lesson: Reviewing Additive Secret Sharing\n",
        "- Lesson: Encrypted Subtraction and Public/Scalar Multiplication\n",
        "- Lesson: Encrypted Computation in PySyft\n",
        "- Project: Build an Encrypted Database\n",
        "- Lesson: Encrypted Deep Learning in PyTorch\n",
        "- Lesson: Encrypted Deep Learning in Keras\n",
        "- Final Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFymvBDc5VqP",
        "colab_type": "text"
      },
      "source": [
        "# Lesson: Reviewing Additive Secret Sharing\n",
        "\n",
        "_For more great information about SMPC protocols like this one, visit https://mortendahl.github.io. With permission, Morten's work directly inspired this first teaching segment._"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aNcrUoDKSg3",
        "colab_type": "code",
        "outputId": "aae5aab6-0f6c-4acf-c27f-965725518436",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 785
        }
      },
      "source": [
        "!pip install --upgrade syft"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: syft in /usr/local/lib/python3.6/dist-packages (0.1.21a1)\n",
            "Requirement already satisfied, skipping upgrade: websockets>=7.0 in /usr/local/lib/python3.6/dist-packages (from syft) (8.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from syft) (1.16.4)\n",
            "Requirement already satisfied, skipping upgrade: websocket-client>=0.56.0 in /usr/local/lib/python3.6/dist-packages (from syft) (0.56.0)\n",
            "Requirement already satisfied, skipping upgrade: tf-encrypted>=0.5.4 in /usr/local/lib/python3.6/dist-packages (from syft) (0.5.6)\n",
            "Requirement already satisfied, skipping upgrade: torch>=1.1 in /usr/local/lib/python3.6/dist-packages (from syft) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn>=0.21.0 in /usr/local/lib/python3.6/dist-packages (from syft) (0.21.2)\n",
            "Requirement already satisfied, skipping upgrade: lz4>=2.1.6 in /usr/local/lib/python3.6/dist-packages (from syft) (2.1.10)\n",
            "Requirement already satisfied, skipping upgrade: tblib>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from syft) (1.4.0)\n",
            "Requirement already satisfied, skipping upgrade: torchvision>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from syft) (0.3.0)\n",
            "Requirement already satisfied, skipping upgrade: msgpack>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from syft) (0.6.1)\n",
            "Requirement already satisfied, skipping upgrade: Flask>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from syft) (1.1.1)\n",
            "Requirement already satisfied, skipping upgrade: flask-socketio>=3.3.2 in /usr/local/lib/python3.6/dist-packages (from syft) (4.1.0)\n",
            "Requirement already satisfied, skipping upgrade: zstd>=1.4.0.0 in /usr/local/lib/python3.6/dist-packages (from syft) (1.4.0.0)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from websocket-client>=0.56.0->syft) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: pyyaml>=5.1 in /usr/local/lib/python3.6/dist-packages (from tf-encrypted>=0.5.4->syft) (5.1.1)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow<2,>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tf-encrypted>=0.5.4->syft) (1.14.0)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.0->syft) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.0->syft) (0.13.2)\n",
            "Requirement already satisfied, skipping upgrade: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.3.0->syft) (4.3.0)\n",
            "Requirement already satisfied, skipping upgrade: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (0.15.4)\n",
            "Requirement already satisfied, skipping upgrade: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (7.0)\n",
            "Requirement already satisfied, skipping upgrade: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (2.10.1)\n",
            "Requirement already satisfied, skipping upgrade: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: python-socketio>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from flask-socketio>=3.3.2->syft) (4.2.0)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.33.4)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.1.7)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.7.1)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.14.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.14.0)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.11.2)\n",
            "Requirement already satisfied, skipping upgrade: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.2.2)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (3.7.1)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.8.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.0.8)\n",
            "Requirement already satisfied, skipping upgrade: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision>=0.3.0->syft) (0.46)\n",
            "Requirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->Flask>=1.0.2->syft) (1.1.1)\n",
            "Requirement already satisfied, skipping upgrade: python-engineio>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from python-socketio>=2.1.0->flask-socketio>=3.3.2->syft) (3.8.2.post1)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (3.1.1)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (41.0.1)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (2.8.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oz4QRsed5VqQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "BASE = 10\n",
        "\n",
        "PRECISION_INTEGRAL = 8\n",
        "PRECISION_FRACTIONAL = 8\n",
        "Q = 293973345475167247070445277780365744413\n",
        "\n",
        "PRECISION = PRECISION_INTEGRAL + PRECISION_FRACTIONAL\n",
        "\n",
        "assert(Q > BASE**PRECISION)\n",
        "\n",
        "def encode(rational):\n",
        "    upscaled = int(rational * BASE**PRECISION_FRACTIONAL)\n",
        "    field_element = upscaled % Q\n",
        "    return field_element\n",
        "\n",
        "def decode(field_element):\n",
        "    upscaled = field_element if field_element <= Q/2 else field_element - Q\n",
        "    rational = upscaled / BASE**PRECISION_FRACTIONAL\n",
        "    return rational\n",
        "\n",
        "def encrypt(secret):\n",
        "    first  = random.randrange(Q)\n",
        "    second = random.randrange(Q)\n",
        "    third  = (secret - first - second) % Q\n",
        "    return [first, second, third]\n",
        "\n",
        "def decrypt(sharing):\n",
        "    return sum(sharing) % Q\n",
        "\n",
        "def add(a, b):\n",
        "    c = list()\n",
        "    for i in range(len(a)):\n",
        "        c.append((a[i] + b[i]) % Q)\n",
        "    return tuple(c)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHoDnqnx5VqT",
        "colab_type": "code",
        "outputId": "f6506aac-f0d6-4cc2-f05a-9f5f156d4a24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "x = encrypt(encode(5.5))\n",
        "x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[76415910642592650282410530616961883967,\n",
              " 29136920984719121970593682754902659143,\n",
              " 188420513847855474817441064409051201303]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fljLY9WH5VqY",
        "colab_type": "code",
        "outputId": "e36b5a8f-69ae-4d2c-df7b-40467e4007ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "y = encrypt(encode(2.3))\n",
        "y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[166195622956431362823577447161467892485,\n",
              " 246469003377878055249095104209355375995,\n",
              " 175282064616025076068218004190138220345]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xg62EjC45Vqb",
        "colab_type": "code",
        "outputId": "25942f40-f619-49bc-ada3-1747131ba7c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "z = add(x,y)\n",
        "z"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(242611533599024013105987977778429776452,\n",
              " 275605924362597177219688786964258035138,\n",
              " 69729232988713303815213790818823677235)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9TKnNup5Vqe",
        "colab_type": "code",
        "outputId": "38bd3a92-72ba-4f59-9eb5-456520b4f9fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "decode(decrypt(z))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7.79999999"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpquPdXd5Vqh",
        "colab_type": "text"
      },
      "source": [
        "# Lesson: Encrypted Subtraction and Public/Scalar Multiplication"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cnnKK0N5Vqi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Idft5AaE5Vqk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "field = 23740629843760239486723"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4Hj4ivF5Vqm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = 5\n",
        "\n",
        "bob_x_share = 2372385723 # random number\n",
        "alices_x_share = field - bob_x_share + x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClBi_eth5Vqp",
        "colab_type": "code",
        "outputId": "f0010610-21d1-4286-e0e3-8a8969b15361",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "(bob_x_share + alices_x_share) % field"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0X0hCbZU5Vqv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "field = 10\n",
        "\n",
        "x = 5\n",
        "\n",
        "bob_x_share = 8\n",
        "alice_x_share = field - bob_x_share + x\n",
        "\n",
        "y = 1\n",
        "\n",
        "bob_y_share = 9\n",
        "alice_y_share = field - bob_y_share + y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzPS982g5Vqz",
        "colab_type": "code",
        "outputId": "53da33a4-4227-48b6-cd17-e2286ece82ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "((bob_x_share + alice_x_share) - (bob_y_share + alice_y_share)) % field"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcrlMAe25Vq2",
        "colab_type": "code",
        "outputId": "f7ebeefd-0bf3-448e-f977-b62ec3285554",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "((bob_x_share - bob_y_share) + (alice_x_share - alice_y_share)) % field"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1otjU2-5Vq5",
        "colab_type": "code",
        "outputId": "afec9ec2-9826-4507-d4e2-ee4639960c54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "bob_x_share + alice_x_share + bob_y_share + alice_y_share"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIIiAQXa5VrF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bob_z_share = (bob_x_share - bob_y_share)\n",
        "alice_z_share = (alice_x_share - alice_y_share)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10sBLHx_5VrO",
        "colab_type": "code",
        "outputId": "bba5392d-f57d-4571-863e-0ea2167ac727",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "(bob_z_share + alice_z_share) % field"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dwen9WnR5Vrm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sub(a, b):\n",
        "    c = list()\n",
        "    for i in range(len(a)):\n",
        "        c.append((a[i] - b[i]) % Q)\n",
        "    return tuple(c)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tX5V0f9n5Vrp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "field = 10\n",
        "\n",
        "x = 5\n",
        "\n",
        "bob_x_share = 8\n",
        "alice_x_share = field - bob_x_share + x\n",
        "\n",
        "y = 1\n",
        "\n",
        "bob_y_share = 9\n",
        "alice_y_share = field - bob_y_share + y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdNvXWUY5Vrt",
        "colab_type": "code",
        "outputId": "f1d35173-0817-4130-d5f7-eb662e96b6ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "bob_x_share + alice_x_share"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4yquXr55Vry",
        "colab_type": "code",
        "outputId": "63d60f75-d237-4251-d987-78853b71f270",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "bob_y_share + alice_y_share"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JO3k_7th5Vr3",
        "colab_type": "code",
        "outputId": "8fa62b3f-3d02-419d-8667-3961d39ee356",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "((bob_y_share * 3) + (alice_y_share * 3)) % field"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFnXMdCn5Vr6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def imul(a, scalar):\n",
        "    \n",
        "    # logic here which can multiply by a public scalar\n",
        "    \n",
        "    c = list()\n",
        "    \n",
        "    for i in range(len(a)):\n",
        "        c.append((a[i] * scalar) % Q)\n",
        "        \n",
        "    return tuple(c)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iCvxRyV5VsA",
        "colab_type": "code",
        "outputId": "2c005ad6-bf08-46c5-afc3-1257f5a31a05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "x = encrypt(encode(5.5))\n",
        "x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3540224615689186850666997178009893611,\n",
              " 231634467016271076990970851752039249528,\n",
              " 58798653843206983228807428850866601274]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FuW4qg75VsF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "z = imul(x, 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8aoUcfZ5VsM",
        "colab_type": "code",
        "outputId": "ed698b40-a542-414b-aca9-9b1a6be5a2cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "decode(decrypt(z))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16.5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtnQqV2O5VsP",
        "colab_type": "text"
      },
      "source": [
        "# Lesson: Encrypted Computation in PySyft"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPi98MGp5VsP",
        "colab_type": "code",
        "outputId": "15135396-2a7d-492e-d59f-e3e43e31f181",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "import syft as sy\n",
        "import torch as th\n",
        "hook = sy.TorchHook(th)\n",
        "from torch import nn, optim"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0715 00:23:21.999238 139681796171648 secure_random.py:26] Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was '/usr/local/lib/python3.6/dist-packages/tf_encrypted/operations/secure_random/secure_random_module_tf_1.14.0.so'\n",
            "W0715 00:23:22.017191 139681796171648 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tf_encrypted/session.py:26: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hO5o7abG5VsR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bob = sy.VirtualWorker(hook, id=\"bob\").add_worker(sy.local_worker)\n",
        "alice = sy.VirtualWorker(hook, id=\"alice\").add_worker(sy.local_worker)\n",
        "secure_worker = sy.VirtualWorker(hook, id=\"secure_worker\").add_worker(sy.local_worker)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ruel2cu35VsT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = th.tensor([1,2,3,4])\n",
        "y = th.tensor([2,-1,1,0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4ApRsXk5VsV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = x.share(bob, alice, crypto_provider=secure_worker)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSPuK1y_5VsX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = y.share(bob, alice, crypto_provider=secure_worker)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KV0t08U5VsZ",
        "colab_type": "code",
        "outputId": "9cb23323-7fe9-4b4f-a9f3-65bdaa76872b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "z = x + y\n",
        "z.get()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3, 1, 4, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8sfycPV5Vsb",
        "colab_type": "code",
        "outputId": "e1704c85-d4f9-4756-fdb4-5bb52ad6f1c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "z = x - y\n",
        "z.get()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-1,  3,  2,  4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoofwi9n5Vsd",
        "colab_type": "code",
        "outputId": "a5ac5d2c-47d4-44b2-e4b4-91705d301e84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "z = x * y\n",
        "z.get()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 2, -2,  3,  0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A98VDjjb5Vsh",
        "colab_type": "code",
        "outputId": "d4043048-d7cb-4e99-cf66-1b3a66319ae2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "z = x > y\n",
        "z.get()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcX7695q5Vsj",
        "colab_type": "code",
        "outputId": "c68e9556-8018-45a0-f4c0-31061ab475b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "z = x < y\n",
        "z.get()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52pqZFFQ5Vsm",
        "colab_type": "code",
        "outputId": "46eb65d9-16c9-448d-bfe5-ac323a7d2d8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "z = x == y\n",
        "z.get()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MjRyzqs5Vsp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXJNWLMi5Vsq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = th.tensor([1,2,3,4])\n",
        "y = th.tensor([2,-1,1,0])\n",
        "\n",
        "x = x.fix_precision().share(bob, alice, crypto_provider=secure_worker)\n",
        "y = y.fix_precision().share(bob, alice, crypto_provider=secure_worker)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyoEwTY45Vss",
        "colab_type": "code",
        "outputId": "4f30cc6d-6f34-487a-d89a-60d3bb71ad7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "z = x + y\n",
        "z.get().float_precision()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3., 1., 4., 4.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uhpt4hMH5Vsu",
        "colab_type": "code",
        "outputId": "762f9add-7a25-45bd-88a5-ee246091593f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "z = x - y\n",
        "z.get().float_precision()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-2d4b75384585>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat_precision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/tensors/interpreters/native.py\u001b[0m in \u001b[0;36mfloat_prec\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfloat_prec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat_precision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m     \u001b[0mfloat_precision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat_prec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'child'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmkAafBU5Vsx",
        "colab_type": "code",
        "outputId": "26c8ffee-74c2-4840-a751-c535d45ecc63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "z = x * y\n",
        "z.get().float_precision()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 2., -2.,  3.,  0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swGw-_8-5Vs4",
        "colab_type": "code",
        "outputId": "106e09b0-dc52-4490-a6d9-85f17ba8b65f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "z = x > y\n",
        "z.get().float_precision()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 1., 1., 1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9OzZHpW5Vs_",
        "colab_type": "code",
        "outputId": "f8868f12-5b5f-48f5-e4bd-22f6ddf14bef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "z = x < y\n",
        "z.get().float_precision()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gm1Hupt5VtG",
        "colab_type": "code",
        "outputId": "db36a697-c37d-4e5f-f265-0d03bd0c0c08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "z = x == y\n",
        "z.get().float_precision()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlpmXWwx5VtL",
        "colab_type": "text"
      },
      "source": [
        "# Project: Build an Encrypted Database"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AKbYgJU5VtM",
        "colab_type": "code",
        "outputId": "9cc93854-70ff-4342-de13-1e473e8e7c1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import string\n",
        "bob.clear_objects()\n",
        "alice.clear_objects()\n",
        "secure_worker.clear_objects()"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<VirtualWorker id:secure_worker #objects:0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXXKQSrx5VtO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "char_index={}\n",
        "index_char={}\n",
        "for idx,char in enumerate(\" \"+string.ascii_letters+string.digits+string.punctuation):\n",
        "  char_index[char]=idx\n",
        "  index_char[idx]=char\n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUrSTUG85VtU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def string_index(string_crt):\n",
        "  indices=list()\n",
        "  for char in string_crt:\n",
        "    indices.append(char_index[char])\n",
        "\n",
        "  return th.tensor(indices)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xAVEmRS5VtZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class string_key_value():\n",
        "  def __init__(self,*owners):\n",
        "    self.keys=list()\n",
        "    self.values=list()\n",
        "    self.owners=list(owners)\n",
        "  def string_match(self,string_query):\n",
        "    string_query=string_query.share(self.owners[0],self.owners[1],crypto_provider=self.owners[2])\n",
        "    for idx,key in enumerate(self.keys):\n",
        "      if len(string_query)==len(key):\n",
        "        if (th.sum(key.sub(string_query))).get()==0:\n",
        "          result=self.values[idx]\n",
        "          result=result.get()\n",
        "          return result\n",
        "      \n",
        "\n",
        "  def add_data(self,key,value):\n",
        "    key=key.share(self.owners[0],self.owners[1],crypto_provider=self.owners[2])\n",
        "    self.keys.append(key)\n",
        "    value=value.share(self.owners[0],self.owners[1],crypto_provider=self.owners[2])\n",
        "\n",
        "    self.values.append(value)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEZLk9Sz5MjO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def index_string(index_crt):\n",
        "  string_list=list()\n",
        "  index_crt=list(index_crt.numpy())\n",
        "  for i in index_crt:\n",
        "    string_list.append(index_char[i])\n",
        "  return \"\".join(string_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqKFymS-UGbs",
        "colab_type": "code",
        "outputId": "2e1a4d86-fca6-4ba0-a4e8-fefab81c7f93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "db=string_key_value(bob,alice,secure_worker)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<VirtualWorker id:bob #objects:14> <VirtualWorker id:alice #objects:18> <VirtualWorker id:secure_worker #objects:0>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxHx_JnFUU7C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "db.add_data(string_index(\"key1\"),string_index(\"value1\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sEd6_W88csm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "db.add_data(string_index(\"key2\"),string_index(\"value2\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fay5kg_P8YQp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "match_key=string_index(\"key2\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WV51AQjsQC_I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result=db.string_match(match_key)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbnyDSWg4z7X",
        "colab_type": "code",
        "outputId": "3474743a-6928-418d-de80-90b51cf43fdd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "result_string=index_string(result)\n",
        "result_string"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'value2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evV5jq40Nr01",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fT5EeXpNryC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGRhTRt8NrvT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OM0dp7M05Vta",
        "colab_type": "text"
      },
      "source": [
        "# Lesson: Encrypted Deep Learning in PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Jau9RAy5Vta",
        "colab_type": "text"
      },
      "source": [
        "### Train a Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ouA4zvD5Vtb",
        "colab_type": "code",
        "outputId": "ba29d3b6-52a2-437d-b224-c2083f2d900c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# A Toy Dataset\n",
        "data = th.tensor([[0,0],[0,1],[1,0],[1,1.]], requires_grad=True)\n",
        "target = th.tensor([[0],[0],[1],[1.]], requires_grad=True)\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(2, 20)\n",
        "        self.fc2 = nn.Linear(20, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# A Toy Model\n",
        "model = Net()\n",
        "\n",
        "def train():\n",
        "    # Training Logic\n",
        "    opt = optim.SGD(params=model.parameters(),lr=0.1)\n",
        "    for iter in range(20):\n",
        "\n",
        "        # 1) erase previous gradients (if they exist)\n",
        "        opt.zero_grad()\n",
        "\n",
        "        # 2) make a prediction\n",
        "        pred = model(data)\n",
        "\n",
        "        # 3) calculate how much we missed\n",
        "        loss = ((pred - target)**2).sum()\n",
        "\n",
        "        # 4) figure out which weights caused us to miss\n",
        "        loss.backward()\n",
        "\n",
        "        # 5) change those weights\n",
        "        opt.step()\n",
        "\n",
        "        # 6) print our progress\n",
        "        print(loss.data)\n",
        "        \n",
        "train()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(2.9485)\n",
            "tensor(9.6907)\n",
            "tensor(10.5821)\n",
            "tensor(0.9325)\n",
            "tensor(0.8769)\n",
            "tensor(0.8296)\n",
            "tensor(0.7735)\n",
            "tensor(0.6877)\n",
            "tensor(0.5834)\n",
            "tensor(0.4648)\n",
            "tensor(0.3408)\n",
            "tensor(0.2242)\n",
            "tensor(0.1346)\n",
            "tensor(0.0782)\n",
            "tensor(0.0450)\n",
            "tensor(0.0270)\n",
            "tensor(0.0174)\n",
            "tensor(0.0120)\n",
            "tensor(0.0086)\n",
            "tensor(0.0064)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJvLJKpO5Vtd",
        "colab_type": "code",
        "outputId": "d0a041d8-27ab-4b05-a310-3511d5b47467",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "model(data)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0572],\n",
              "        [-0.0323],\n",
              "        [ 0.9775],\n",
              "        [ 0.9994]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YMWgQB-5Vtf",
        "colab_type": "text"
      },
      "source": [
        "## Encrypt the Model and Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-w0xQSaG5Vtf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encrypted_model = model.fix_precision().share(alice, bob, crypto_provider=secure_worker)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NILruezg5Vth",
        "colab_type": "code",
        "outputId": "b6b14bb1-8a21-433b-9f4d-12bd03b108d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "list(encrypted_model.parameters())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " Parameter>FixedPrecisionTensor>(Wrapper)>[AdditiveSharingTensor]\n",
              " \t-> (Wrapper)>[PointerTensor | me:99497974212 -> alice:36782629387]\n",
              " \t-> (Wrapper)>[PointerTensor | me:45779793437 -> bob:64169565995]\n",
              " \t*crypto provider: secure_worker*, Parameter containing:\n",
              " Parameter>FixedPrecisionTensor>(Wrapper)>[AdditiveSharingTensor]\n",
              " \t-> (Wrapper)>[PointerTensor | me:16690494985 -> alice:59671716694]\n",
              " \t-> (Wrapper)>[PointerTensor | me:20210949258 -> bob:84651898958]\n",
              " \t*crypto provider: secure_worker*, Parameter containing:\n",
              " Parameter>FixedPrecisionTensor>(Wrapper)>[AdditiveSharingTensor]\n",
              " \t-> (Wrapper)>[PointerTensor | me:96971646175 -> alice:13312025986]\n",
              " \t-> (Wrapper)>[PointerTensor | me:66400910854 -> bob:9377596562]\n",
              " \t*crypto provider: secure_worker*, Parameter containing:\n",
              " Parameter>FixedPrecisionTensor>(Wrapper)>[AdditiveSharingTensor]\n",
              " \t-> (Wrapper)>[PointerTensor | me:54458996411 -> alice:66153288266]\n",
              " \t-> (Wrapper)>[PointerTensor | me:76209616124 -> bob:8284896360]\n",
              " \t*crypto provider: secure_worker*]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwvNFwsC5Vtk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encrypted_data = data.fix_precision().share(alice, bob, crypto_provider=secure_worker)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrBDU8635Vtn",
        "colab_type": "code",
        "outputId": "43f5c221-0971-470c-e50b-7ef555860e46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "encrypted_data"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Wrapper)>FixedPrecisionTensor>(Wrapper)>[AdditiveSharingTensor]\n",
              "\t-> (Wrapper)>[PointerTensor | me:11305882392 -> alice:65818850167]\n",
              "\t-> (Wrapper)>[PointerTensor | me:43379962836 -> bob:44254893162]\n",
              "\t*crypto provider: secure_worker*"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIVu8Hd05Vtp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encrypted_prediction = encrypted_model(encrypted_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iDShKrU5Vtq",
        "colab_type": "code",
        "outputId": "109cb7f1-7c9a-4d36-b13f-ccce52b66b23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "encrypted_prediction.get().float_precision()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0580],\n",
              "        [-0.0310],\n",
              "        [ 0.9750],\n",
              "        [ 0.9970]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGGCCyfh5Vts",
        "colab_type": "text"
      },
      "source": [
        "# Lesson: Encrypted Deep Learning in Keras\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TQKmFzo5Vtt",
        "colab_type": "text"
      },
      "source": [
        "## Step 1: Public Training\n",
        "\n",
        "Welcome to this tutorial! In the following notebooks you will learn how to provide private predictions. By private predictions, we mean that the data is constantly encrypted throughout the entire process. At no point is the user sharing raw data, only encrypted (that is, secret shared) data. In order to provide these private predictions, Syft Keras uses a library called [TF Encrypted](https://github.com/tf-encrypted/tf-encrypted) under the hood. TF Encrypted combines cutting-edge cryptographic and machine learning techniques, but you don't have to worry about this and can focus on your machine learning application.\n",
        "\n",
        "You can start serving private predictions with only three steps:\n",
        "- **Step 1**: train your model with normal Keras.\n",
        "- **Step 2**: secure and serve your machine learning model (server).\n",
        "- **Step 3**: query the secured model to receive private predictions (client). \n",
        "\n",
        "Alright, let's go through these three steps so you can deploy impactful machine learning services without sacrificing user privacy or model security.\n",
        "\n",
        "Huge shoutout to the Dropout Labs ([@dropoutlabs](https://twitter.com/dropoutlabs)) and TF Encrypted ([@tf_encrypted](https://twitter.com/tf_encrypted)) teams for their great work which makes this demo possible, especially: Jason Mancuso ([@jvmancuso](https://twitter.com/jvmancuso)), Yann Dupis ([@YannDupis](https://twitter.com/YannDupis)), and Morten Dahl ([@mortendahlcs](https://github.com/mortendahlcs)). \n",
        "\n",
        "_Demo Ref: https://github.com/OpenMined/PySyft/tree/dev/examples/tutorials_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OE_GxloB5Vtt",
        "colab_type": "text"
      },
      "source": [
        "## Train Your Model in Keras\n",
        "\n",
        "To use privacy-preserving machine learning techniques for your projects you should not have to learn a new machine learning framework. If you have basic [Keras](https://keras.io/) knowledge, you can start using these techniques with Syft Keras. If you have never used Keras before, you can learn a bit more about it through the [Keras documentation](https://keras.io). \n",
        "\n",
        "Before serving private predictions, the first step is to train your model with normal Keras. As an example, we will train a model to classify handwritten digits. To train this model we will use the canonical [MNIST dataset](http://yann.lecun.com/exdb/mnist/).\n",
        "\n",
        "We borrow [this example](https://github.com/keras-team/keras/blob/master/examples/mnist_cnn.py) from the reference Keras repository.  To train your classification model, you just run the cell below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBRScriF5Vtu",
        "colab_type": "code",
        "outputId": "1381fa94-2c05-4e13-bb81-449d7a7703de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "source": [
        "from __future__ import print_function\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, AveragePooling2D\n",
        "from tensorflow.keras.layers import Activation\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 2\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(10, (3, 3), input_shape=input_shape))\n",
        "model.add(AveragePooling2D((2, 2)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(AveragePooling2D((2, 2)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(AveragePooling2D((2, 2)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adadelta(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0715 01:18:40.915485 140546383480704 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/2\n",
            "60000/60000 [==============================] - 4s 69us/sample - loss: 2.3016 - acc: 0.1338 - val_loss: 2.3003 - val_acc: 0.1535\n",
            "Epoch 2/2\n",
            "60000/60000 [==============================] - 2s 34us/sample - loss: 2.2999 - acc: 0.1559 - val_loss: 2.2984 - val_acc: 0.1739\n",
            "Test loss: 2.2983899822235108\n",
            "Test accuracy: 0.1739\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0H7r0jCl5Vtw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Save your model's weights for future private prediction\n",
        "model.save('short-conv-mnist.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VuyQiPmB5Vty",
        "colab_type": "text"
      },
      "source": [
        "## Step 2: Load and Serve the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1WxbGmb5Vtz",
        "colab_type": "text"
      },
      "source": [
        "Now that you have a trained model with normal Keras, you are ready to serve some private predictions. We can do that using Syft Keras.\n",
        "\n",
        "To secure and serve this model, we will need three TFEWorkers (servers). This is because TF Encrypted under the hood uses an encryption technique called [multi-party computation (MPC)](https://en.wikipedia.org/wiki/Secure_multi-party_computation). The idea is to split the model weights and input data into shares, then send a share of each value to the different servers. The key property is that if you look at the share on one server, it reveals nothing about the original value (input data or model weights).\n",
        "\n",
        "We'll define a Syft Keras model like we did in the previous notebook. However, there is a trick: before instantiating this model, we'll run `hook = sy.KerasHook(tf.keras)`. This will add three important new methods to the Keras Sequential class:\n",
        " - `share`: will secure your model via secret sharing; by default, it will use the SecureNN protocol from TF Encrypted to secret share your model between each of the three TFEWorkers. Most importantly, this will add the capability of providing predictions on encrypted data.\n",
        " - `serve`: this function will launch a serving queue, so that the TFEWorkers can can accept prediction requests on the secured model from external clients.\n",
        " - `shutdown_workers`: once you are done providing private predictions, you can shut down your model by running this function. It will direct you to shutdown the server processes manually if you've opted to manually manage each worker.\n",
        "\n",
        "If you want learn more about MPC, you can read this excellent [blog](https://mortendahl.github.io/2017/04/17/private-deep-learning-with-mpc/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-Nd0snz5Vtz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "98033193-c481-4879-f1f0-deac206b2b96"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import AveragePooling2D, Conv2D, Dense, Activation, Flatten, ReLU, Activation\n",
        "\n",
        "import syft as sy\n",
        "hook = sy.KerasHook(tf.keras)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0715 01:18:57.476640 140546383480704 secure_random.py:26] Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was '/usr/local/lib/python3.6/dist-packages/tf_encrypted/operations/secure_random/secure_random_module_tf_1.14.0.so'\n",
            "W0715 01:18:57.575459 140546383480704 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tf_encrypted/session.py:26: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07eOHWsv5Vt1",
        "colab_type": "text"
      },
      "source": [
        "## Model\n",
        "\n",
        "As you can see, we define almost the exact same model as before, except we provide a `batch_input_shape`. This allows TF Encrypted to better optimize the secure computations via predefined tensor shapes. For this MNIST demo, we'll send input data with the shape of (1, 28, 28, 1). \n",
        "We also return the logit instead of softmax because this operation is complex to perform using MPC, and we don't need it to serve prediction requests."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "En1E_4rl5Vt2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_classes = 10\n",
        "input_shape = (1, 28, 28, 1)\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(10, (3, 3), batch_input_shape=input_shape))\n",
        "model.add(AveragePooling2D((2, 2)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(AveragePooling2D((2, 2)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(AveragePooling2D((2, 2)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(num_classes, name=\"logit\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-IAM2qQQ5Vt3",
        "colab_type": "text"
      },
      "source": [
        "### Load Pre-trained Weights\n",
        "\n",
        "With `load_weights` you can easily load the weights you have saved previously after training your model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlbwIioi5Vt4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pre_trained_weights = 'short-conv-mnist.h5'\n",
        "model.load_weights(pre_trained_weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9A7MDc8eLP8g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1038eb26-d33c-45e4-8bc9-0458f8e6bc24"
      },
      "source": [
        "!ping localhost:4000\n",
        "  "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: ping: command not found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WF739JlZ5Vt6",
        "colab_type": "text"
      },
      "source": [
        "## Step 3: Setup Your Worker Connectors\n",
        "\n",
        "Let's now connect to the TFEWorkers (`alice`, `bob`, and `carol`) required by TF Encrypted to perform private predictions. For each TFEWorker, you just have to specify a host.\n",
        "\n",
        "These workers run a [TensorFlow server](https://www.tensorflow.org/api_docs/python/tf/distribute/Server), which you can either manage manually (`AUTO = False`) or ask the workers to manage for you (`AUTO = True`). If choosing to manually manage them, you will be instructed to execute a terminal command on each worker's host device after calling `model.share()` below.  If all workers are hosted on a single device (e.g. `localhost`), you can choose to have Syft automatically manage the worker's TensorFlow server."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yl8XAJRE5Vt6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "AUTO = False\n",
        "\n",
        "alice = sy.TFEWorker(host='localhost:8887', auto_managed=AUTO)\n",
        "bob = sy.TFEWorker(host='localhost:8888', auto_managed=AUTO)\n",
        "carol = sy.TFEWorker(host='localhost:8889', auto_managed=AUTO)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlhD3dRT5Vt8",
        "colab_type": "text"
      },
      "source": [
        "## Step 4: Split the Model Into Shares\n",
        "\n",
        "Thanks to `sy.KerasHook(tf.keras)` you can call the `share` method to transform your model into a TF Encrypted Keras model.\n",
        "\n",
        "If you have asked to manually manage servers above then this step will not complete until they have all been launched. Note that your firewall may ask for Python to accept incoming connection."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3R_rXrQf5Vt8",
        "colab_type": "code",
        "outputId": "eca27433-fbc6-40b7-8bb8-a4f49ff0c629",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        }
      },
      "source": [
        "model.share(alice, bob, carol)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0715 01:20:30.971613 140546383480704 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tf_encrypted/keras/engine/base_layer_utils.py:29: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0715 01:20:30.973762 140546383480704 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tf_encrypted/tensor/native.py:403: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0715 01:20:30.981237 140546383480704 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tf_encrypted/tensor/native.py:101: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0715 01:20:31.027499 140546383480704 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tf_encrypted/tensor/shared.py:62: calling extract_image_patches (from tensorflow.python.ops.array_ops) with ksizes is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "ksizes is deprecated, use sizes instead\n",
            "W0715 01:20:31.122115 140546383480704 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tf_encrypted/protocol/pond/pond.py:3131: The name tf.Dimension is deprecated. Please use tf.compat.v1.Dimension instead.\n",
            "\n",
            "W0715 01:20:31.152074 140546383480704 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_encrypted/protocol/securenn/odd_tensor.py:306: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "I0715 01:20:34.159528 140546383480704 tfe.py:46] If not done already, please launch the following command in a terminal on host localhost:8887: 'python -m tf_encrypted.player --config /tmp/tfe.config server0'\n",
            "This can be done automatically in a local subprocess by setting `auto_managed=True` when instantiating a TFEWorker.\n",
            "\n",
            "I0715 01:20:34.160843 140546383480704 tfe.py:46] If not done already, please launch the following command in a terminal on host localhost:8888: 'python -m tf_encrypted.player --config /tmp/tfe.config server1'\n",
            "This can be done automatically in a local subprocess by setting `auto_managed=True` when instantiating a TFEWorker.\n",
            "\n",
            "I0715 01:20:34.162190 140546383480704 tfe.py:46] If not done already, please launch the following command in a terminal on host localhost:8889: 'python -m tf_encrypted.player --config /tmp/tfe.config server2'\n",
            "This can be done automatically in a local subprocess by setting `auto_managed=True` when instantiating a TFEWorker.\n",
            "\n",
            "I0715 01:20:34.165435 140546383480704 session.py:55] Starting session on target 'grpc://localhost:8887' using config graph_options {\n",
            "}\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50C_ExVC5Vt-",
        "colab_type": "text"
      },
      "source": [
        "## Step 5: Launch 3 Servers\n",
        "\n",
        "```\n",
        "python -m tf_encrypted.player --config /tmp/tfe.config server0\n",
        "python -m tf_encrypted.player --config /tmp/tfe.config server1\n",
        "python -m tf_encrypted.player --config /tmp/tfe.config server2```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kI_sH9X0HBL4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python -m tf_encrypted.player --config /tmp/tfe.config server0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcphe2dOHnCg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        },
        "outputId": "b3ae3d11-bf29-44d9-ae98-32dcc48e649f"
      },
      "source": [
        "!python -m tf_encrypted.player --config /tmp/tfe.config server1 "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0715 01:13:23.958401 140615319328640 secure_random.py:26] Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was '/usr/local/lib/python3.6/dist-packages/tf_encrypted/operations/secure_random/secure_random_module_tf_1.14.0.so'\n",
            "W0715 01:13:23.974628 140615319328640 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tf_encrypted/session.py:26: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "I0715 01:13:24.014045 140615319328640 config.py:280] Creating server for 'server1' using ClusterSpec({'tfe': ['localhost:4000', 'localhost:4001', 'localhost:4002']})\n",
            "W0715 01:13:24.014289 140615319328640 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tf_encrypted/config.py:281: The name tf.train.Server is deprecated. Please use tf.distribute.Server instead.\n",
            "\n",
            "2019-07-15 01:13:24.018623: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2019-07-15 01:13:24.018812: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x175f2c0 executing computations on platform Host. Devices:\n",
            "2019-07-15 01:13:24.018839: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2019-07-15 01:13:24.021336: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n",
            "2019-07-15 01:13:24.132566: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-15 01:13:24.133040: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4eb8700 executing computations on platform CUDA. Devices:\n",
            "2019-07-15 01:13:24.133065: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2019-07-15 01:13:24.133275: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-15 01:13:24.133780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-07-15 01:13:24.134159: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-07-15 01:13:24.135301: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-07-15 01:13:24.136242: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-07-15 01:13:24.136524: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-07-15 01:13:24.137744: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-07-15 01:13:24.138580: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-07-15 01:13:24.141529: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-07-15 01:13:24.141678: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-15 01:13:24.142086: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-15 01:13:24.142414: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2019-07-15 01:13:24.142465: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-07-15 01:13:24.143326: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-07-15 01:13:24.143352: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2019-07-15 01:13:24.143364: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2019-07-15 01:13:24.143664: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-15 01:13:24.144077: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-15 01:13:24.144467: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:40] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-07-15 01:13:24.144528: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:tfe/replica:0/task:1/device:GPU:0 with 13540 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "2019-07-15 01:13:24.145637: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:250] Initialize GrpcChannelCache for job tfe -> {0 -> localhost:4000, 1 -> localhost:4001, 2 -> localhost:4002}\n",
            "2019-07-15 01:13:24.146480: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:365] Started server with target: grpc://localhost:4001\n",
            "I0715 01:13:24.146585 140615319328640 config.py:288] Created server for 'server1' as device '/job:tfe/replica:0/task:1/cpu:0'; own session target is 'grpc://localhost:4001'\n",
            "^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqkC1bKeHmvM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "84c5d7e6-5246-4b28-e866-e63e10ddd624"
      },
      "source": [
        "!python -m tf_encrypted.player --config /tmp/tfe.config server1 "
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-b93d4284b679>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'python -m tf_encrypted.player --config /tmp/tfe.config server1 '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'also_return_output'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_system_commands\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_system_compat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpip_warn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_system_compat\u001b[0;34m(shell, cmd, also_return_output)\u001b[0m\n\u001b[1;32m    436\u001b[0m   \u001b[0;31m# stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m   result = _run_command(\n\u001b[0;32m--> 438\u001b[0;31m       shell.var_expand(cmd, depth=2), clear_streamed_output=False)\n\u001b[0m\u001b[1;32m    439\u001b[0m   \u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_exit_code'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_INTERRUPTED_SIGNALS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_run_command\u001b[0;34m(cmd, clear_streamed_output)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     with temporary_clearer(), _display_stdin_widget(\n\u001b[0;32m--> 181\u001b[0;31m         delay_millis=500) as update_stdin_widget:\n\u001b[0m\u001b[1;32m    182\u001b[0m       \u001b[0;31m# TODO(b/115531839): Ensure that subprocesses are terminated upon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m       \u001b[0;31m# interrupt.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_display_stdin_widget\u001b[0;34m(delay_millis)\u001b[0m\n\u001b[1;32m    339\u001b[0m   \u001b[0mshell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ipython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m   \u001b[0mdisplay_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'cell_display_stdin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'delayMillis'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdelay_millis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m   \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocking_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdisplay_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent_header\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mecho_updater\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_echo_status\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    169\u001b[0m   \u001b[0;31m# unique.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m   \u001b[0mrequest_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msend_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     if (reply.get('type') == 'colab_reply' and\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THA4BMZb5Vt-",
        "colab_type": "text"
      },
      "source": [
        "## Step 6: Serve the Model\n",
        "\n",
        "Perfect! Now by calling `model.serve`, your model is ready to provide some private predictions. You can set `num_requests` to set a limit on the number of predictions requests served by the model; if not specified then the model will be served until interrupted."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myc8Kvnl5Vt_",
        "colab_type": "code",
        "outputId": "760904c3-8696-43cc-9522-8750d23ed89c",
        "colab": {}
      },
      "source": [
        "model.serve(num_requests=3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Served encrypted prediction 1 to client.\n",
            "Served encrypted prediction 2 to client.\n",
            "Served encrypted prediction 3 to client.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BOjJi3L5VuA",
        "colab_type": "text"
      },
      "source": [
        "## Step 7: Run the Client\n",
        "\n",
        "At this point open up and run the companion notebook: Section 4b - Encrytped Keras Client"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pLSsLH75VuB",
        "colab_type": "text"
      },
      "source": [
        "## Step 8: Shutdown the Servers\n",
        "\n",
        "Once your request limit above, the model will no longer be available for serving requests, but it's still secret shared between the three workers above. You can kill the workers by executing the cell below.\n",
        "\n",
        "**Congratulations** on finishing Part 12: Secure Classification with Syft Keras and TFE!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blRFnEvq5VuB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.shutdown_workers()\n",
        "\n",
        "if not AUTO:\n",
        "    process_ids = !ps aux | grep '[p]ython -m tf_encrypted.player --config /tmp/tfe.config' | awk '{print $2}'\n",
        "    for process_id in process_ids:\n",
        "        !kill {process_id}\n",
        "        print(\"Process ID {id} has been killed.\".format(id=process_id))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sbu189Y5VuC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "larmN8pQ5VuE",
        "colab_type": "text"
      },
      "source": [
        "# Keystone Project - Mix and Match What You've Learned\n",
        "\n",
        "Description: Take two of the concepts you've learned about in this course (Encrypted Computation, Federated Learning, Differential Privacy) and combine them for a use case of your own design. Extra credit if you can get your demo working with [WebSocketWorkers](https://github.com/OpenMined/PySyft/tree/dev/examples/tutorials/advanced/websockets-example-MNIST) instead of VirtualWorkers! Then take your demo or example application, write a blogpost, and share that blogpost in #general-discussion on OpenMined's slack!!!\n",
        "\n",
        "Inspiration:\n",
        "- This Course's Code: https://github.com/Udacity/private-ai\n",
        "- OpenMined's Tutorials: https://github.com/OpenMined/PySyft/tree/dev/examples/tutorials\n",
        "- OpenMined's Blog: https://blog.openmined.org"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p51oDKCd5VuE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iC2NN-OA5VuH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXBnmvI85VuI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "paq4FSRy5VuM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgY8mWwg5VuN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7UeADUQ5VuO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKHXkDna5VuR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G11wzZJH5VuS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l49_trlR5VuT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjaBw7wa5VuV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3-OkPsB5VuW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PK0QaD6Y5VuX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kn9CjKq05Vua",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFeYHKTp5Vub",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mF1Tx0C25Vuc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhZ_ILvQ5Vuc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNUumm615Vuf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmMwuDUZ5Vug",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vN0NPP0d5Vug",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}